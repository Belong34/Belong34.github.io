<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.1">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.1" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.1">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.4.1',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="此文只是笔记+课件记录，时间有限，没有系统补充知识以总结，没有什么参考意义">
<meta property="og:type" content="article">
<meta property="og:title" content="acm machines learning note">
<meta property="og:url" content="Belong34.github.io/2020/03/02/Deeping_learning/acm machines learning note/index.html">
<meta property="og:site_name" content="Renegades">
<meta property="og:description" content="此文只是笔记+课件记录，时间有限，没有系统补充知识以总结，没有什么参考意义">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200303_231616_81.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_133332_75.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_133026_33.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_144342_82.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_144526_10.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_150052_85.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_151345_26.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_152125_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_152224_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_153019_27.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_153625_30.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_130851_77.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_131806_93.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_132108_75.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200314_215650_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200314_220406_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_134548_69.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_135004_76.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_140809_41.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_141040_87.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_142550_96.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_143216_11.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_143922_14.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_144710_10.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_150049_88.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_150720_55.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154953_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200315_000807_92.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_145911_01.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_150314_31.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_150732_61.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_151639_36.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_152129_25.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154359_81.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154633_36.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153012_30.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153113_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153336_19.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_135936_56.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_153844_57.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_154330_97.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155147_29.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155422_99.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155854_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_160044_95.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161323_39.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161508_35.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161540_22.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161925_76.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_175803_53.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_175940_11.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_180234_99.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_180913_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_181219_96.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174024_10.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174135_90.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174708_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174826_53.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_181853_99.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_182227_25.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_182556_35.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193048_57.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193311_58.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193930_87.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_194409_24.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_194750_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_195806_12.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_201042_34.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210137_21.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210151_77.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210304_12.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210438_41.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_203021_17.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_203434_90.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_205854_74.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_204308_24.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_204542_97.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_231906_11.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_232746_36.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_233535_59.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_233824_39.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_234954_20.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200509_221623_41.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_235651_83.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_000557_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_002916_31.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003316_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003429_93.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003746_97.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_004325_17.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_195527_32.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_201959_54.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_210348_68.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_210937_80.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_211302_29.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_211518_91.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_211656_49.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_225404_18.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_225750_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_230152_21.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_230601_45.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_230749_26.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_231054_95.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_231203_71.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_231417_38.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_231928_54.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_232319_78.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233201_92.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233420_91.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200419_002407_43.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233631_22.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233746_36.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233851_94.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_234405_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_234651_85.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_235042_97.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_235657_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_190417_91.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200419_000006_24.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200419_000410_59.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200419_000253_16.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_160003_22.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_160329_83.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_161533_69.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_161543_16.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_161824_41.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_162015_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_162239_60.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_163845_58.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164150_49.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164202_25.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164510_19.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164630_98.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164756_71.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_165239_23.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_165658_60.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_165709_70.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_180100_69.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_180649_99.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_181115_59.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_181455_86.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_182353_46.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_182858_70.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_183027_83.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_183231_85.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_183341_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_183918_73.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_213730_96.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_214320_93.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_214520_35.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_214629_11.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_215324_64.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_215329_88.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_215535_74.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_215932_28.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_220216_21.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_220241_86.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_220354_41.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_220429_49.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_225340_74.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_221212_92.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_221405_42.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_221641_22.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_221933_99.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_222207_83.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_222522_86.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_222636_59.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_223007_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_223100_85.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_224932_24.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_101221_77.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_103543_22.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104010_82.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104335_94.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_224603_55.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_224811_98.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104543_39.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104719_31.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104833_21.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_105048_88.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_105353_67.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_105533_36.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_105441_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_110311_74.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_110716_95.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_110911_30.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_111824_15.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_112543_66.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113043_42.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113121_83.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113243_90.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113633_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113826_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113935_91.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_114236_19.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_114426_77.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_195206_49.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_195749_94.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_200011_64.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_200115_54.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_200824_31.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_200923_31.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201036_71.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201443_51.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201510_56.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201624_78.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201711_98.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201847_17.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_224916_36.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_202845_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_203112_35.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_203612_98.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_203935_35.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_204143_50.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_204426_57.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_204533_11.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_204725_32.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_205032_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_205052_50.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_205148_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_205356_61.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_211617_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_220605_39.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095146_17.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095225_16.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095353_26.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095533_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095812_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_100248_59.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_100402_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_100458_74.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_100905_53.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101347_86.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101611_24.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101618_35.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101625_17.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101637_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101645_12.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101653_49.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_112840_26.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113144_82.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113308_52.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113408_11.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113554_81.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113837_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_114138_32.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_114240_28.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_114416_51.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_114823_52.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115020_23.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115316_93.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115327_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115337_20.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115727_97.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115833_14.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_120120_91.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_120726_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_121105_60.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_121208_57.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_121353_19.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_121646_89.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122110_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122310_72.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122506_59.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122645_83.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122719_66.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122941_57.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_123147_89.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124001_76.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124224_87.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124355_52.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124458_91.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124637_53.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124909_74.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_125019_20.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_125206_27.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_084904_10.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_085437_68.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_085557_20.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_090034_02.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_090218_50.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_090319_70.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_090833_41.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_091132_88.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_091428_79.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_091841_81.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_091936_91.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_092141_54.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_092223_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_092438_57.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_092605_15.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_092730_82.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_093002_52.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_093016_52.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_093206_99.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_093417_60.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_093849_48.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_102002_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_102459_55.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_221352_98.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_221544_19.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_221627_90.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_221754_33.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_221924_68.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_222012_60.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_222228_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_222334_33.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_222415_35.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_222517_97.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_222558_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_222709_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_222941_36.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_223001_27.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_223306_22.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_223508_24.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_224705_49.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_225007_99.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_225052_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_225131_69.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_225237_86.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_225344_39.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_225522_77.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_225943_40.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_230139_86.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_230330_56.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_230416_45.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_230546_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_230844_92.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_230907_33.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_231133_90.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_231303_14.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_231451_64.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_232012_86.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_232732_79.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_233015_34.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_233049_19.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_233240_73.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_233413_76.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_233440_53.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_233548_57.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_233713_36.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_233904_50.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_234010_12.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_234137_30.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_234249_58.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_234510_79.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_235038_77.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_235152_87.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_235633_61.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_235833_18.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200520_000025_30.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200520_000253_23.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200520_000446_68.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_103627_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_104008_33.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_104220_71.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_104527_10.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_104815_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_105148_17.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_105629_95.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_105747_33.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_110016_63.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_133009_49.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_133349_37.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_133549_61.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_133621_31.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_134237_32.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_142338_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_142448_43.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_142656_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_222145_39.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_222513_23.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_222629_15.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_222919_20.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_223221_54.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_223403_53.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_223636_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_223757_26.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_223941_51.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_224222_62.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_224303_19.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_224439_43.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_224636_94.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_224812_58.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_224922_14.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_225013_26.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_225455_45.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_225732_82.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_230238_10.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_230309_23.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_230441_53.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_230721_32.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_230821_99.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_230907_52.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_231057_12.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_231210_80.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_232750_94.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_232852_96.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_232929_34.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233023_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233051_67.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233209_37.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233242_73.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233502_91.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233553_41.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233645_16.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233803_94.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233903_32.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_234155_59.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_181318_35.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_181336_15.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_182138_86.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_182252_45.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_182703_79.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_182827_90.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_183424_72.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_184037_07.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_184558_79.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_185053_37.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_211041_42.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_211526_16.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_211849_55.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_212126_48.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_212249_37.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_212334_59.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_212420_58.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_212712_40.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_212945_23.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_213028_52.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_213048_25.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_213159_61.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_214232_30.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_214346_29.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_214832_92.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_221804_34.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_222119_40.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_222650_38.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_223012_46.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_223304_70.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_223655_43.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_224616_70.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_225004_25.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_225227_31.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_225452_15.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_225637_54.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_225724_37.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_230040_46.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_230405_42.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_230556_43.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_230715_49.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_231030_12.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_231120_15.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_231315_49.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_231454_26.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_231741_38.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_231929_10.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_232019_34.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_232238_20.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_181817_52.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_182538_20.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_182904_70.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_183413_78.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_183448_82.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_184036_31.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_200619_89.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_200806_45.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_201058_42.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_082948_58.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_083028_28.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_083205_66.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_083429_43.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_083704_62.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_083910_89.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_084329_54.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_084812_96.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_084901_53.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_085059_26.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_085450_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_085539_98.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_085701_60.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_085919_50.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_090050_33.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_090247_39.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_090309_29.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_090333_49.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_090350_19.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_090653_67.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_090730_68.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_091012_40.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_091204_46.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_091259_49.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_091718_91.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_091829_27.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_092218_28.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_092522_66.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_092749_52.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_092857_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_092908_88.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_092918_28.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_092956_94.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_093232_26.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_093522_22.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_203147_85.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_203255_22.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_203828_56.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_203957_89.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_204252_62.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_204618_40.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_204735_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_205121_61.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_205152_98.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_205321_48.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_205556_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_205711_74.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_210210_69.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_211708_57.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_212337_66.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_212526_18.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_212619_50.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_212704_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_212836_34.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_235612_62.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_213617_86.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_213800_20.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_213859_55.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_214201_91.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_214311_30.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_214454_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_214704_41.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_231752_61.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_231859_20.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_233644_67.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_235526_48.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_235618_90.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_235811_14.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_235949_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_000600_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_000718_37.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_001030_21.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_062952_24.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_063146_16.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_063431_12.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_063831_87.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_064000_95.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_064436_17.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_065029_39.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_065457_80.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_065840_51.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_070104_71.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_070235_78.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_070319_86.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_070925_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_071048_68.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_071234_34.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_071646_96.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_071721_19.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_071947_20.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_072112_88.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_072214_83.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_072401_17.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_072826_18.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_111056_19.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_111214_62.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_111412_96.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_111756_45.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_111840_33.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_112020_89.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_112247_86.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_112339_70.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_112441_41.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_112619_97.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_112719_28.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_112830_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_113141_32.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_113346_66.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_113436_15.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_113613_34.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_113843_45.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_114144_29.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_114425_80.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_150009_83.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_150109_31.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_150309_66.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_150640_87.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_150756_63.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_151043_37.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_151411_95.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_151619_33.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_151730_66.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_151953_73.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_152323_82.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_162512_71.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_162806_31.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_162951_22.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_163053_11.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_163203_76.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_163416_99.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_163606_43.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_163840_23.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_164037_89.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_164410_55.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_164503_52.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_164606_41.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_164857_29.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_164942_10.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_165051_72.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_165301_74.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_165520_69.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_165816_55.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_165841_52.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_165934_21.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_170225_35.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_170547_12.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_170753_52.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_170902_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_171414_30.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_171657_58.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_171946_10.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_172259_63.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_172405_60.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_172550_48.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_173419_50.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_173404_04.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_173512_17.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_173613_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_173624_80.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_173644_33.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_174002_34.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_174018_85.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_174047_73.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_174100_95.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_174406_59.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_174803_37.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_175024_72.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_175549_68.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_175947_32.png">
<meta property="og:updated_time" content="2023-10-16T13:56:58.034Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="acm machines learning note">
<meta name="twitter:description" content="此文只是笔记+课件记录，时间有限，没有系统补充知识以总结，没有什么参考意义">
<meta name="twitter:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200303_231616_81.png">
  <link rel="canonical" href="Belong34.github.io/2020/03/02/Deeping_learning/acm machines learning note/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>acm machines learning note | Renegades</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Renegades</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
        
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      
    
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="Belong34.github.io/2020/03/02/Deeping_learning/acm machines learning note/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="狗仔源">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/22.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Renegades">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            acm machines learning note
            

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2020-03-02 13:13:34" itemprop="dateCreated datePublished" datetime="2020-03-02T13:13:34+08:00">2020-03-02</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-10-16 21:56:58" itemprop="dateModified" datetime="2023-10-16T21:56:58+08:00">2023-10-16</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deeping-learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deeping_learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
              
                <span class="post-meta-item-text">本文字数：</span>
              
              <span>19k</span>
            </span>
          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
              
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              
              <span>17 分钟</span>
            </span>
          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>此文只是笔记+课件记录，时间有限，没有系统补充知识以总结，没有什么参考意义</p>
<a id="more"></a>
<h1 id="人工智能"><a href="#人工智能" class="headerlink" title="人工智能"></a>人工智能</h1><p>搜索 推理 学习</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200303_231616_81.png" alt="20200303_231616_81"></p>
<h1 id="数据科学"><a href="#数据科学" class="headerlink" title="数据科学"></a>数据科学</h1><p>目标：发现数据的基本原理，从观测的结果中构建数据模型，由于其数据比较大，所以会使用很多的算法来实现数据的分析。本质上讲与传统的物理学,化学等做的内容一样,但更加广泛</p>
<p>用户行为建模的例子：通过利用一些比较容易得到的数据去得到比较获取并且很有价值的数据<br>由联合数据分布P(x)得到条件数据分布P(x2|x1)<br>Raw Data -&gt; Data Service -&gt; Application</p>
<p>数据处理技术：数据本身是没有价值的，有价值的是数据服务</p>
<h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><h2 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h2><p>50年代（创建ML术语）-&gt;60年代（神经网络+感知机，因为感知机被证明了局限性所以被冷冻）-&gt;70年代（做符号归纳，专家系统。决策树模型）-&gt;80年代（起飞一波，反向传播，高级决策树）-&gt;90年代（自适应，文本学习，RL提出，SVM+核方法，贝叶斯）-&gt;00年代（概率图，变分推理，迁移学习，跨模态学习）-&gt;10年代（深度学习，强大算力，GPU，多任务+终身学习，深度强化学习）</p>
<h2 id="机器学习的两种类型"><a href="#机器学习的两种类型" class="headerlink" title="机器学习的两种类型"></a>机器学习的两种类型</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_133332_75.png" alt="20200302_133332_75"><br>监督侧重的是：通过某一维预测某一维。基于给定的数据预测目标概率分布</p>
<p>无监督：侧重在全部维，联合分布下求条件分布</p>
<p>而决策是多步的，主语是机器。</p>
<p>预测型用于辅助人决策，决策型是自己替代人自己决策。</p>
<h2 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_133026_33.png" alt="20200302_133026_33"></p>
<h1 id="机器学习应用"><a href="#机器学习应用" class="headerlink" title="机器学习应用"></a>机器学习应用</h1><h2 id="面向预测的应用"><a href="#面向预测的应用" class="headerlink" title="面向预测的应用"></a>面向预测的应用</h2><p>网页搜索：基本的Learning to rank；新一代搜索：QA系统，反馈<br>人脸识别<br>推荐系统：更重要的时手机终端<br>在线广告：用户是否喜欢广告，广告客户如何出价<br>信息提取：结构化信息提取，医疗文本信息提取<br>医疗图像分析<br>金融数据预测</p>
<h2 id="面向决策的应用"><a href="#面向决策的应用" class="headerlink" title="面向决策的应用"></a>面向决策的应用</h2><p>交互式内容推荐：抖音、影响用户的兴趣，GNN<br>机器人控制<br>自动驾驶<br>游戏智能<br>多智能体协作（Multi-agent RL），合作或竞争</p>
<p>关于文本的标注：半监督的一种：远程监督</p>
<h1 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_144342_82.png" alt="20200302_144342_82"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_144526_10.png" alt="20200302_144526_10"></p>
<h2 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h2><h3 id="学习目标是什么？"><a href="#学习目标是什么？" class="headerlink" title="学习目标是什么？"></a>学习目标是什么？</h3><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_150052_85.png" alt="20200302_150052_85"></p>
<p>平方误差：距离越远，损失越多，但容忍小距离 (误差)</p>
<p>怎么更新假设空间：梯度下降</p>
<h1 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h1><h2 id="过拟合，欠拟合"><a href="#过拟合，欠拟合" class="headerlink" title="过拟合，欠拟合"></a>过拟合，欠拟合</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_151345_26.png" alt="20200302_151345_26"></p>
<p>一开始建立复杂的模型防止欠拟合，然后正则化去惩罚</p>
<h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>本质：    本质上都是对向量求一个范式。损失函数 + 基于假设的罚值（范数距离）  </p>
<p>为了防止他只去到最中间那个点(每个等高线是θ)，也就是过拟合，过每个点的那种，我们加上惩罚项，使他往外面走一点。<br><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_152125_65.png" alt="20200302_152125_65"></p>
<ul>
<li>L1：稀疏特征</li>
<li>L1+L2：工业界一般</li>
<li>q太大了也不行，值可能也会变大，一般来说不会每个特征都大。BTW，一般残差(n次方)的权重都不会太大，太大了一般代表有一些东西干扰了。<br><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_152224_44.png" alt="20200302_152224_44"><h3 id="Q：超参入可学习吗？"><a href="#Q：超参入可学习吗？" class="headerlink" title="Q：超参入可学习吗？"></a>Q：超参入可学习吗？</h3>不可，不可导，也学习是使loss越小越好，这里明显是惩罚用的。</li>
</ul>
<h2 id="奥卡姆剃刀"><a href="#奥卡姆剃刀" class="headerlink" title="奥卡姆剃刀"></a>奥卡姆剃刀</h2><p>有多个假设模型，我们应该选择假设条件最少的建模方法，so正则化。比如少用些特征，或者特征间的交互模式比较简单</p>
<h2 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_153019_27.png" alt="20200302_153019_27"></p>
<h1 id="泛化能力-GA"><a href="#泛化能力-GA" class="headerlink" title="泛化能力(GA)"></a>泛化能力(GA)</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_153625_30.png" alt="20200302_153625_30"></p>
<h1 id="判别模型与生成模型"><a href="#判别模型与生成模型" class="headerlink" title="判别模型与生成模型"></a>判别模型与生成模型</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_130851_77.png" alt="20200309_130851_77"></p>
<h2 id="生成模型"><a href="#生成模型" class="headerlink" title="生成模型"></a>生成模型</h2><p>生成模型就是建模一个联合概率分布，然后进行条件推断(先建立好多维度的，然后根据需要选择特定维度，进行边缘化)。探寻数据分布(数据科学的本质)，受益于隐变量建模</p>
<p>应用:朴素贝叶斯,隐马尔科夫模型,混合高斯模型,马尔科夫随机场, 隐狄利克雷分布(LDA)等</p>
<p>关于生成模型，贝叶斯派，更能很好反映数据的分布，频率派：好算，投入生产中</p>
<h2 id="判别模型"><a href="#判别模型" class="headerlink" title="判别模型"></a>判别模型</h2><p>判别模型，确定性模型本质相当于拟合一个函数，而随机判别就是建立条件概率。</p>
<ul>
<li>直接建模预测标签与已知特征的关联</li>
<li>易于定义特定依赖的特征和模型</li>
<li>实际上产生更高的预测性能</li>
</ul>
<p>应用：线性回归,逻辑回归,k近邻, 支持向量机, (多层)感知机,决策树,随机森林等</p>
<h2 id="两者的差别"><a href="#两者的差别" class="headerlink" title="两者的差别"></a>两者的差别</h2><p>误差的侧重点，判别模型是集中精力去寻找这两维的差别，，而生成模型相当于学习到联合联合概率分布，和边缘分布。侧重于所有维，那么误差也是存在于所有维度上的，</p>
<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><p>确定性判别模型，一个截距，加上每一维度与标量的乘积</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_131806_93.png" alt="20200309_131806_93">   </p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_132108_75.png" alt="20200309_132108_75"></p>
<p>二维回归也是线性模型，相当于增加了一个映射，增多了一个维度(出现θ方就不是线性)。只不过可以把fai理解为特征工程</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200314_215650_84.png" alt="20200314_215650_84"></p>
<p>转换成三维图看，每一组特征所对应的y值不一样，但是会通过f(x)映射到一个面上，这个面叫做流形。那个y的取值不一样可以从两个角度理解，一个是x和y概率分布的问题。一个是还有一些特征没有被挖掘。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200314_220406_13.png" alt="20200314_220406_13"></p>
<p>在最小化目标函数的时候，我们可以看到，从某个θ处不同的取值看都是U(不同θU都是不一样的)。所以才使用梯度下降。 如果是θ多维的，就寻找梯度绝对值最大且沿着斜率往上走的那个，再减去这个梯度。</p>
<h1 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_134548_69.png" alt="20200309_134548_69"></p>
<p>目标是使得这个优化函数的值最小，然后梯度更新的目标是使得θ朝着梯度绝对值最大的地方，所以对fθ求导的xi</p>
<p>批量梯度在那个等高线图上的表示就是前面几段线更新的幅度都很大。而随机梯度在后半端会疯狂震荡，因为每一个取值都有偏差对他造成影响。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_135004_76.png" alt="20200309_135004_76"></p>
<p>小批量梯度将训练集分成k个batch，来优化，梯度下降</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_140809_41.png" alt="20200309_140809_41"></p>
<p>当然批量梯度下降也可以b并行化，具体还得看具体项目或者数据的规格，如果数据量很大的话，机器性能很有限的话，还是不适宜切割这么大块的数据。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_141040_87.png" alt="20200309_141040_87"></p>
<p>初始值不同有可能得到不同的局部最优解，初始化位置，可以当作为一个超参数，但如对于一个凸优化函数，局部最小值就是全局最小值，凸函数不一定可导，Relu</p>
<p>学习率的设置往往会对应一个函数动态发生改变1/根号t，其次，我们检查梯度下降是否有效，往往可以打印几个迭代得到的损失值，取判断误差是否有正常的下降</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_142550_96.png" alt="20200309_142550_96"></p>
<p>Q：梯度大，变化率大，也就是梯度下降会很敏感，如果还取很大的值的话，会不会很容易越界，跑过头了？<br>如图，存在这种情况，这个沟很窄，很容易就越出去，但通常来说，构建好的模型，往往在实际应用中会出现偏移，如果取值范围这么窄的话，很有可能实际中就不对应了，所以为了鲁棒性，一般来说会选择比较大的沟。其次为了防止落入窄山谷中，还有一些其他的梯度下降(动量等)</p>
<h1 id="线性回归矩阵形式"><a href="#线性回归矩阵形式" class="headerlink" title="线性回归矩阵形式"></a>线性回归矩阵形式</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_143216_11.png" alt="20200309_143216_11"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_143922_14.png" alt="20200309_143922_14"></p>
<p>计算量太大了 求逆的复杂度是n^3，所以这个只是理论上的，实际上还是使用梯度下降。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_144710_10.png" alt="20200309_144710_10"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_150049_88.png" alt="20200309_150049_88"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_150720_55.png" alt="20200309_150720_55"></p>
<p>当矩阵不是满秩的时候，得到的解不是唯一解，如图所示，很有可能谷底不是一个点，而是一条线，这时候我们需要引入正则化，取与这条线相切的那一点。</p>
<h1 id="泛线性模型"><a href="#泛线性模型" class="headerlink" title="泛线性模型"></a>泛线性模型</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154953_47.png" alt="20200309_154953_47"></p>
<p>泛线性模型其实就是将x变成了针对每个特征的一个映射矩阵。θ之间没有乘除运算即属于线性模型</p>
<p>核矩阵的作用：计算低维空间中的数据映射到高维空间后的内积，使得不再在乎x特征以及映射，而在乎相似度</p>
<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>分类问题线性可分，不可分的情况会映射到高维下可分</p>
<h2 id="二分类"><a href="#二分类" class="headerlink" title="二分类"></a>二分类</h2><p>逻辑回归处理分类问题，属于判别模型中的一种，通常来说使用概率判别模型(分类是离散数据，确定性判别模型对于分类任务不可以微分(函数表示都是导数为0，判别模型概率将离散数据转变成概率分布的连续分布,存在有意义的导数可以学习)。)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200315_000807_92.png" alt="20200315_000807_92"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_145911_01.png" alt="20200321_145911_01"></p>
<p>需要用sigmoid把概率的预测值转化为0-1之间的连续可导的表示，求出概率之后通过设置域(也就是h，看你的需要，更care哪个指标)来确定最终标签(大于为正例，否则为负例)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_150314_31.png" alt="20200321_150314_31"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_150732_61.png" alt="20200321_150732_61"></p>
<p>多分类是可以变成二分类的，例如五分类，可以变成5个二分类(是否第一类，是否第二类….)，不过相应参数会表达许多，在分类较多的情况下不太好</p>
<p>多分类将最小化交叉熵变成最大对数化似然求解，最后加上softmax函数，可以看作是sigmoid函数在多分类情况下的延伸，最后将得到类别数减去一组参数(把一组normalize为1,相当于二分类那个1)。通过e指数形式将模型输出的分数转换为一个概率分布。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_151639_36.png" alt="20200321_151639_36"></p>
<p>关于onehot的表示,通常会转成稀疏表示。因为这样，能确保每个特征之间独立。如果用1-7表示星期1到星期日，其实在先验上赋予了这些类别一些东西。七倍啥的，因此，还有一种设法是onehot 全0也代表一种类别。这种也是不太推荐的。在求取w和b的时候由于太接近了，使得他们的区分线很接近，导致准确率降低。全零的也是一个道理，相当于拿b和别人做区分。也是不太好的。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_152129_25.png" alt="20200321_152129_25"></p>
<h2 id="与非线性模型对比"><a href="#与非线性模型对比" class="headerlink" title="与非线性模型对比"></a>与非线性模型对比</h2><ul>
<li>优点：标准化，易于理解和实施，高效和可拓展性</li>
<li>缺点：建模局限（特征独立假设）,无法探索特征及交互</li>
</ul>
<h1 id="最大似然估计"><a href="#最大似然估计" class="headerlink" title="最大似然估计"></a>最大似然估计</h1><p>随机判别</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154359_81.png" alt="20200309_154359_81"></p>
<p>假设白噪声σ固定，然后可以把条件概率分布等价为了一个高斯分布(联合概率分布)，横坐标上的是θ，其对应的y就是这个条件概率分布。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154633_36.png" alt="20200309_154633_36"></p>
<p>然后我们是这个概率最大，这里使用到了对数计算，一个是因为可以避免算到无穷大或无穷小。把乘法变成了加法，二是最后的化简结果恰好等价于均方误差，就可以不用求梯度了。</p>
<p>PS：判别模型其实根据不同的数据取不同的σ，例如这个噪声的分布十分的不均匀，均方一下很大一下很小，我们就得使用大一点的sigma了</p>
<h1 id="分类指标"><a href="#分类指标" class="headerlink" title="分类指标"></a>分类指标</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153012_30.png" alt="20200309_153012_30"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153113_84.png" alt="20200309_153113_84"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153336_19.png" alt="20200309_153336_19"></p>
<p>如何决定h？使得f1score得到最大值，这样pr会比较均衡</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_135936_56.png" alt="20200321_135936_56"><br>前面的f1score等指标会受到正负样本比等 的影响，但auc基本上都在[0.5,1]，不受样本的太大影响，因此可以用它来横向对比不同任务数据上。如何计算，通过不断降低h的真正假正的变化计算。</p>
<h1 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_153844_57.png" alt="20200321_153844_57"></p>
<p>在现实中，数据存在噪声，往往会在数据周围有个分布，所以支持向量机的划线就是出于这种距离的原则，离数据点间隔越大越好，建立一个最鲁棒的决策边界. 离线的距离是打分，法向量是θ。如果函数</p>
<h2 id="逻辑回归的可视化"><a href="#逻辑回归的可视化" class="headerlink" title="逻辑回归的可视化"></a>逻辑回归的可视化</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_154330_97.png" alt="20200321_154330_97"></p>
<h2 id="支持向量机-1"><a href="#支持向量机-1" class="headerlink" title="支持向量机"></a>支持向量机</h2><p>类别标签的不同：{-1，1}</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155147_29.png" alt="20200321_155147_29"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155422_99.png" alt="20200321_155422_99"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155854_47.png" alt="20200321_155854_47"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_160044_95.png" alt="20200321_160044_95"></p>
<h2 id="向量机优化"><a href="#向量机优化" class="headerlink" title="向量机优化"></a>向量机优化</h2><p>这里使用到了一个凸优化的求解(拉格朗日对偶问题KKT条件)。推导看不太懂。主要的作用就是将一个有限制条件的函数变成了一个没有限制条件(少限制条件)的函数，从而使得可以求导。<br><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161323_39.png" alt="20200321_161323_39"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161508_35.png" alt="20200321_161508_35"></p>
<p>需要满足ag=0，当a等于0的时候是外面的那些点其实是没什么意义的。当g等于0的时候代表的就是最近的那几个点。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161540_22.png" alt="20200321_161540_22"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161925_76.png" alt="20200321_161925_76"></p>
<p>这里minmax和maxmin的选择，因为满足了KKT条件，所以两者是一样的。但是max在里面其实是没有什么意义的。因为有意义的点是求导等于0的。所以使用min在里面。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_175803_53.png" alt="20200329_175803_53"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_175940_11.png" alt="20200329_175940_11"><br>a&gt;0的情况仅仅存在于最近的几个支持向量上，通过这几个向量求解W，b则通过最近的两个正例和负例取平均值求得。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_180234_99.png" alt="20200329_180234_99"></p>
<p>只需要计算支持向量与样例的内积，计算效率很高，然后比较截距就得到正例和负例的判断了。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_180913_65.png" alt="20200329_180913_65"></p>
<p>如果存在一些偏了一点点的点(噪声)，可能会使得函数为了区分他造成很大的影响。我们可以加入个松弛变量(惩罚项)取限制住他，就是使得目标函数不要被太大的影响</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_181219_96.png" alt="20200329_181219_96"></p>
<p>相比较，hinge因为只受到那几个支持向量的影响，得到的函数都是很直的，即正负例分的很清晰。逻辑回归，因为考虑到较多点，虽然平滑，但是往往会使得一些已经判断是正确的了还会去影响到函数</p>
<p>流程如下：</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174024_10.png" alt="20200329_174024_10"></p>
<p>目标函数：</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174135_90.png" alt="20200329_174135_90"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174708_13.png" alt="20200329_174708_13"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174826_53.png" alt="20200329_174826_53"></p>
<h1 id="序列最小优化-SMO"><a href="#序列最小优化-SMO" class="headerlink" title="序列最小优化(SMO)"></a>序列最小优化(SMO)</h1><h2 id="坐标上升法"><a href="#坐标上升法" class="headerlink" title="坐标上升法"></a>坐标上升法</h2><p>每一次优化的时候，只取一个α。不断优化，直至收敛，</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_181853_99.png" alt="20200329_181853_99"></p>
<h2 id="SMO"><a href="#SMO" class="headerlink" title="SMO"></a>SMO</h2><p>但是不能使用，因为有一个限制条件，Σαiyi=0，只要有一点改变α就不等于0了(也就是αi变了αj也得变)，因此引入smo</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_182227_25.png" alt="20200329_182227_25"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_182556_35.png" alt="20200329_182556_35"></p>
<p>效率很高，复杂度仅仅为O(1)</p>
<h1 id="支持向量机核方法"><a href="#支持向量机核方法" class="headerlink" title="支持向量机核方法"></a>支持向量机核方法</h1><p>上文提到的松弛变量只能解决存在一点噪声的不可分情况，而实际上遇到高维的线性不可分，还是得从核出发</p>
<p>解决方法：将特征向量映射到高维空间中</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193048_57.png" alt="20200329_193048_57"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193311_58.png" alt="20200329_193311_58"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193930_87.png" alt="20200329_193930_87"></p>
<p>相对不关注映射是怎么样的，更多是衡量两者之间的相似性，包括到b的求解也是可以直接带入到K中，从而避开了映射。复杂度为O(n)(小于直接计算的O(n方))</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_194409_24.png" alt="20200329_194409_24"></p>
<p>此映射函数是一个无穷维的函数，但是我们不care。K是对称矩阵，半正定矩阵(ZTKZ&gt;=0)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_194750_84.png" alt="20200329_194750_84"></p>
<p>还有sigmoid核子(tanh(ax^Tz+C))，相当于一个二层的感知机</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>其实svm只是一个优化的目标函数而已，和最小化均方差啥的都一个道理，但是他有很好的结构性质与技巧。α。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_195806_12.png" alt="20200329_195806_12"></p>
<p>统计机器学习的本质归根到底就是两个数据的相似性：相似的数据拥有相同的label</p>
<h1 id="人工神经网络发展"><a href="#人工神经网络发展" class="headerlink" title="人工神经网络发展"></a>人工神经网络发展</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_201042_34.png" alt="20200329_201042_34"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210137_21.png" alt="20200329_210137_21"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210151_77.png" alt="20200329_210151_77"></p>
<p>停滞了20年，1986多感知机的方法得到了实现，但是解决方案不唯一</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210304_12.png" alt="20200329_210304_12"></p>
<p>直到前馈的出世统一了这个解决方案</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210438_41.png" alt="20200329_210438_41"></p>
<h1 id="普适逼近定理"><a href="#普适逼近定理" class="headerlink" title="普适逼近定理"></a>普适逼近定理</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_203021_17.png" alt="20200329_203021_17"></p>
<p>可以理解维有限神经元是很多隐藏层，每个点都是个感知机，可以通过一个精度控制每个感知机负责一小块的线段。达到逼近任意线的目标。</p>
<p>其中激活函数的目标就是添加非线性的因素，因为线性怎么叠加仍然还是线性，</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_203434_90.png" alt="20200329_203434_90"></p>
<p>Q:神经网络相比于一般的逼近方法(分段插值)，有什么好的地方呢？</p>
<p>A：可学习，到了深层次的东西，不可解释的东西，往往出现一些难以解释的效果</p>
<h1 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_205854_74.png" alt="20200329_205854_74"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_204308_24.png" alt="20200329_204308_24"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_204542_97.png" alt="20200329_204542_97"></p>
<h1 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_231906_11.png" alt="20200405_231906_11"></p>
<p>tanh将sigmoid的(0,1)和(2，2)变成了(-1,1)和(-1，1)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_232746_36.png" alt="20200405_232746_36"></p>
<p>Relu的问题是在0附近，过一点点就不动了，softplus(平滑)和noiseRelu(增加白噪声)就是针对0做一些处理，使其平滑。相比而言，Relu的计算最简单(快)，其次，由于在负值上的取值为0，所以起到了一种稀疏表示的作用(dropout)</p>
<p>损失函数：回归：均方误差 分类：交叉熵</p>
<h1 id="深度学习思想简介"><a href="#深度学习思想简介" class="headerlink" title="深度学习思想简介"></a>深度学习思想简介</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_233535_59.png" alt="20200405_233535_59"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_233824_39.png" alt="20200405_233824_39"></p>
<p>通常不会使用l1l2，如图，l2相当与在0点有一个量去拉着你，很容易导致掉下山峰</p>
<p>众包平台</p>
<p>cpu优化延迟，gpu优化带宽</p>
<h1 id="梯度消失问题的解决方法"><a href="#梯度消失问题的解决方法" class="headerlink" title="梯度消失问题的解决方法"></a>梯度消失问题的解决方法</h1><h2 id="Relu"><a href="#Relu" class="headerlink" title="Relu"></a>Relu</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_234954_20.png" alt="20200405_234954_20"></p>
<p>正值是1，所以相乘怎么样都是有梯度的   </p>
<h2 id="深度残差Resnet"><a href="#深度残差Resnet" class="headerlink" title="深度残差Resnet"></a>深度残差Resnet</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200509_221623_41.png" alt="20200509_221623_41"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_235651_83.png" alt="20200405_235651_83"></p>
<p>训练数据有时在更深的神经网络性能反倒更差，有一种理解是：更深层次的表达后往往会出现更多不确定的优化曲面，很容易陷在一些沟壑内</p>
<p>Resnet的意义：通过一个skip connection使得信号能在不损失信号的情况下，将信号传到很深的地方</p>
<h2 id="批标准化"><a href="#批标准化" class="headerlink" title="批标准化"></a>批标准化</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_000557_13.png" alt="20200406_000557_13"></p>
<p>存在一些问题，就是每次经过激活函数的时候，往往利用的都是没什么意义的区域，就是经过一个激活函数之后，他的输出分布在很后面或者很前面，没有到曲折的部分，这是我们不想看到的。 这时候我们通过一个batch的数据构建分布，当然，这个分布可以自己设置位置(几个可以学习的参数)</p>
<h1 id="陷入局部最小的解决方法"><a href="#陷入局部最小的解决方法" class="headerlink" title="陷入局部最小的解决方法"></a>陷入局部最小的解决方法</h1><p>两个方向：爬山起点怎么设计，怎么更好的爬山</p>
<h2 id="深度信念网络"><a href="#深度信念网络" class="headerlink" title="深度信念网络"></a>深度信念网络</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_002916_31.png" alt="20200406_002916_31"></p>
<p>就是可见单元到隐藏单元，然后隐藏单元能回来，与原本的可见单元比较</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003316_13.png" alt="20200406_003316_13"></p>
<p>encoder和decoder，将特征压缩(学习到最有效的表征信息)再扩展回来和原图差不多，相当于有监督+无监督，损失函数是两张图片的差距，通过这种手段生成一组不错的初始值，然后就是微调模型了。例子：你去爬山，相当于你起点就是青藏高原了。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003429_93.png" alt="20200406_003429_93"></p>
<h2 id="adam"><a href="#adam" class="headerlink" title="adam"></a>adam</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003746_97.png" alt="20200406_003746_97"></p>
<p>可以基于之前的梯度冲出局部最小值。</p>
<h1 id="正则化-1"><a href="#正则化-1" class="headerlink" title="正则化"></a>正则化</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_004325_17.png" alt="20200406_004325_17"></p>
<p>通常不会使用l1l2，如图，l2相当与在0点有一个量去拉着你，很容易导致掉下山峰。</p>
<p>一个有意思的理解：相当于集成学习，每一次dropout的形式都代表一种模型，然后最后测试的时候使用的是全部模型集成在一起。</p>
<h1 id="CNN-空间上的特征"><a href="#CNN-空间上的特征" class="headerlink" title="CNN(空间上的特征)"></a>CNN(空间上的特征)</h1><p>其实kernel可以看作各种各样的模式，取获取这个感受野的内积也就是模式是否相似，然后pooling就是在反传的时候去掉一些意义不大的gradient。所以一般用maxpooling (match最大的)。前面n-1层就是抽取不同感受野下的特征(像素，线条，角，局部，全局)，但是最后一层往往都是线性分类。表征学习</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_195527_32.png" alt="20200418_195527_32"></p>
<p>真相挖掘</p>
<h2 id="用于文本分类"><a href="#用于文本分类" class="headerlink" title="用于文本分类"></a>用于文本分类</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_201959_54.png" alt="20200418_201959_54"></p>
<p>使用的kernel红色：1x3(embedding的5列实际只是编码的表而已，所以不用管)，使用了4个kernel变成第二个红色，也就是将连续的词语获得特征，变成一个，然后max over time pooling，则是将连续的一列词句抽取特征最显著的变成了一个，然后4个kernel连接起来，形成表征。所有kernel结合起来。好处就是抽取了和分类任务相关的词语合起来，得到最有效的表征。相当于我抽了 listen word。省了时间，而不是说每三个就组成一个，这样一个个训练效率不高。</p>
<h1 id="RNN-时间上的特征"><a href="#RNN-时间上的特征" class="headerlink" title="RNN(时间上的特征)"></a>RNN(时间上的特征)</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_210348_68.png" alt="20200418_210348_68"></p>
<p>可以理解为两个w相乘再相加，也可以理解为两个wconcat再乘。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_210937_80.png" alt="20200418_210937_80"></p>
<p>可以看到bp的时候涉及w的运算很多，也很容易把我们带到很远的地方去，所以要小心学习率</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_211302_29.png" alt="20200418_211302_29"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_211518_91.png" alt="20200418_211518_91"></p>
<h1 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h1><p>RNN问题：</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_211656_49.png" alt="20200418_211656_49"></p>
<p>sigmoid都是拿来当一个过滤的门，而relu或tanh都是做特征来用的</p>
<p>遗忘门基于当前的记忆要把长期记忆哪部分遗忘掉，而输入门则是注入哪些当前信号。</p>
<p>有long term 和short term，long term 通过两个sigmoid遗忘和注入新的记忆，再把得到的新long term 和一个sigmoid 过滤当作当前的short term 放到下一个short term上</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_225404_18.png" alt="20200418_225404_18"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_225750_44.png" alt="20200418_225750_44"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_230152_21.png" alt="20200418_230152_21"></p>
<h2 id="Q-amp-A-课程上的提问"><a href="#Q-amp-A-课程上的提问" class="headerlink" title="Q &amp; A(课程上的提问)"></a>Q &amp; A(课程上的提问)</h2><ul>
<li>1.为什么要用tanh来压缩信息？还是说是只是为了丰富网络？如果只是为了丰富网络用relu可以吗？压缩了信息处理会变快吗？</li>
</ul>
<p>你这个问题其实问到我了，我之前没仔细思考为啥lstm里面默认是tanh而不是relu。我临时思考了一下，感觉是这样的：c里面是长期记忆，如果你用relu这样的activation，很可能某一个step就会往c里面注入很大的信息量，把之前的记忆都dominate了。相反tanh因为是bound住的，所以不会造成某一step注入过量信息。</p>
<ul>
<li><p>2.为什么说c这部分没有经过压缩就能很好的解决长期依赖？压缩了就不能很好地传递长期信息了吗？</p>
<p>每次压缩是把之前的记忆向量乘以一个矩阵然后加上当前step进来的信息向量。如果压缩一直做，当然就不能很好的保持较长的dependency了。</p>
<h2 id="词嵌入"><a href="#词嵌入" class="headerlink" title="词嵌入"></a>词嵌入</h2></li>
</ul>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_230601_45.png" alt="20200418_230601_45"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_230749_26.png" alt="20200418_230749_26"></p>
<p>词嵌入是一种对文本算法学习后的表示形式，可以理解为一个单词在算法中的储存形式。大家知道存入计算机的都是0101的数值化序列，这里也是同理，词嵌入就是将文本数值化以方便拟合算法。这种将单词或者文档数字化表示的方式被认为是深度学习在自然语言处理任务中最具有挑战性的问题之一。<br>词嵌入实际上是一种将各个单词在预定的向量空间中表示为实值向量的一类技术。每个单词被映射成一个向量（初始随机化），并且这个向量可以通过神经网络的方式来学习更新。因此这项技术基本集中应用与深度学习领域。</p>
<p>这项技术的关键点在于如何用密集的分布式向量来表示每个单词。这样做的好处在于与one-hot这样的编码对比，使用词嵌入表示的单词向量往往只有几十或者几百个维度。极大的减少了计算和储存量</p>
<h2 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_231054_95.png" alt="20200418_231054_95"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_231203_71.png" alt="20200418_231203_71">  </p>
<h2 id="视觉语言对齐"><a href="#视觉语言对齐" class="headerlink" title="视觉语言对齐"></a>视觉语言对齐</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_231417_38.png" alt="20200418_231417_38"></p>
<p>对齐：描述经过双向rnn，得到每一个位置的vector表示，图片划分区域，用vector和图片位置做一些操作，得到分数用于监督</p>
<h2 id="生成图像描述"><a href="#生成图像描述" class="headerlink" title="生成图像描述"></a>生成图像描述</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_231928_54.png" alt="20200418_231928_54"><br>通过展平的cnn向量和decode的rnn生成单词，做loss的计算，返回给rnn和cnn。 cnn也学习如何生成更符合表征的vector</p>
<p>长短期记忆网络学习视觉语言对齐时，通过计算区域CNN的图片输出表示与双向RNN的中间输出向量之间的内积，来评判语句与图像之间的匹配程度</p>
<h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_232319_78.png" alt="20200418_232319_78"></p>
<p>Q:sigmoid relu tanh<br>sigmoid一般不放在神经网络中间，因为梯度消失，但类似lstm这种需要0-1区间的地方用得到。</p>
<h1 id="函数逼近"><a href="#函数逼近" class="headerlink" title="函数逼近"></a>函数逼近</h1><p>前几周的学习都是参数化的模型，然后梯度求解。(参数的规模不会随数据发生改变)。树的思维方式不一样</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233201_92.png" alt="20200418_233201_92"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233420_91.png" alt="20200418_233420_91"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200419_002407_43.png" alt="20200419_002407_43"></p>
<p>直接再假设空间找到函数，而不是通过参数学习出来</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233631_22.png" alt="20200418_233631_22"></p>
<p>非常容易学习高阶特征(非线性可分)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233746_36.png" alt="20200418_233746_36"></p>
<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233851_94.png" alt="20200418_233851_94"></p>
<p>如何选择分裂节点？-&gt;具有更高的信息增益的特征(更强分类能力)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_234405_65.png" alt="20200418_234405_65"></p>
<p>越中间越不确定</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_234651_85.png" alt="20200418_234651_85"></p>
<p>度量的是两个分布的距离</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_235042_97.png" alt="20200418_235042_97"></p>
<p>相当于有没有看到y对于我不确定的降低有多少</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_235657_47.png" alt="20200418_235657_47"></p>
<p>前者的弊端就是有可能人们把树分的很细，每个节点可能就一两个，(升高分成厘米)。所以引入后者避免这个问题</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_190417_91.png" alt="20200426_190417_91"></p>
<h1 id="ID3"><a href="#ID3" class="headerlink" title="ID3"></a>ID3</h1><p>一个特征在同一条路径最多出现一次。因为第二次使用特征的时候并不会分出子空间来。如果不限制树的深度和宽度，树是可以无限拟合数据的。定义损失函数为叶子节点的经验熵<em>数据量的总和，再次基础上加上叶子节点的数目</em>lamda。这个项用来防止过拟合。ID3是针对离散数据的。C4.5改进了它用信息增益率来分节点。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200419_000006_24.png" alt="20200419_000006_24"></p>
<ul>
<li>Q：有可能划分到最后每一个样例一个节点？</li>
</ul>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200419_000410_59.png" alt="20200419_000410_59"></p>
<p>改进损失函数，加入关于叶子节点数量的惩罚项</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200419_000253_16.png" alt="20200419_000253_16"></p>
<p>Q：决策树和神经网络？<br>决策树更适用一些比较混乱的数据或者missing，而神经网络一般是比较连续的数据</p>
<h1 id="CART决策树"><a href="#CART决策树" class="headerlink" title="CART决策树"></a>CART决策树</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_160003_22.png" alt="20200426_160003_22"></p>
<h2 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_160329_83.png" alt="20200426_160329_83"></p>
<h2 id="分类树"><a href="#分类树" class="headerlink" title="分类树"></a>分类树</h2><p>贝塔分布</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_161533_69.png" alt="20200426_161533_69"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_161543_16.png" alt="20200426_161543_16"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_161824_41.png" alt="20200426_161824_41"></p>
<p>基尼不纯度与熵的分类错误率十分相似，选择能最小化基尼不纯度的特征作为分割点</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_162015_44.png" alt="20200426_162015_44"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_162239_60.png" alt="20200426_162239_60"></p>
<p>往往决策树的模型都可以可视化变成if else便于可视化，原理解释以及debug</p>
<h2 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h2><p>树模型往往更适合处理mix type，missing的数据，outliers，单调的输入，不相关输入，介于参数化和无参数化模型(多一个样本不会多一个参数，或者样本变多了参数也不一定会固定不变)，可解释性。<br>缺点：对于斜着的线性分割不在行，单颗树不太适于预测</p>
<h1 id="集成树"><a href="#集成树" class="headerlink" title="集成树"></a>集成树</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_163845_58.png" alt="20200426_163845_58"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164150_49.png" alt="20200426_164150_49"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164202_25.png" alt="20200426_164202_25"></p>
<p>不同模型在不同场景的权重可以不一样。某方面的专家可以提高他的权重，也可也学习权重</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164510_19.png" alt="20200426_164510_19"></p>
<p>softmax作为gating fn</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164630_98.png" alt="20200426_164630_98"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164756_71.png" alt="20200426_164756_71"></p>
<p>术业有专攻，针对改变每个专家的权重</p>
<h1 id="bagging"><a href="#bagging" class="headerlink" title="bagging"></a>bagging</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_165239_23.png" alt="20200426_165239_23"></p>
<p>使得小数据样本的下的训练更加客观，鲁棒，不会受一些特别数据的影响。</p>
<h2 id="bootstrap"><a href="#bootstrap" class="headerlink" title="bootstrap"></a>bootstrap</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_165658_60.png" alt="20200426_165658_60"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_165709_70.png" alt="20200426_165709_70"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_180100_69.png" alt="20200426_180100_69"></p>
<p>除了训练集上的采样，也可以对特征sampling。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_180649_99.png" alt="20200426_180649_99"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_181115_59.png" alt="20200426_181115_59"></p>
<p>最后的三个项分别噪声(没法降低)，偏差，方差。</p>
<h1 id="树模型总结"><a href="#树模型总结" class="headerlink" title="树模型总结"></a>树模型总结</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_181455_86.png" alt="20200426_181455_86"></p>
<p>树模型不是在参数空间进行的模型，而是泛函空间，通过改变树的结构来训练模型，本质上loss也不是一个东西，一个是通过梯度求解的，树则是通过不断分割节点计算loss。</p>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_182353_46.png" alt="20200426_182353_46"></p>
<p>协方差矩阵的求解，得到b要大，ρ要小的指导思想，可知bagging tree往往不能使得ρ降低。</p>
<p>虽然通过bootstrap可以使得训练集的分布不太一样，但是树本身还是比较鲁棒的，没有很好的降低相关度</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_182858_70.png" alt="20200426_182858_70"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_183027_83.png" alt="20200426_183027_83"></p>
<h1 id="bagging-VS-随机森林-VS-Bootsing"><a href="#bagging-VS-随机森林-VS-Bootsing" class="headerlink" title="bagging VS 随机森林 VS Bootsing"></a>bagging VS 随机森林 VS Bootsing</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_183231_85.png" alt="20200426_183231_85"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_183341_47.png" alt="20200426_183341_47"></p>
<h1 id="广义加性模型"><a href="#广义加性模型" class="headerlink" title="广义加性模型"></a>广义加性模型</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_183918_73.png" alt="20200426_183918_73"></p>
<p>以上一次的m个模型集合一起的输出与上个模型的结果做差作为这个模型的label</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_213730_96.png" alt="20200426_213730_96"></p>
<h1 id="Adaboost"><a href="#Adaboost" class="headerlink" title="Adaboost"></a>Adaboost</h1><h2 id="学习准则"><a href="#学习准则" class="headerlink" title="学习准则"></a>学习准则</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_214320_93.png" alt="20200426_214320_93"></p>
<p>区别是多了1和log  ，指数准则和对数似然(交叉熵)在二阶泰勒级数上是等价的</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_214520_35.png" alt="20200426_214520_35"></p>
<p>区别是多了一个1/2</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_214629_11.png" alt="20200426_214629_11"></p>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_215324_64.png" alt="20200426_215324_64"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_215329_88.png" alt="20200426_215329_88"></p>
<p>相当于max精准度，因为y和fx同号</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_215535_74.png" alt="20200426_215535_74"></p>
<p>目标同上</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_215932_28.png" alt="20200426_215932_28"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_220216_21.png" alt="20200426_220216_21"></p>
<p>根据c和err关系公式你可以看到，如果一个模型的c显著高于其他模型，那这个模型的err就很接近于0了，那这个时候确实应该让这个模型“一家独大”，dominate其他模型。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_220241_86.png" alt="20200426_220241_86"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_220354_41.png" alt="20200426_220354_41"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_220429_49.png" alt="20200426_220429_49"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_225340_74.png" alt="20200426_225340_74"></p>
<h1 id="提升算法简史"><a href="#提升算法简史" class="headerlink" title="提升算法简史"></a>提升算法简史</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_221212_92.png" alt="20200426_221212_92"></p>
<p>其实和svm一样，统计学习中都是说如何使得边界间隔最大</p>
<h1 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_221405_42.png" alt="20200426_221405_42"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_221641_22.png" alt="20200426_221641_22"></p>
<p>多一棵树模型变得复杂当然要加一个惩罚项</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_221933_99.png" alt="20200426_221933_99"></p>
<p>就是对两个梯度进行优化，可以理解为在梯度方向上长一棵树，最小化j</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_222207_83.png" alt="20200426_222207_83"></p>
<p>叶子数要少，且w不能太大(要不与深度加深同步的是假设性太强)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_222522_86.png" alt="20200426_222522_86"></p>
<p>二次优化问题，没有c是因为树沿着梯度方向走已经学出来了最优值</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_222636_59.png" alt="20200426_222636_59"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_223007_44.png" alt="20200426_223007_44"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_223100_85.png" alt="20200426_223100_85"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_224932_24.png" alt="20200426_224932_24"></p>
<h1 id="深度森林"><a href="#深度森林" class="headerlink" title="深度森林"></a>深度森林</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_101221_77.png" alt="20200503_101221_77"></p>
<p>DNNs成功的关键：庞大的训练数据(减小过拟合),高效的算力机器，训练技巧(一般的多层网络反串的时候多层会发散)</p>
<p>dnn的关键：逐层处理，特征变换，足够的模型复杂度</p>
<p>dnn就是在中间学习多层的Representation(逐层学习)，而一般的机器学习是就数据那层</p>
<p>dnn&amp;&amp;kernel matrix：统计学习的本质就是学习相似度，kernel matrix在svm中是直接给出了定义的函数映射，而dnn中是通过学习到效果较好的kernel matrix</p>
<p>与树模型的对比：树模型连简单的线性旋转也没做到</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_103543_22.png" alt="20200503_103543_22"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104010_82.png" alt="20200503_104010_82"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104335_94.png" alt="20200503_104335_94"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_224603_55.png" alt="20200505_224603_55"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_224811_98.png" alt="20200505_224811_98"></p>
<h2 id="多粒度级联森林-gcforest"><a href="#多粒度级联森林-gcforest" class="headerlink" title="多粒度级联森林(gcforest)"></a>多粒度级联森林(gcforest)</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104543_39.png" alt="20200503_104543_39"></p>
<p>集成学习：个体存在差异，个体不能太差</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104719_31.png" alt="20200503_104719_31"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104833_21.png" alt="20200503_104833_21"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_105048_88.png" alt="20200503_105048_88"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_105353_67.png" alt="20200503_105353_67"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_105533_36.png" alt="20200503_105533_36"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_105441_65.png" alt="20200503_105441_65"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_110311_74.png" alt="20200503_110311_74"></p>
<p>gcforest所有数据都用相同的超参数，但是在图像上可能还是不太行，因为树模型本身的曲线就是不光滑的(阶梯)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_110716_95.png" alt="20200503_110716_95"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_110911_30.png" alt="20200503_110911_30"></p>
<h1 id="排序与过滤"><a href="#排序与过滤" class="headerlink" title="排序与过滤"></a>排序与过滤</h1><h1 id="学习排序"><a href="#学习排序" class="headerlink" title="学习排序"></a>学习排序</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_111824_15.png" alt="20200503_111824_15"></p>
<p>可导是必要条件</p>
<p>信息检索(IR)是从信息集合中获取用户所需要的有关信息的过程。两个关键：检索候选文档，对检索文档排序</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_112543_66.png" alt="20200503_112543_66"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113043_42.png" alt="20200503_113043_42"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113121_83.png" alt="20200503_113121_83"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113243_90.png" alt="20200503_113243_90"></p>
<h1 id="排序方法"><a href="#排序方法" class="headerlink" title="排序方法"></a>排序方法</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113633_44.png" alt="20200503_113633_44"></p>
<h2 id="pointwise"><a href="#pointwise" class="headerlink" title="pointwise"></a>pointwise</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113826_44.png" alt="20200503_113826_44"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113935_91.png" alt="20200503_113935_91"></p>
<h2 id="pairwise"><a href="#pairwise" class="headerlink" title="pairwise"></a>pairwise</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_114236_19.png" alt="20200503_114236_19"></p>
<p>不在讨论q&amp;d的labels了，而是直接讨论谁应该在前面</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_114426_77.png" alt="20200503_114426_77"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_195206_49.png" alt="20200505_195206_49"></p>
<p>缺点：每个文档都被认为具有相同的重要性，但是实际情况上前面的重要性和后面的重要性是不同的。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_195749_94.png" alt="20200505_195749_94"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_200011_64.png" alt="20200505_200011_64"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_200115_54.png" alt="20200505_200115_54"></p>
<h2 id="Listwise"><a href="#Listwise" class="headerlink" title="Listwise"></a>Listwise</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_200824_31.png" alt="20200505_200824_31"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_200923_31.png" alt="20200505_200923_31"></p>
<h2 id="LambdaRank"><a href="#LambdaRank" class="headerlink" title="LambdaRank"></a>LambdaRank</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201036_71.png" alt="20200505_201036_71"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201443_51.png" alt="20200505_201443_51"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201510_56.png" alt="20200505_201510_56"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201624_78.png" alt="20200505_201624_78"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201711_98.png" alt="20200505_201711_98"></p>
<h2 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201847_17.png" alt="20200505_201847_17"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_224916_36.png" alt="20200505_224916_36"></p>
<p>与传统的二分类有什么区别呢？二分类label与label之间没关系，排序label之间有相关性。如ABC(ground truth)和ACB的分数会比较高。</p>
<h1 id="个性化推荐"><a href="#个性化推荐" class="headerlink" title="个性化推荐"></a>个性化推荐</h1><p>与信息检索的区别是没有用户的查询，操作基于用户画像。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_202845_47.png" alt="20200505_202845_47"></p>
<p>协同过滤是跨维度的。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_203112_35.png" alt="20200505_203112_35"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_203612_98.png" alt="20200505_203612_98"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_203935_35.png" alt="20200505_203935_35"></p>
<p>皮尔森那里，减去平均值可以区分一些喜欢打高分和低分的用户</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_204143_50.png" alt="20200505_204143_50"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_204426_57.png" alt="20200505_204426_57"></p>
<p>xa指的是先验的用户，xu指的是目标用户</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_204533_11.png" alt="20200505_204533_11"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_204725_32.png" alt="20200505_204725_32"></p>
<p>大训练集比较好，K取30的时候效果最好</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_205032_65.png" alt="20200505_205032_65"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_205052_50.png" alt="20200505_205052_50"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_205148_44.png" alt="20200505_205148_44"></p>
<h1 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_205356_61.png" alt="20200505_205356_61"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_211617_84.png" alt="20200505_211617_84"></p>
<p>KNN，高斯过程</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_220605_39.png" alt="20200505_220605_39"></p>
<h1 id="概率图模型"><a href="#概率图模型" class="headerlink" title="概率图模型"></a>概率图模型</h1><p>数据科学的目的就是构建数据的联合分布，然后根据联合分布求求出想要知道的条件分布，但是问题就是我们如果直接根据数据本身求联合概率分布，复杂度很高，所以这里引入了概率图模型，也就是通过一些先验知识对features之间的关系做一些限制。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095146_17.png" alt="20200507_095146_17"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095225_16.png" alt="20200507_095225_16"></p>
<h1 id="贝叶斯网络-有向图"><a href="#贝叶斯网络-有向图" class="headerlink" title="贝叶斯网络(有向图)"></a>贝叶斯网络(有向图)</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095353_26.png" alt="20200507_095353_26"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095533_44.png" alt="20200507_095533_44"></p>
<p>如果是一般的联合概率分布求法是全连接图，计算复杂度也大大增加。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095812_47.png" alt="20200507_095812_47"></p>
<p>首先假设xi是符合某种先验的分布的，然后根据先验分布下的x去求取label，最后把所有的xi连乘起来(独立)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_100248_59.png" alt="20200507_100248_59"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_100402_65.png" alt="20200507_100402_65"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_100458_74.png" alt="20200507_100458_74"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_100905_53.png" alt="20200507_100905_53"></p>
<p>前半段训练(推断所有random variable的后验分布)，后面是预测。边缘化即积掉隐变量</p>
<h1 id="概率图模型的条件独立"><a href="#概率图模型的条件独立" class="headerlink" title="概率图模型的条件独立"></a>概率图模型的条件独立</h1><p>上图式子的连乘的前提条件是独立</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101347_86.png" alt="20200507_101347_86">   </p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101611_24.png" alt="20200507_101611_24"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101618_35.png" alt="20200507_101618_35"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101625_17.png" alt="20200507_101625_17"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101637_44.png" alt="20200507_101637_44"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101645_12.png" alt="20200507_101645_12"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101653_49.png" alt="20200507_101653_49"></p>
<p>head to head 知道的node发生变化，则概率也在发生变化：：explaining away</p>
<h2 id="有向分离"><a href="#有向分离" class="headerlink" title="有向分离"></a>有向分离</h2><p>只通过图模型，就判断谁和谁是独立的。A和B的所有路径都被阻断了</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_112840_26.png" alt="20200507_112840_26"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113144_82.png" alt="20200507_113144_82"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113308_52.png" alt="20200507_113308_52"></p>
<h2 id="独立同分布"><a href="#独立同分布" class="headerlink" title="独立同分布"></a>独立同分布</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113408_11.png" alt="20200507_113408_11"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113554_81.png" alt="20200507_113554_81"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113837_65.png" alt="20200507_113837_65"></p>
<p>α是拉普拉斯平滑因子，防止为0</p>
<h1 id="马尔可夫网络-无向图"><a href="#马尔可夫网络-无向图" class="headerlink" title="马尔可夫网络(无向图)"></a>马尔可夫网络(无向图)</h1><p>某个random variable的周围邻居全部被阻塞了，则这个也确定下来了</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_114138_32.png" alt="20200507_114138_32"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_114240_28.png" alt="20200507_114240_28"></p>
<p>团内两两连接</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_114416_51.png" alt="20200507_114416_51"></p>
<ul>
<li>势函数需要&gt;=0，确保概率为非负数</li>
<li>势函数可以用领域知识定义，相当于贝叶斯的，conditional distribution</li>
</ul>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_114823_52.png" alt="20200507_114823_52"></p>
<p>能量高的时候，势比较低。也就是能量高就越不稳定，就越难保持在原地。概率也就越低</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115020_23.png" alt="20200507_115020_23"></p>
<p>温度很高，处于混沌状态那么ps也就等于1/|s|(所有的state取平均)</p>
<h1 id="马尔可夫网络实例"><a href="#马尔可夫网络实例" class="headerlink" title="马尔可夫网络实例"></a>马尔可夫网络实例</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115316_93.png" alt="20200507_115316_93"></p>
<p>这里取负数，联想玻尔兹曼分布</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115327_13.png" alt="20200507_115327_13"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115337_20.png" alt="20200507_115337_20"></p>
<h1 id="马尔可夫-Vs-贝叶斯"><a href="#马尔可夫-Vs-贝叶斯" class="headerlink" title="马尔可夫 Vs 贝叶斯"></a>马尔可夫 Vs 贝叶斯</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115727_97.png" alt="20200507_115727_97"></p>
<p>1234成为了一个团</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115833_14.png" alt="20200507_115833_14"></p>
<p>两者的conditional independence绝大多是可以共同表示出来，但是还是存在一些不能同时表示出来的。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_120120_91.png" alt="20200507_120120_91"></p>
<p>图1 如果变成了无向图之后，分布变得更加广阔了。</p>
<h1 id="链式模型推断"><a href="#链式模型推断" class="headerlink" title="链式模型推断"></a>链式模型推断</h1><p>就是给了任意图结构之后，去推断出边缘分布</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_120726_84.png" alt="20200507_120726_84"></p>
<p>频率派是参数估计(parameter estimation)，也就是通过最小或最大loss方程来更新参数。而贝叶斯派则是推断新的分布(variable inference)，也就是通过更新更优的分布，对认知的升级。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_121105_60.png" alt="20200507_121105_60"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_121208_57.png" alt="20200507_121208_57"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_121353_19.png" alt="20200507_121353_19"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_121646_89.png" alt="20200507_121646_89"></p>
<p>横向动态规划</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122110_13.png" alt="20200507_122110_13"></p>
<p>z不用求了。计算条件分布的时候会除掉</p>
<h1 id="树图模型推断"><a href="#树图模型推断" class="headerlink" title="树图模型推断"></a>树图模型推断</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122310_72.png" alt="20200507_122310_72"></p>
<p>13根节点的确定是随意的。提起来就是一棵树</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122506_59.png" alt="20200507_122506_59"></p>
<p>因为树有交叉，所以不能用消息传递，一个factor指向同一个x相当于计算一种x的势函数。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122645_83.png" alt="20200507_122645_83"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122719_66.png" alt="20200507_122719_66"></p>
<p>factor和random variable只于彼此相连，因子图通过为因子引入额外的节点来进行显式分解</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122941_57.png" alt="20200507_122941_57"></p>
<p>和消息传递类似，就是根据要的random variable，与他相连的所有factor开始加和他们的子节点(子节点可能会遇到factor的话就连乘)，最后连乘所有与他相连的factor(message 就是加和关系，function就是连乘)，message就是被隐藏掉的所有random variable的加和</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_123147_89.png" alt="20200507_123147_89"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124001_76.png" alt="20200507_124001_76"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124224_87.png" alt="20200507_124224_87"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124355_52.png" alt="20200507_124355_52"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124458_91.png" alt="20200507_124458_91"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124637_53.png" alt="20200507_124637_53"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124909_74.png" alt="20200507_124909_74"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_125019_20.png" alt="20200507_125019_20"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_125206_27.png" alt="20200507_125206_27"></p>
<p>sum product算法</p>
<h1 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h1><p>贝叶斯派比较于频率派，是白盒模型，而且往往需要较少的样本就可以得到不错效果，但是确定在于他求条件概率的时候的对于w一些积分是没有显式解的，通常就是使用一些sample w的方法或者定义他符合某个分布(高斯)去拟合他。结果就是思维elegant，解法比较随意。 也就是问题所在，思想很高，但是落地很难</p>
<h1 id="论坛：强化学习"><a href="#论坛：强化学习" class="headerlink" title="论坛：强化学习"></a>论坛：强化学习</h1><p>环境也会因为上一步的决策行为发生改变</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_084904_10.png" alt="20200513_084904_10"></p>
<p>序列决策：多步决策，直到从长远看，效率奖励最大化 。单步的决策和预测任务没区别</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_085437_68.png" alt="20200513_085437_68"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_085557_20.png" alt="20200513_085557_20"></p>
<p>一般的预测问题是通过一个model利用给好的数据去训练一个分布，强化学习使用agent，原本是没有数据的，但是agent与环境进行交互产生数据，用此数据去训练。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_090034_02.png" alt="20200513_090034_02"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_090218_50.png" alt="20200513_090218_50"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_090319_70.png" alt="20200513_090319_70"></p>
<p>对未来的guess更新当前的价值估计</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_090833_41.png" alt="20200513_090833_41"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_091132_88.png" alt="20200513_091132_88"></p>
<p>价值相当于老师or评论家，策略相当于学生</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_091428_79.png" alt="20200513_091428_79"></p>
<p>一般很难用表格表达(连续)，所以使用一些参数化的函数的近似</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_091841_81.png" alt="20200513_091841_81"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_091936_91.png" alt="20200513_091936_91"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_092141_54.png" alt="20200513_092141_54"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_092223_47.png" alt="20200513_092223_47"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_092438_57.png" alt="20200513_092438_57"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_092605_15.png" alt="20200513_092605_15"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_092730_82.png" alt="20200513_092730_82"></p>
<p>不知道奖励如何定义，有先验的专家示范，先学习这个，然后再自博弈</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_093002_52.png" alt="20200513_093002_52"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_093016_52.png" alt="20200513_093016_52"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_093206_99.png" alt="20200513_093206_99"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_093417_60.png" alt="20200513_093417_60"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200513_093849_48.png" alt="20200513_093849_48"></p>
<p>让Ai做完一切事情，而不仅仅是辅助</p>
<h1 id="无监督学习简介"><a href="#无监督学习简介" class="headerlink" title="无监督学习简介"></a>无监督学习简介</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_102002_13.png" alt="20200519_102002_13"></p>
<p>无监督学习构建联合分布然后再推断条件概率分布。而有监督学习则是通过已有的标签取构建条件分布。因为模型的容量是有限的，所以针对于后者，前者的对于特定标签的精度也是较低的。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_102459_55.png" alt="20200519_102459_55"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_221352_98.png" alt="20200519_221352_98"></p>
<p>一般的工程师是先可视化数据，观察到一些特性，再选择特定的模型，数据初始化</p>
<h1 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_221544_19.png" alt="20200519_221544_19"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_221627_90.png" alt="20200519_221627_90"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_221754_33.png" alt="20200519_221754_33"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_221924_68.png" alt="20200519_221924_68"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_222012_60.png" alt="20200519_222012_60"></p>
<p>一个方向是，选择每一步选择最远的点</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_222228_65.png" alt="20200519_222228_65"></p>
<h1 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h1><p>降维</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_222334_33.png" alt="20200519_222334_33"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_222415_35.png" alt="20200519_222415_35"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_222517_97.png" alt="20200519_222517_97"></p>
<p>使得大家都在一个标准上</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_222558_13.png" alt="20200519_222558_13"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_222709_47.png" alt="20200519_222709_47"></p>
<p>标准正交基</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_222941_36.png" alt="20200519_222941_36"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_223001_27.png" alt="20200519_223001_27"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_223306_22.png" alt="20200519_223306_22"></p>
<p>满秩</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_223508_24.png" alt="20200519_223508_24"></p>
<p>ui对应方向的特征值就是数据在ui方向投影后的方差</p>
<h1 id="混合高斯模型的EM算法"><a href="#混合高斯模型的EM算法" class="headerlink" title="混合高斯模型的EM算法"></a>混合高斯模型的EM算法</h1><p>Kmeans没有考虑到数据分布的形状</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_224705_49.png" alt="20200519_224705_49"></p>
<p>考虑到了均值和方差</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_225007_99.png" alt="20200519_225007_99"></p>
<p>基于隐变量模型重建分布</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_225052_84.png" alt="20200519_225052_84"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_225131_69.png" alt="20200519_225131_69"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_225237_86.png" alt="20200519_225237_86"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_225344_39.png" alt="20200519_225344_39"></p>
<p>不断上升</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_225522_77.png" alt="20200519_225522_77"></p>
<p>E更新weight，M更新利用权重每个高斯参数</p>
<p>给定每个x，然后明确由几个高斯，不断迭代得到高斯之前的分布，高斯A和B采数据的权重</p>
<h1 id="通用EM算法"><a href="#通用EM算法" class="headerlink" title="通用EM算法"></a>通用EM算法</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_225943_40.png" alt="20200519_225943_40"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_230139_86.png" alt="20200519_230139_86"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_230330_56.png" alt="20200519_230330_56"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_230416_45.png" alt="20200519_230416_45"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_230546_44.png" alt="20200519_230546_44"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_230844_92.png" alt="20200519_230844_92"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_230907_33.png" alt="20200519_230907_33"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_231133_90.png" alt="20200519_231133_90"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_231303_14.png" alt="20200519_231303_14"></p>
<p>E-step到时候构建一个分布使得在那一点上与分布相切，然后当点发生变化的时候，重复上述过程</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_231451_64.png" alt="20200519_231451_64"></p>
<h1 id="传统无监督总结"><a href="#传统无监督总结" class="headerlink" title="传统无监督总结"></a>传统无监督总结</h1><p>帮助我们更好理解数据，提出一些模型，帮助模型做更好数据的表征还有初始化，更好理解有监督，降低数据量。</p>
<p>聚类把instance捏在一起，降维把dimension捏在一起</p>
<p>隐变量从本质上全是数据的结构化信息</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_232012_86.png" alt="20200519_232012_86"></p>
<h1 id="生成式对抗网络"><a href="#生成式对抗网络" class="headerlink" title="生成式对抗网络"></a>生成式对抗网络</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_232732_79.png" alt="20200519_232732_79"></p>
<p>通过qx生成数据x</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_233015_34.png" alt="20200519_233015_34"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_233049_19.png" alt="20200519_233049_19"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_233240_73.png" alt="20200519_233240_73"></p>
<p>px的数据分布往往是很奇奇怪怪的，用高斯很难拟合出来。频率派的可以</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_233413_76.png" alt="20200519_233413_76"></p>
<p>确定的映射变成分布：加噪声。不需要反推</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_233440_53.png" alt="20200519_233440_53"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_233548_57.png" alt="20200519_233548_57"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_233713_36.png" alt="20200519_233713_36"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_233904_50.png" alt="20200519_233904_50"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_234010_12.png" alt="20200519_234010_12"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_234137_30.png" alt="20200519_234137_30"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_234249_58.png" alt="20200519_234249_58"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_234510_79.png" alt="20200519_234510_79"></p>
<p>必须是连续数据。文本就要再想办法。rl？</p>
<h1 id="限制玻尔兹曼机简介"><a href="#限制玻尔兹曼机简介" class="headerlink" title="限制玻尔兹曼机简介"></a>限制玻尔兹曼机简介</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_235038_77.png" alt="20200519_235038_77"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_235152_87.png" alt="20200519_235152_87"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_235633_61.png" alt="20200519_235633_61"></p>
<p>每一值都独立同分布</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200519_235833_18.png" alt="20200519_235833_18"></p>
<p>采样与反采样</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200520_000025_30.png" alt="20200520_000025_30"></p>
<p>子节点未知的情况，是独立同分布的，概率图模型那里</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200520_000253_23.png" alt="20200520_000253_23"></p>
<p>去掉了h的影响，输入v就可以求出来，sum-produce</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200520_000446_68.png" alt="20200520_000446_68"></p>
<p>基于v可以sample h，hsample完之后返回来又可以生成v</p>
<p>生成环节用于图像修复，风格转换</p>
<h1 id="RBM学习算法"><a href="#RBM学习算法" class="headerlink" title="RBM学习算法"></a>RBM学习算法</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_103627_84.png" alt="20200526_103627_84"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_104008_33.png" alt="20200526_104008_33"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_104220_71.png" alt="20200526_104220_71"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_104527_10.png" alt="20200526_104527_10"></p>
<p>只需要直到n-1各点，就能推测出n点</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_104815_13.png" alt="20200526_104815_13"></p>
<p>每一步，梯度方向不一定是准的，但是至少是沿着方向的锐角进行，所以会收敛。</p>
<h1 id="深度信念网络-1"><a href="#深度信念网络-1" class="headerlink" title="深度信念网络"></a>深度信念网络</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_105148_17.png" alt="20200526_105148_17"></p>
<p>降维，升维</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_105629_95.png" alt="20200526_105629_95"></p>
<p>先unroll出来不错的照片，然后在fine-tuning阶段去训练模型，因为是微调，所以梯度消失的问题也不太严重了。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_105747_33.png" alt="20200526_105747_33"></p>
<p>pca是线性的映射，导致重叠在一起</p>
<h1 id="自动编码器"><a href="#自动编码器" class="headerlink" title="自动编码器"></a>自动编码器</h1><p>类似于DBN，但是训练方式更暴力</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_110016_63.png" alt="20200526_110016_63"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_133009_49.png" alt="20200526_133009_49"></p>
<p>到后来，因为有很多针对于网络深度的BP的解决方案了，DBN也就慢慢退出舞台了。Auto encoder可以通过其他技术去实现</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_133349_37.png" alt="20200526_133349_37"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_133549_61.png" alt="20200526_133549_61"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_133621_31.png" alt="20200526_133621_31"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_134237_32.png" alt="20200526_134237_32"></p>
<p>白盒模型能写出来参数，可视化，但是往往是有很多假设，脱离的实际的情况。黑盒模型的分布可以更多样化，但你往往就难以表示</p>
<h1 id="学习理论"><a href="#学习理论" class="headerlink" title="学习理论"></a>学习理论</h1><p>针对于当前问题，我的模型要做的有多复杂</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_142338_65.png" alt="20200526_142338_65"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_142448_43.png" alt="20200526_142448_43"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_142656_84.png" alt="20200526_142656_84"></p>
<h1 id="偏差-方差分解"><a href="#偏差-方差分解" class="headerlink" title="偏差-方差分解"></a>偏差-方差分解</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_222145_39.png" alt="20200526_222145_39"></p>
<p>偏差来源于数据分布，参数，标签  ， bias underfitting 模型过于简单，与结果产生偏差， var overfitting  模型过于复杂，导致自己本身就会有很大震荡。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_222513_23.png" alt="20200526_222513_23"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_222629_15.png" alt="20200526_222629_15"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_222919_20.png" alt="20200526_222919_20"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_223221_54.png" alt="20200526_223221_54"></p>
<p>在测试的时候，通过偏差的增大，减小了方差，trend off</p>
<h1 id="假设空间ERM边界"><a href="#假设空间ERM边界" class="headerlink" title="假设空间ERM边界"></a>假设空间ERM边界</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_223403_53.png" alt="20200526_223403_53"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_223636_13.png" alt="20200526_223636_13"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_223757_26.png" alt="20200526_223757_26"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_223941_51.png" alt="20200526_223941_51"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_224222_62.png" alt="20200526_224222_62"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_224303_19.png" alt="20200526_224303_19"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_224439_43.png" alt="20200526_224439_43"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_224636_94.png" alt="20200526_224636_94"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_224812_58.png" alt="20200526_224812_58"></p>
<p>样本数-参数数-特征数</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_224922_14.png" alt="20200526_224922_14"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_225013_26.png" alt="20200526_225013_26"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_225455_45.png" alt="20200526_225455_45"></p>
<p>在推荐系统里，往往不会说弄到很复杂的模型，更在乎的是在更少的时间内使用更多的特征。</p>
<h1 id="VC维"><a href="#VC维" class="headerlink" title="VC维"></a>VC维</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_225732_82.png" alt="20200526_225732_82"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_230238_10.png" alt="20200526_230238_10"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_230309_23.png" alt="20200526_230309_23"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_230441_53.png" alt="20200526_230441_53"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_230721_32.png" alt="20200526_230721_32"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_230821_99.png" alt="20200526_230821_99"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_230907_52.png" alt="20200526_230907_52"></p>
<p>vc维比log更bend得住</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_231057_12.png" alt="20200526_231057_12"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_231210_80.png" alt="20200526_231210_80"></p>
<p>但是在神经网络中参数量往往会远大于数据量？</p>
<p>1.在0附近做random initialization才训练得好，分布是崎岖的，那么我走不了多远就停下来。虽然参数量，但走不远，很多参数都没有用  2.彩票假设定理：神经网络为什么可以work。网络中也包含着许多子网络(每层取部分节点)，那么我random initialization的话，就可以碰运气，会有一个子网络在local mini 。参数大，包含着指数级别的子网络，有一个买彩票买中了，网络就不会差。</p>
<h1 id="交叉验证-1"><a href="#交叉验证-1" class="headerlink" title="交叉验证"></a>交叉验证</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_232750_94.png" alt="20200526_232750_94"></p>
<p>往往轮数也是个超参。不断的训练就会overfit这个data了</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_232852_96.png" alt="20200526_232852_96"></p>
<h1 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_232929_34.png" alt="20200526_232929_34"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233023_65.png" alt="20200526_233023_65"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233051_67.png" alt="20200526_233051_67"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233209_37.png" alt="20200526_233209_37"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233242_73.png" alt="20200526_233242_73"></p>
<p>L1直接稀疏化，好处是提升了泛化误差，降低var，不要到一些local turn，noise data。提升了泛化性能</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233502_91.png" alt="20200526_233502_91"></p>
<p>无监督带来x的信息量取recover信息本身  有监督在乎信息量</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233553_41.png" alt="20200526_233553_41"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233645_16.png" alt="20200526_233645_16"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233803_94.png" alt="20200526_233803_94"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_233903_32.png" alt="20200526_233903_32"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200526_234155_59.png" alt="20200526_234155_59"></p>
<h1 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h1><p>解决序列性决策问题</p>
<p>预测是产生一个信号(脑海中的想法)，决策：做事情，会改变环境(多步问题)。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_181318_35.png" alt="20200602_181318_35"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_181336_15.png" alt="20200602_181336_15"></p>
<p>有监督，无监督：数据有限且不变。强化：动态环境。而且随着智能体的逻辑策略不同，交互得到的数据也是不同的。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_182138_86.png" alt="20200602_182138_86"></p>
<p>state可以如果已知，可以是给出的东西(棋盘)。否则，也可以是由前面的0R推断出来(利用一些网络，模型)。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_182252_45.png" alt="20200602_182252_45"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_182703_79.png" alt="20200602_182703_79"></p>
<p>奖励就像loss一样是标量，一维的，多维会产生冲突</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_182827_90.png" alt="20200602_182827_90"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_183424_72.png" alt="20200602_183424_72"></p>
<p>model-base需要构建policy和reward。</p>
<p>model free直接从data构建value和policy。纯试错。不知道规则</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_184037_07.png" alt="20200602_184037_07"></p>
<p>视觉的作用：是在于处理数据这块，把数据变成点云，模式识别等。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_184558_79.png" alt="20200602_184558_79"></p>
<p>DDPG</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_185053_37.png" alt="20200602_185053_37">   </p>
<h1 id="探索与利用"><a href="#探索与利用" class="headerlink" title="探索与利用"></a>探索与利用</h1><p>概率都不是确定的，中心极限定理告诉我们要尝试，探索。<br><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_211041_42.png" alt="20200602_211041_42"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_211526_16.png" alt="20200602_211526_16"></p>
<p>balance！实际场景的限制，优化longterm value意味着现在的value效益要降低。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_211849_55.png" alt="20200602_211849_55"></p>
<h2 id="多臂老虎机"><a href="#多臂老虎机" class="headerlink" title="多臂老虎机"></a>多臂老虎机</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_212126_48.png" alt="20200602_212126_48"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_212249_37.png" alt="20200602_212249_37"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_212334_59.png" alt="20200602_212334_59"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_212420_58.png" alt="20200602_212420_58"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_212712_40.png" alt="20200602_212712_40"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_212945_23.png" alt="20200602_212945_23"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_213028_52.png" alt="20200602_213028_52"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_213048_25.png" alt="20200602_213048_25"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_213159_61.png" alt="20200602_213159_61"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_214232_30.png" alt="20200602_214232_30"></p>
<p>Q值比reward更大，隐含信息就是鼓励探索。相当于一群人，都假定智商200，然后要多try才可以把每个人的信息降低到一个稳定的地方。try的少的Q大</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_214346_29.png" alt="20200602_214346_29"></p>
<p>平衡的时候还需要仅仅平均值是不够的</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_214832_92.png" alt="20200602_214832_92"></p>
<p>均值小，方差大或方差大，均值小</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_221804_34.png" alt="20200602_221804_34"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_222119_40.png" alt="20200602_222119_40"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_222650_38.png" alt="20200602_222650_38"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_223012_46.png" alt="20200602_223012_46"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_223304_70.png" alt="20200602_223304_70"></p>
<p>但不绝对说谁比较好，看情况，分布</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_223655_43.png" alt="20200602_223655_43"></p>
<p>无状态：外界的环境是不变的，reward只与action有关，与认知无关</p>
<h1 id="马尔可夫决策过程"><a href="#马尔可夫决策过程" class="headerlink" title="马尔可夫决策过程"></a>马尔可夫决策过程</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_224616_70.png" alt="20200602_224616_70"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_225004_25.png" alt="20200602_225004_25"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_225227_31.png" alt="20200602_225227_31"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_225452_15.png" alt="20200602_225452_15"></p>
<p>γ是防止智能体一直维持现状不变</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_225637_54.png" alt="20200602_225637_54"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_225724_37.png" alt="20200602_225724_37"></p>
<p>如何量化动态环境下的data？</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_230040_46.png" alt="20200602_230040_46"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_230405_42.png" alt="20200602_230405_42"></p>
<h2 id="MDP-基于动态规划的强化学习"><a href="#MDP-基于动态规划的强化学习" class="headerlink" title="MDP(基于动态规划的强化学习)"></a>MDP(基于动态规划的强化学习)</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_230556_43.png" alt="20200602_230556_43"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_230715_49.png" alt="20200602_230715_49"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_231030_12.png" alt="20200602_231030_12"></p>
<p>动态规划，根据未来的guess来更新</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_231120_15.png" alt="20200602_231120_15"></p>
<p>谁主谁辅？</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_231315_49.png" alt="20200602_231315_49"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_231454_26.png" alt="20200602_231454_26"></p>
<p>异步的更新可能会导致不稳定</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_231741_38.png" alt="20200602_231741_38"></p>
<p>价值迭代：快，没用策略的概念</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_231929_10.png" alt="20200602_231929_10"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_232019_34.png" alt="20200602_232019_34"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200602_232238_20.png" alt="20200602_232238_20"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_181817_52.png" alt="20200605_181817_52"></p>
<h1 id="基于模型的强化学习-model-base"><a href="#基于模型的强化学习-model-base" class="headerlink" title="基于模型的强化学习(model base)"></a>基于模型的强化学习(model base)</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_182538_20.png" alt="20200605_182538_20"></p>
<p>实际情况，难以得到转移概率和奖励函数，那么如何去构建这个函数呢？</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_182904_70.png" alt="20200605_182904_70"></p>
<p>可以通过一些参数化的模型去构建。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_183413_78.png" alt="20200605_183413_78"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_183448_82.png" alt="20200605_183448_82"></p>
<p>动态规划很敏感有许多max，如果，参数不是很精确的话，带来的解的差距很大。一般更多是直接用data产生的统计信息去拟合环境。(model-free)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_184036_31.png" alt="20200605_184036_31"></p>
<h1 id="模型无光强化学习"><a href="#模型无光强化学习" class="headerlink" title="模型无光强化学习"></a>模型无光强化学习</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_200619_89.png" alt="20200605_200619_89"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_200806_45.png" alt="20200605_200806_45"></p>
<p>通过data去recover 奖励与转移概率</p>
<h1 id="蒙特卡罗方法"><a href="#蒙特卡罗方法" class="headerlink" title="蒙特卡罗方法"></a>蒙特卡罗方法</h1><p>随机采样，通过大数定律去接近想要的结果</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200605_201058_42.png" alt="20200605_201058_42"></p>
<h2 id="蒙特卡罗价值预测"><a href="#蒙特卡罗价值预测" class="headerlink" title="蒙特卡罗价值预测"></a>蒙特卡罗价值预测</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_082948_58.png" alt="20200606_082948_58"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_083028_28.png" alt="20200606_083028_28"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_083205_66.png" alt="20200606_083205_66"></p>
<p>历史的Vs的重要性降低</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_083429_43.png" alt="20200606_083429_43"></p>
<p>过程无限，不sample到最后得不到精准的Gt</p>
<h1 id="重要性采样"><a href="#重要性采样" class="headerlink" title="重要性采样"></a>重要性采样</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_083704_62.png" alt="20200606_083704_62"></p>
<p>trick：sample px难度比较大，可以从另一个分布sample</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_083910_89.png" alt="20200606_083910_89"></p>
<p>通过历史policy得到的data来反inference现在的policy的Gt</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_084329_54.png" alt="20200606_084329_54"></p>
<p>是无偏估计，但是当qx过小的时候会导致方差变大。一个instance就可以抵掉很多数据</p>
<p>方法是是牺牲bias，限制variance。策略1：将比值加上上界的约束</p>
<p>策略2：只看t+1一步，不是多步连乘，得到一个比例的话，影响就很小，</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_084812_96.png" alt="20200606_084812_96"></p>
<h1 id="时序差分学习"><a href="#时序差分学习" class="headerlink" title="时序差分学习"></a>时序差分学习</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_084901_53.png" alt="20200606_084901_53"></p>
<p>只需要知道一个四元组，就可以进行碎片化学习，自举法</p>
<h2 id="MC-VS-TD"><a href="#MC-VS-TD" class="headerlink" title="MC VS TD"></a>MC VS TD</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_085059_26.png" alt="20200606_085059_26"></p>
<p>MC就相当于每次在分布上取一个点，作为期望，但是由于他会不断趋近，值也会越来越好，达到动态平衡。</p>
<p>TD信息量来源于reward，误差值只于一个变量有关</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_085450_65.png" alt="20200606_085450_65"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_085539_98.png" alt="20200606_085539_98"></p>
<p>TDlocally 学习，作用范围超过MC，他们的关系就相当于SGD，BGD</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_085701_60.png" alt="20200606_085701_60"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_085919_50.png" alt="20200606_085919_50"></p>
<p>初始值不一样，收敛的就不一样，因为有bias</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_090050_33.png" alt="20200606_090050_33"></p>
<p>MC会震荡，但是稳步下降，TD下降很快，但是后期会上升，有bias。SGD 。BGD</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_090247_39.png" alt="20200606_090247_39"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_090309_29.png" alt="20200606_090309_29"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_090333_49.png" alt="20200606_090333_49"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_090350_19.png" alt="20200606_090350_19"></p>
<p>多步的时序差分。相当于两者的权衡。</p>
<h1 id="SARSA"><a href="#SARSA" class="headerlink" title="SARSA"></a>SARSA</h1><p>前文是做value的估计，提升policy</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_090653_67.png" alt="20200606_090653_67"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_090730_68.png" alt="20200606_090730_68"></p>
<p>v相当于多个sample，我取一个就是Q，通过这种方式，只需要维护一种Q就可以一步greedy得到policy。之前还需要考虑探索。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_091012_40.png" alt="20200606_091012_40"></p>
<p>on policy是从刚刚得到的policy马上交互学习，得到data继续更新，但是很难实现，保持时刻交互</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_091204_46.png" alt="20200606_091204_46"></p>
<h1 id="Q"><a href="#Q" class="headerlink" title="Q"></a>Q</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_091259_49.png" alt="20200606_091259_49"></p>
<p>Vs需要考虑policy，取得什么，Qsa就只考虑一个action，贪心策略就只考虑一个argmax，而Vs要分析现在状态在什么地方，用到环境的转移概率，这点难以计算，除非用一些模型去建模出来。</p>
<p>SARSA更新只用最新的，对数据利用率很低，Q变了data就不能用了。除非加上重要性采样</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_091718_91.png" alt="20200606_091718_91"></p>
<p>off policy为什么重要？on plicy更多在于实验室环境下，实际环境下，出现的新数据，数据量低，也没有这么好的model，不足以训练。大部分落地都是离线的。不断通过各种policy采样一堆data，再用这堆data训练一个新升级的policy，然后部署，产生更多data。不够好的policy不敢放到实际环境交互得到data。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_091829_27.png" alt="20200606_091829_27"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_092218_28.png" alt="20200606_092218_28"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_092522_66.png" alt="20200606_092522_66"><br>follow当前的Q选择使得Q最大at+1,没有和历史的policy做交互，就不需要重要性采样。利用历史的data和现在的环境得到一个四元组</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_092749_52.png" alt="20200606_092749_52"></p>
<h2 id="收敛性证明"><a href="#收敛性证明" class="headerlink" title="收敛性证明"></a>收敛性证明</h2><p>数列的收敛<br><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_092857_84.png" alt="20200606_092857_84"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_092908_88.png" alt="20200606_092908_88"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_092918_28.png" alt="20200606_092918_28"></p>
<p>一直取max，但是没有到无穷</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_092956_94.png" alt="20200606_092956_94"></p>
<h1 id="总结-4"><a href="#总结-4" class="headerlink" title="总结"></a>总结</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_093232_26.png" alt="20200606_093232_26"></p>
<p>SARSA更加安全，QLearning更激进，探索的时候会有一个概率掉下去。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200606_093522_22.png" alt="20200606_093522_22"></p>
<p>off policy使得模型训练好了再与实际环境交互。DRL刚出来的时候，大都时model free，通过policy，交互产生data，直接训练，得到提升的policy，再采data再训练。不需要刻画，只是通过大量数据avg。19.18年发现RL数据使用率太低了，回到模型，通过data搭建模型得到更多data，降低了在真实世界sample data的比率，反而提高了真实数据的数据利用率</p>
<h1 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h1><p>迁移学习本质区别就是source domina和target dominant是否一样。否则就是传统机器学习</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_203147_85.png" alt="20200613_203147_85"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_203255_22.png" alt="20200613_203255_22"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_203828_56.png" alt="20200613_203828_56"></p>
<p>传统机器学习在不同的task使用不同数据集训练不同的label，然后在各自的数据分布上做测试。</p>
<p>迁移学习source tasks(大的数据集)，训练model或者表征，得到knowledge。通过原问题上的knowledge，帮助target task得到提升</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_203957_89.png" alt="20200613_203957_89"></p>
<p>唯一的指标是在target上的表现，并不关心source task的表现</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_204252_62.png" alt="20200613_204252_62"></p>
<p>大部分论文在同构迁移学习上， 也就是映射不同。异构的方法论不如同构的泛化性强，可共享。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_204618_40.png" alt="20200613_204618_40"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_204735_84.png" alt="20200613_204735_84"></p>
<h1 id="示例迁移"><a href="#示例迁移" class="headerlink" title="示例迁移"></a>示例迁移</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_205121_61.png" alt="20200613_205121_61"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_205152_98.png" alt="20200613_205152_98"></p>
<p>space基本一样，分布不太一样</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_205321_48.png" alt="20200613_205321_48"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_205556_84.png" alt="20200613_205556_84"></p>
<p>数据分布不一样，可以用重要性采样(一切模型都可以)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_205711_74.png" alt="20200613_205711_74"></p>
<p>分开估计会有很大的gap</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_210210_69.png" alt="20200613_210210_69"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_211708_57.png" alt="20200613_211708_57"></p>
<p>相当于抽feature 去训练一个判断的模型。为啥用一个模型比两个模型相除来得好呢？因为一个模型拥有一定的联系性。不会x变一点点 ，pt差距极大</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_212337_66.png" alt="20200613_212337_66"></p>
<p>广告通过train的model出价，然后拿到赢下来的数据再训练一次model，但是这个model本身就是缺少loss的数据的，有偏差的。有偏的数据在训练，给广告出价，不团loop，一段时间后，模型就不能用了</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_212526_18.png" alt="20200613_212526_18"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_212619_50.png" alt="20200613_212619_50"></p>
<p>三赢</p>
<h2 id="示例二"><a href="#示例二" class="headerlink" title="示例二"></a>示例二</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_212704_65.png" alt="20200613_212704_65"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_212836_34.png" alt="20200613_212836_34"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_235612_62.png" alt="20200613_235612_62"></p>
<p>权重差距大，去规避这个instance。error大，关注的更多(adaboost)</p>
<h1 id="特征迁移"><a href="#特征迁移" class="headerlink" title="特征迁移"></a>特征迁移</h1><p>源域与目标域的特征映射到同一个空间上</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_213617_86.png" alt="20200613_213617_86"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_213800_20.png" alt="20200613_213800_20"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_213859_55.png" alt="20200613_213859_55"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_214201_91.png" alt="20200613_214201_91"></p>
<p>区分出来源域与目标域不同的隐因素，knowledge从share的隐因素上提取出来</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_214311_30.png" alt="20200613_214311_30"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_214454_47.png" alt="20200613_214454_47"></p>
<p>取得多个分布，然后将两个域同时映射到同一个分布上</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_214704_41.png" alt="20200613_214704_41"></p>
<h1 id="参数迁移"><a href="#参数迁移" class="headerlink" title="参数迁移"></a>参数迁移</h1><p>模型空间：根据源域模型学习目标域模型的参数，假定land scape 接近(差太远不行)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_231752_61.png" alt="20200613_231752_61"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_231859_20.png" alt="20200613_231859_20"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_233644_67.png" alt="20200613_233644_67"></p>
<p>和而不同</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_235526_48.png" alt="20200613_235526_48"></p>
<p>多任务在于每个task都要降低loss，每个任务都好，迁移在于将目标task任务的损失降低。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_235618_90.png" alt="20200613_235618_90"></p>
<h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_235811_14.png" alt="20200613_235811_14"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200613_235949_84.png" alt="20200613_235949_84"></p>
<h1 id="深度迁移学习"><a href="#深度迁移学习" class="headerlink" title="深度迁移学习"></a>深度迁移学习</h1><p>深度模型的知识：隐层，权重，但是，一些惩罚的范式(上节课的距离)不太适合使用，因为，深度神经网络学习的曲面十分陡峭，不敢乱加力</p>
<h2 id="实例迁移"><a href="#实例迁移" class="headerlink" title="实例迁移"></a>实例迁移</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_000600_47.png" alt="20200614_000600_47"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_000718_37.png" alt="20200614_000718_37"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_001030_21.png" alt="20200614_001030_21"></p>
<p>半监督学习：到了全连接层之后，可以走两条路，一条是直接判断分类(有y)，另一条路，像auto encoder 一样reconstructed data。(没有y)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_062952_24.png" alt="20200614_062952_24"></p>
<p>h是全连接层那里，最后一项是given x后y的分布是否集中在某一类。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_063146_16.png" alt="20200614_063146_16"></p>
<p>选择容易区分的作为数据，帮助我在target得到更好结果</p>
<h2 id="特征迁移-1"><a href="#特征迁移-1" class="headerlink" title="特征迁移"></a>特征迁移</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_063431_12.png" alt="20200614_063431_12"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_063831_87.png" alt="20200614_063831_87"></p>
<p>MMD通过核函数去评估距离本身，在核函数里面去寻找使得两个分布最大差距的核函数是什么</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_064000_95.png" alt="20200614_064000_95"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_064436_17.png" alt="20200614_064436_17"></p>
<p>深度网络中，层与层有什么关系，哪些特征可迁移。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_065029_39.png" alt="20200614_065029_39"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_065457_80.png" alt="20200614_065457_80"></p>
<p>selfer 自己训练的网络不用A， + fine tune。蓝色说明了前n层不改变没有太大关系，因为后面层还要大量可学习。transfer+fine tuning最好，co-adapted 每层参数会平移。4transfer的信息在另一个task看来没用</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_065840_51.png" alt="20200614_065840_51"></p>
<p>生成的data就是新的dominant。以学习的方法绕过了定义距离的方式。用这个分类器去指导如何做dominant adaptation</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_070104_71.png" alt="20200614_070104_71"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_070235_78.png" alt="20200614_070235_78"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_070319_86.png" alt="20200614_070319_86"></p>
<h2 id="参数迁移-1"><a href="#参数迁移-1" class="headerlink" title="参数迁移"></a>参数迁移</h2><p>深层网络，用l2不如用dropout来得好，他的等高线是个很奇怪的形状，限制了之后，点会飘走</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_070925_84.png" alt="20200614_070925_84"></p>
<p>往往只改变最后一层的表示。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_071048_68.png" alt="20200614_071048_68"></p>
<p>做好特征的学习就好了，至于目标的区分度不用管，交给后面几层</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_071234_34.png" alt="20200614_071234_34"></p>
<p>在network上做一些变化，重用以前的knowledge</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_071646_96.png" alt="20200614_071646_96"></p>
<p>一个点分裂开来两个重复的点。函数值是完全一样的。网络容量变大了，初始化也很好</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_071721_19.png" alt="20200614_071721_19"></p>
<h2 id="Resnet"><a href="#Resnet" class="headerlink" title="Resnet"></a>Resnet</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_071947_20.png" alt="20200614_071947_20"></p>
<p>深层网络我形状太崎岖了，以至于往外走，走不了多久就陷入了局部解，导致，训练也差。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_072112_88.png" alt="20200614_072112_88"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_072214_83.png" alt="20200614_072214_83"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_072401_17.png" alt="20200614_072401_17"></p>
<h2 id="summary-1"><a href="#summary-1" class="headerlink" title="summary"></a>summary</h2><p>异构迁移学习太灵活了，参数和特征两者是互相影响的。深度机器学习时代，更care网络的重用和扩展，使得更深更宽的网络在新的任务做的更好。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200614_072826_18.png" alt="20200614_072826_18"></p>
<h1 id="多任务学习"><a href="#多任务学习" class="headerlink" title="多任务学习"></a>多任务学习</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_111056_19.png" alt="20200622_111056_19"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_111214_62.png" alt="20200622_111214_62"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_111412_96.png" alt="20200622_111412_96"></p>
<p>使A通过B学到G，再把G的pattern拿给A用</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_111756_45.png" alt="20200622_111756_45"></p>
<p>多任务学习比起迁移学习是种更加对称的任务，也就是各种任务都得学好。迁移学习对元任务没有要求，是通过源任务去提升目标任务。元学习的知识更加meta层面，就是如何解决新任务。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_111840_33.png" alt="20200622_111840_33"></p>
<p>惩罚项处理L1L2这种，也可以是相关距离这种</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_112020_89.png" alt="20200622_112020_89"></p>
<p>异构的学习实在太特殊了，因为之间如何共享知识，如何学习，完全取决于具体是什么task， 同构的话，由于特征空间啥的都是相同的，所以可以更加meta层面上去研究</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_112247_86.png" alt="20200622_112247_86"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_112339_70.png" alt="20200622_112339_70"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_112441_41.png" alt="20200622_112441_41"></p>
<p>这个表达式更加侧重于两个任务的共同进步。软参数共享，保证了相关性。</p>
<h1 id="非神经网络模型"><a href="#非神经网络模型" class="headerlink" title="非神经网络模型"></a>非神经网络模型</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_112619_97.png" alt="20200622_112619_97"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_112719_28.png" alt="20200622_112719_28"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_112830_84.png" alt="20200622_112830_84"></p>
<p>特征选择，剪枝，但是只是单任务之间的</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_113141_32.png" alt="20200622_113141_32"></p>
<p>先行做l2，变成了一列的向量，再列做l1，进行特征的选择，实现提取任务之间的关系的作用</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_113346_66.png" alt="20200622_113346_66"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_113436_15.png" alt="20200622_113436_15"></p>
<p>正交，旋转。更多参数，学习能力更强</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_113613_34.png" alt="20200622_113613_34"></p>
<h1 id="深度多任务学习"><a href="#深度多任务学习" class="headerlink" title="深度多任务学习"></a>深度多任务学习</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_113843_45.png" alt="20200622_113843_45"></p>
<p>我们常用的是硬参数共享，然后软参数共享就是同一层的hidden layers 做回归使得分布接近。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_114144_29.png" alt="20200622_114144_29"></p>
<p>类似层次聚类。每一层都做相关性的评估，然后分开。减少参数，完成更好的共享。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_114425_80.png" alt="20200622_114425_80"></p>
<p>在不同的层次之间，根据需要建立不同的共享机制</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_150009_83.png" alt="20200622_150009_83"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_150109_31.png" alt="20200622_150109_31"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_150309_66.png" alt="20200622_150309_66"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_150640_87.png" alt="20200622_150640_87"></p>
<p>轮询：task训练的循环 课程学习：首先学简单task，然后慢慢变难。防止梯度爆炸，而反课程学习，更适合多任务学习。首先学难的任务，获得的pattern和features 通过共享反而更适合简单任务，有更充分的建模能力</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_150756_63.png" alt="20200622_150756_63"></p>
<p>根据不相关性，动态分配loss的权重。使得最后每个task都完成的比较好</p>
<h1 id="summary-2"><a href="#summary-2" class="headerlink" title="summary"></a>summary</h1><p>单任务模型相当于弱人工智能，或者说甚至只是学到了一些统计信息。多任务–强人工智能。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_151043_37.png" alt="20200622_151043_37"></p>
<h1 id="元学习-META"><a href="#元学习-META" class="headerlink" title="元学习(META)"></a>元学习(META)</h1><p>好比机器学习界的成功学，不关注学习的东西本身，而是关注如何去学。multitask没有这么关注meta的知识。通过元学习，变成通用人工智能</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_151411_95.png" alt="20200622_151411_95"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_151619_33.png" alt="20200622_151619_33"></p>
<p>类似人类展现出来的，基于少量学习样本的快速学习的能力。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_151730_66.png" alt="20200622_151730_66"></p>
<p>每个instance(每一行)就是一个任务的全部</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_151953_73.png" alt="20200622_151953_73"></p>
<p>元学习器，关注于让learner拥有什么样的配置，以至于可以快速的学习</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_152323_82.png" alt="20200622_152323_82"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_162512_71.png" alt="20200622_162512_71"></p>
<p>梯度的更新如果是根据某种rule的话，那么我们为什么不能直接学习这个rule呢？使得我们梯度更加adaptive。什么时候快，什么时候慢，什么时候转向</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_162806_31.png" alt="20200622_162806_31"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_162951_22.png" alt="20200622_162951_22"></p>
<p>feature learner</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_163053_11.png" alt="20200622_163053_11"></p>
<h2 id="初始化方法"><a href="#初始化方法" class="headerlink" title="初始化方法"></a>初始化方法</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_163203_76.png" alt="20200622_163203_76"></p>
<p>重用前面n-1层，最后几层进行fine tuning，使得能马上adaptive投入到新任务</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_163416_99.png" alt="20200622_163416_99"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_163606_43.png" alt="20200622_163606_43"></p>
<p>对于θ，我们要怎么更新呢？使得每个task到一个位置上，然后只要前进最少的距离就可以到达下一个TASK</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_163840_23.png" alt="20200622_163840_23"></p>
<p>通常k取1，k取得太大会增加模型的不稳定性和成本</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_164037_89.png" alt="20200622_164037_89"><br>在推荐系统中，可以把每个用户组都当作是一个task，当一个用户来了，只需要通过MAML简单的几个点击，得到比较好的结果，</p>
<h2 id="基于梯度的方法"><a href="#基于梯度的方法" class="headerlink" title="基于梯度的方法"></a>基于梯度的方法</h2><h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h3><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_164410_55.png" alt="20200622_164410_55"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_164503_52.png" alt="20200622_164503_52"></p>
<p>学习过程应该如何做相应的更新</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_164606_41.png" alt="20200622_164606_41"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_164857_29.png" alt="20200622_164857_29"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_164942_10.png" alt="20200622_164942_10"></p>
<p>提高速度，共享单变量lstm</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_165051_72.png" alt="20200622_165051_72"></p>
<p>只要是说，你的模型不比人类手写的公式差的话，效果都是好的啦~</p>
<h2 id="强化学习-1"><a href="#强化学习-1" class="headerlink" title="强化学习"></a>强化学习</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_165301_74.png" alt="20200622_165301_74"></p>
<p>想象成一个序列决策的问题，相当于每次根据情况更新当前的梯度。得到新的梯度相当于又在山上走了一步。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_165520_69.png" alt="20200622_165520_69"></p>
<p>奖励和状态是基于loss降低了多少，动作就是降低梯度</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_165816_55.png" alt="20200622_165816_55"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_165841_52.png" alt="20200622_165841_52"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_165934_21.png" alt="20200622_165934_21"><br>RNN发散是因为RNN看到的reward是比较短时间内的，会陷入局部解上。而RL是长期来看的。可以说是损失某些短期利益获得长期利益</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_170225_35.png" alt="20200622_170225_35"></p>
<h1 id="自动机器学习与神经架构网络"><a href="#自动机器学习与神经架构网络" class="headerlink" title="自动机器学习与神经架构网络"></a>自动机器学习与神经架构网络</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_170547_12.png" alt="20200622_170547_12"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_170753_52.png" alt="20200622_170753_52"></p>
<p>一旦是有经验的东西我们就可以通过学习把他自动化</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_170902_44.png" alt="20200622_170902_44"></p>
<p>越往后退一步，机器学习的普适性就越高， 使得使用者可以更加的白菜。当一个公司发现这个的确能提高公司的运行效率的话，一定会进一步去投资使用人才。所以说自动机器学习真正起到的是人工智能普及到各个领域的功能</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_171414_30.png" alt="20200622_171414_30"></p>
<p>没有梯度回传，因为模型参数这些本身就没有梯度，所以更应该把他放到强化学习上去理解</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_171657_58.png" alt="20200622_171657_58"></p>
<p>相当于子网络只是控制器上的一个点，因而导出一个现象，就是对算力的需求越来越大。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_171946_10.png" alt="20200622_171946_10"></p>
<p>网络的设计从resnet开始，都是 以block为基础，所以设计的时候，先设计一个block里面的一些参数，剩下的就是复制多少份</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_172259_63.png" alt="20200622_172259_63"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_172405_60.png" alt="20200622_172405_60"></p>
<p>文本生成</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_172550_48.png" alt="20200622_172550_48"></p>
<p>通过reward去调整每种策略的概率，走了几十轮，去sampling说我这个策略是不是很好。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_173419_50.png" alt="20200622_173419_50"></p>
<p>另一个方法：重要性采样，故意使用一些human knowledge，故意生成某些A，然后使用important sampling，使得要让其采样a的概率除掉，使得成为无偏估计。让模型直接看到一些积极的reward，以至于不会让他一开始看到什么都是很差的，以至于无法学习</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_173404_04.png" alt="20200622_173404_04"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_173512_17.png" alt="20200622_173512_17"></p>
<p>也可以生成一些带有skip connection的网络</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_173613_47.png" alt="20200622_173613_47"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_173624_80.png" alt="20200622_173624_80"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_173644_33.png" alt="20200622_173644_33"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_174002_34.png" alt="20200622_174002_34"></p>
<p>Rnn，lstm的cell也可以搜素</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_174018_85.png" alt="20200622_174018_85"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_174047_73.png" alt="20200622_174047_73"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_174100_95.png" alt="20200622_174100_95"></p>
<h1 id="summary-3"><a href="#summary-3" class="headerlink" title="summary"></a>summary</h1><p>我们现在处于单任务学习到多任务学习的过程中，或者说是专用人工智能到通用人工智能的探索过程中。就好比是一个笔只能写写作到成为一个人，可以执行多任务</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_174406_59.png" alt="20200622_174406_59"></p>
<h1 id="机器学习的未来"><a href="#机器学习的未来" class="headerlink" title="机器学习的未来"></a>机器学习的未来</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_174803_37.png" alt="20200622_174803_37"></p>
<p>更多要求机器人的鲁棒性和安全性的问题。5G的优势更多发挥在机器与机器之间，激活Ai和整个智慧城市，世界的联系。现在更多侧重在群体智能上。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_175024_72.png" alt="20200622_175024_72"></p>
<p>自动机器学习作为一种服务，如果能更加贴近产业的方方面面，使用的环境也更加灵活。</p>
<p>Ai的三次浪潮，hinton认为这次，不会再落下去了，因为前两次AI是在实验室环境发表论文的一种技术，而这一次是实际落地，产生GDP的技术，市场完全被打开之后，就不会在落下去了</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_175549_68.png" alt="20200622_175549_68"></p>
<p>组合优化这条腿，相当于我们举一反三的能力，但是近20年冷，被统计给抢了风头。但是，随着AI的胃口被吊起来。相信最近五年，基于神经网络的骨干，知识工程，常识推理，长出来属于自己的那份春天。如何整合这两部分的技术，可能是未来发展方向之一。</p>
<h1 id="课程结语"><a href="#课程结语" class="headerlink" title="课程结语"></a>课程结语</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200622_175947_32.png" alt="20200622_175947_32"></p>
<p>机器学习这门学科是进展很快的学科，很容易过失。我们要建立一种终生学习的观念，时刻保持学习的状态。只有不断学习，我们才能停留在原地。但是站在时代前沿的感觉是不错的，这也是学习带来的红利。</p>
<p>很多知识点都得学很多次才可以学会，每次你以为学会了，过段时间就会忘记了，原因是你每次以为你悟道了，但是没有很深刻的理解。得多实践，写写代码，调调参，bug。</p>
<p>nlp变得比较火，bert为落地助力，最近这段时间可能cv有点基本饱和了。更多的注意力可能放在自然语言处理，强化学习，数据挖掘上面。但是很多深度学习的技术，都是在cv先发现再传到nlp。cv走在较前沿。自动化控制与强化学习的联系。</p>
<p>Thanks For All！:)</p>

    </div>

    
    
    
        
      

      <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2020/02/11/Deeping_learning/深度学习14天笔记/" rel="next" title="深度学习14天笔记">
                  <i class="fa fa-chevron-left"></i> 深度学习14天笔记
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2020/03/07/Deeping_learning/目标检测总结/" rel="prev" title="目标追踪总结">
                  目标追踪总结 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    
    <div class="comments" id="gitalk-container"></div>
  

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#人工智能"><span class="nav-number">1.</span> <span class="nav-text">人工智能</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#数据科学"><span class="nav-number">2.</span> <span class="nav-text">数据科学</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#机器学习"><span class="nav-number">3.</span> <span class="nav-text">机器学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#历史"><span class="nav-number">3.1.</span> <span class="nav-text">历史</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#机器学习的两种类型"><span class="nav-number">3.2.</span> <span class="nav-text">机器学习的两种类型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#优势"><span class="nav-number">3.3.</span> <span class="nav-text">优势</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#机器学习应用"><span class="nav-number">4.</span> <span class="nav-text">机器学习应用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#面向预测的应用"><span class="nav-number">4.1.</span> <span class="nav-text">面向预测的应用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面向决策的应用"><span class="nav-number">4.2.</span> <span class="nav-text">面向决策的应用</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#基本思想"><span class="nav-number">5.</span> <span class="nav-text">基本思想</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#监督学习"><span class="nav-number">5.1.</span> <span class="nav-text">监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#学习目标是什么？"><span class="nav-number">5.1.1.</span> <span class="nav-text">学习目标是什么？</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#模型选择"><span class="nav-number">6.</span> <span class="nav-text">模型选择</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#过拟合，欠拟合"><span class="nav-number">6.1.</span> <span class="nav-text">过拟合，欠拟合</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#正则化"><span class="nav-number">6.2.</span> <span class="nav-text">正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Q：超参入可学习吗？"><span class="nav-number">6.2.1.</span> <span class="nav-text">Q：超参入可学习吗？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#奥卡姆剃刀"><span class="nav-number">6.3.</span> <span class="nav-text">奥卡姆剃刀</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#交叉验证"><span class="nav-number">6.4.</span> <span class="nav-text">交叉验证</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#泛化能力-GA"><span class="nav-number">7.</span> <span class="nav-text">泛化能力(GA)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#判别模型与生成模型"><span class="nav-number">8.</span> <span class="nav-text">判别模型与生成模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#生成模型"><span class="nav-number">8.1.</span> <span class="nav-text">生成模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#判别模型"><span class="nav-number">8.2.</span> <span class="nav-text">判别模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#两者的差别"><span class="nav-number">8.3.</span> <span class="nav-text">两者的差别</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#线性回归"><span class="nav-number">9.</span> <span class="nav-text">线性回归</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#梯度"><span class="nav-number">10.</span> <span class="nav-text">梯度</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#线性回归矩阵形式"><span class="nav-number">11.</span> <span class="nav-text">线性回归矩阵形式</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#泛线性模型"><span class="nav-number">12.</span> <span class="nav-text">泛线性模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#逻辑回归"><span class="nav-number">13.</span> <span class="nav-text">逻辑回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#二分类"><span class="nav-number">13.1.</span> <span class="nav-text">二分类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#与非线性模型对比"><span class="nav-number">13.2.</span> <span class="nav-text">与非线性模型对比</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#最大似然估计"><span class="nav-number">14.</span> <span class="nav-text">最大似然估计</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分类指标"><span class="nav-number">15.</span> <span class="nav-text">分类指标</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#支持向量机"><span class="nav-number">16.</span> <span class="nav-text">支持向量机</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#逻辑回归的可视化"><span class="nav-number">16.1.</span> <span class="nav-text">逻辑回归的可视化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#支持向量机-1"><span class="nav-number">16.2.</span> <span class="nav-text">支持向量机</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#向量机优化"><span class="nav-number">16.3.</span> <span class="nav-text">向量机优化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#序列最小优化-SMO"><span class="nav-number">17.</span> <span class="nav-text">序列最小优化(SMO)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#坐标上升法"><span class="nav-number">17.1.</span> <span class="nav-text">坐标上升法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SMO"><span class="nav-number">17.2.</span> <span class="nav-text">SMO</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#支持向量机核方法"><span class="nav-number">18.</span> <span class="nav-text">支持向量机核方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">18.1.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#人工神经网络发展"><span class="nav-number">19.</span> <span class="nav-text">人工神经网络发展</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#普适逼近定理"><span class="nav-number">20.</span> <span class="nav-text">普适逼近定理</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#反向传播"><span class="nav-number">21.</span> <span class="nav-text">反向传播</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#激活函数"><span class="nav-number">22.</span> <span class="nav-text">激活函数</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#深度学习思想简介"><span class="nav-number">23.</span> <span class="nav-text">深度学习思想简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#梯度消失问题的解决方法"><span class="nav-number">24.</span> <span class="nav-text">梯度消失问题的解决方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Relu"><span class="nav-number">24.1.</span> <span class="nav-text">Relu</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#深度残差Resnet"><span class="nav-number">24.2.</span> <span class="nav-text">深度残差Resnet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#批标准化"><span class="nav-number">24.3.</span> <span class="nav-text">批标准化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#陷入局部最小的解决方法"><span class="nav-number">25.</span> <span class="nav-text">陷入局部最小的解决方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#深度信念网络"><span class="nav-number">25.1.</span> <span class="nav-text">深度信念网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#adam"><span class="nav-number">25.2.</span> <span class="nav-text">adam</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#正则化-1"><span class="nav-number">26.</span> <span class="nav-text">正则化</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CNN-空间上的特征"><span class="nav-number">27.</span> <span class="nav-text">CNN(空间上的特征)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#用于文本分类"><span class="nav-number">27.1.</span> <span class="nav-text">用于文本分类</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#RNN-时间上的特征"><span class="nav-number">28.</span> <span class="nav-text">RNN(时间上的特征)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#LSTM"><span class="nav-number">29.</span> <span class="nav-text">LSTM</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Q-amp-A-课程上的提问"><span class="nav-number">29.1.</span> <span class="nav-text">Q &amp; A(课程上的提问)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#词嵌入"><span class="nav-number">29.2.</span> <span class="nav-text">词嵌入</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#语言模型"><span class="nav-number">29.3.</span> <span class="nav-text">语言模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#视觉语言对齐"><span class="nav-number">29.4.</span> <span class="nav-text">视觉语言对齐</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#生成图像描述"><span class="nav-number">29.5.</span> <span class="nav-text">生成图像描述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结-1"><span class="nav-number">29.6.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#函数逼近"><span class="nav-number">30.</span> <span class="nav-text">函数逼近</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#决策树"><span class="nav-number">31.</span> <span class="nav-text">决策树</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ID3"><span class="nav-number">32.</span> <span class="nav-text">ID3</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CART决策树"><span class="nav-number">33.</span> <span class="nav-text">CART决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#回归树"><span class="nav-number">33.1.</span> <span class="nav-text">回归树</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分类树"><span class="nav-number">33.2.</span> <span class="nav-text">分类树</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结-2"><span class="nav-number">33.3.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#集成树"><span class="nav-number">34.</span> <span class="nav-text">集成树</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#bagging"><span class="nav-number">35.</span> <span class="nav-text">bagging</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#bootstrap"><span class="nav-number">35.1.</span> <span class="nav-text">bootstrap</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#树模型总结"><span class="nav-number">36.</span> <span class="nav-text">树模型总结</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#随机森林"><span class="nav-number">37.</span> <span class="nav-text">随机森林</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#bagging-VS-随机森林-VS-Bootsing"><span class="nav-number">38.</span> <span class="nav-text">bagging VS 随机森林 VS Bootsing</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#广义加性模型"><span class="nav-number">39.</span> <span class="nav-text">广义加性模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Adaboost"><span class="nav-number">40.</span> <span class="nav-text">Adaboost</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#学习准则"><span class="nav-number">40.1.</span> <span class="nav-text">学习准则</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#算法"><span class="nav-number">40.2.</span> <span class="nav-text">算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#提升算法简史"><span class="nav-number">41.</span> <span class="nav-text">提升算法简史</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#GBDT"><span class="nav-number">42.</span> <span class="nav-text">GBDT</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#深度森林"><span class="nav-number">43.</span> <span class="nav-text">深度森林</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#多粒度级联森林-gcforest"><span class="nav-number">43.1.</span> <span class="nav-text">多粒度级联森林(gcforest)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#排序与过滤"><span class="nav-number">44.</span> <span class="nav-text">排序与过滤</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#学习排序"><span class="nav-number">45.</span> <span class="nav-text">学习排序</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#排序方法"><span class="nav-number">46.</span> <span class="nav-text">排序方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#pointwise"><span class="nav-number">46.1.</span> <span class="nav-text">pointwise</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pairwise"><span class="nav-number">46.2.</span> <span class="nav-text">pairwise</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Listwise"><span class="nav-number">46.3.</span> <span class="nav-text">Listwise</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LambdaRank"><span class="nav-number">46.4.</span> <span class="nav-text">LambdaRank</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结-3"><span class="nav-number">46.5.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#个性化推荐"><span class="nav-number">47.</span> <span class="nav-text">个性化推荐</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#KNN"><span class="nav-number">48.</span> <span class="nav-text">KNN</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#概率图模型"><span class="nav-number">49.</span> <span class="nav-text">概率图模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#贝叶斯网络-有向图"><span class="nav-number">50.</span> <span class="nav-text">贝叶斯网络(有向图)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#概率图模型的条件独立"><span class="nav-number">51.</span> <span class="nav-text">概率图模型的条件独立</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#有向分离"><span class="nav-number">51.1.</span> <span class="nav-text">有向分离</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#独立同分布"><span class="nav-number">51.2.</span> <span class="nav-text">独立同分布</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#马尔可夫网络-无向图"><span class="nav-number">52.</span> <span class="nav-text">马尔可夫网络(无向图)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#马尔可夫网络实例"><span class="nav-number">53.</span> <span class="nav-text">马尔可夫网络实例</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#马尔可夫-Vs-贝叶斯"><span class="nav-number">54.</span> <span class="nav-text">马尔可夫 Vs 贝叶斯</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#链式模型推断"><span class="nav-number">55.</span> <span class="nav-text">链式模型推断</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#树图模型推断"><span class="nav-number">56.</span> <span class="nav-text">树图模型推断</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#summary"><span class="nav-number">57.</span> <span class="nav-text">summary</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#论坛：强化学习"><span class="nav-number">58.</span> <span class="nav-text">论坛：强化学习</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#无监督学习简介"><span class="nav-number">59.</span> <span class="nav-text">无监督学习简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#聚类"><span class="nav-number">60.</span> <span class="nav-text">聚类</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#主成分分析"><span class="nav-number">61.</span> <span class="nav-text">主成分分析</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#混合高斯模型的EM算法"><span class="nav-number">62.</span> <span class="nav-text">混合高斯模型的EM算法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#通用EM算法"><span class="nav-number">63.</span> <span class="nav-text">通用EM算法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#传统无监督总结"><span class="nav-number">64.</span> <span class="nav-text">传统无监督总结</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#生成式对抗网络"><span class="nav-number">65.</span> <span class="nav-text">生成式对抗网络</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#限制玻尔兹曼机简介"><span class="nav-number">66.</span> <span class="nav-text">限制玻尔兹曼机简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#RBM学习算法"><span class="nav-number">67.</span> <span class="nav-text">RBM学习算法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#深度信念网络-1"><span class="nav-number">68.</span> <span class="nav-text">深度信念网络</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#自动编码器"><span class="nav-number">69.</span> <span class="nav-text">自动编码器</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#学习理论"><span class="nav-number">70.</span> <span class="nav-text">学习理论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#偏差-方差分解"><span class="nav-number">71.</span> <span class="nav-text">偏差-方差分解</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#假设空间ERM边界"><span class="nav-number">72.</span> <span class="nav-text">假设空间ERM边界</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#VC维"><span class="nav-number">73.</span> <span class="nav-text">VC维</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#交叉验证-1"><span class="nav-number">74.</span> <span class="nav-text">交叉验证</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#特征选择"><span class="nav-number">75.</span> <span class="nav-text">特征选择</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#强化学习"><span class="nav-number">76.</span> <span class="nav-text">强化学习</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#探索与利用"><span class="nav-number">77.</span> <span class="nav-text">探索与利用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#多臂老虎机"><span class="nav-number">77.1.</span> <span class="nav-text">多臂老虎机</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#马尔可夫决策过程"><span class="nav-number">78.</span> <span class="nav-text">马尔可夫决策过程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#MDP-基于动态规划的强化学习"><span class="nav-number">78.1.</span> <span class="nav-text">MDP(基于动态规划的强化学习)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#基于模型的强化学习-model-base"><span class="nav-number">79.</span> <span class="nav-text">基于模型的强化学习(model base)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#模型无光强化学习"><span class="nav-number">80.</span> <span class="nav-text">模型无光强化学习</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#蒙特卡罗方法"><span class="nav-number">81.</span> <span class="nav-text">蒙特卡罗方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#蒙特卡罗价值预测"><span class="nav-number">81.1.</span> <span class="nav-text">蒙特卡罗价值预测</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#重要性采样"><span class="nav-number">82.</span> <span class="nav-text">重要性采样</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#时序差分学习"><span class="nav-number">83.</span> <span class="nav-text">时序差分学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#MC-VS-TD"><span class="nav-number">83.1.</span> <span class="nav-text">MC VS TD</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#SARSA"><span class="nav-number">84.</span> <span class="nav-text">SARSA</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Q"><span class="nav-number">85.</span> <span class="nav-text">Q</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#收敛性证明"><span class="nav-number">85.1.</span> <span class="nav-text">收敛性证明</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#总结-4"><span class="nav-number">86.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#迁移学习"><span class="nav-number">87.</span> <span class="nav-text">迁移学习</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#示例迁移"><span class="nav-number">88.</span> <span class="nav-text">示例迁移</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#示例二"><span class="nav-number">88.1.</span> <span class="nav-text">示例二</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#特征迁移"><span class="nav-number">89.</span> <span class="nav-text">特征迁移</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#参数迁移"><span class="nav-number">90.</span> <span class="nav-text">参数迁移</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#案例"><span class="nav-number">90.1.</span> <span class="nav-text">案例</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#深度迁移学习"><span class="nav-number">91.</span> <span class="nav-text">深度迁移学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#实例迁移"><span class="nav-number">91.1.</span> <span class="nav-text">实例迁移</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#特征迁移-1"><span class="nav-number">91.2.</span> <span class="nav-text">特征迁移</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参数迁移-1"><span class="nav-number">91.3.</span> <span class="nav-text">参数迁移</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Resnet"><span class="nav-number">91.4.</span> <span class="nav-text">Resnet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#summary-1"><span class="nav-number">91.5.</span> <span class="nav-text">summary</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#多任务学习"><span class="nav-number">92.</span> <span class="nav-text">多任务学习</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#非神经网络模型"><span class="nav-number">93.</span> <span class="nav-text">非神经网络模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#深度多任务学习"><span class="nav-number">94.</span> <span class="nav-text">深度多任务学习</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#summary-2"><span class="nav-number">95.</span> <span class="nav-text">summary</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#元学习-META"><span class="nav-number">96.</span> <span class="nav-text">元学习(META)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#初始化方法"><span class="nav-number">96.1.</span> <span class="nav-text">初始化方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于梯度的方法"><span class="nav-number">96.2.</span> <span class="nav-text">基于梯度的方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RNN"><span class="nav-number">96.2.1.</span> <span class="nav-text">RNN</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#强化学习-1"><span class="nav-number">96.3.</span> <span class="nav-text">强化学习</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#自动机器学习与神经架构网络"><span class="nav-number">97.</span> <span class="nav-text">自动机器学习与神经架构网络</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#summary-3"><span class="nav-number">98.</span> <span class="nav-text">summary</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#机器学习的未来"><span class="nav-number">99.</span> <span class="nav-text">机器学习的未来</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#课程结语"><span class="nav-number">100.</span> <span class="nav-text">课程结语</span></a></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/22.png"
      alt="狗仔源">
  <p class="site-author-name" itemprop="name">狗仔源</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">19</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:530738743@qq.com" title="E-Mail &rarr; mailto:530738743@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">狗仔源</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">72k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">1:05</span>
</div>

        












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.1"></script><script src="/js/motion.js?v=7.4.1"></script>
<script src="/js/schemes/pisces.js?v=7.4.1"></script>

<script src="/js/next-boot.js?v=7.4.1"></script>



  





















  

  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: '3fd967d31c63d255d193',
      clientSecret: 'b8ead67458a8526ad97a04eb9a872c28c8ec09ff',
      repo: 'BelongComments',
      owner: 'Belong34',
      admin: ['Belong34'],
      id: '6876d42ce61af5aca7116bd4a3d2e1ab',
        language: window.navigator.language || window.navigator.userLanguage,
      
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
</script>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":0,"vOffset":20},"mobile":{"show":true},"log":false,"tagMode":false});</script></body>
</html>
