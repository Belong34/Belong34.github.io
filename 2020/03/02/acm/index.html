<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.1">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.1" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.1">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.4.1',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="此文只是笔记的随笔，时间有限，没有系统补充知识以总结，谨看">
<meta property="og:type" content="article">
<meta property="og:title" content="acm">
<meta property="og:url" content="Belong34.github.io/2020/03/02/acm/index.html">
<meta property="og:site_name" content="Renegades">
<meta property="og:description" content="此文只是笔记的随笔，时间有限，没有系统补充知识以总结，谨看">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200303_231616_81.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_133332_75.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_133026_33.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_144342_82.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_144526_10.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_150052_85.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_151345_26.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_152125_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_152224_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_153019_27.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_153625_30.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_130851_77.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_131806_93.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_132108_75.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200314_215650_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200314_220406_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_134548_69.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_135004_76.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_140809_41.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_141040_87.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_142550_96.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_143216_11.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_143922_14.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_144710_10.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_150049_88.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_150720_55.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154953_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200315_000807_92.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_145911_01.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_150314_31.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_150732_61.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_151639_36.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_152129_25.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154359_81.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154633_36.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153012_30.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153113_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153336_19.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_135936_56.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_153844_57.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_154330_97.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155147_29.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155422_99.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155854_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_160044_95.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161323_39.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161508_35.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161540_22.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161925_76.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_175803_53.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_175940_11.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_180234_99.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_180913_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_181219_96.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174024_10.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174135_90.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174708_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174826_53.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_181853_99.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_182227_25.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_182556_35.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193048_57.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193311_58.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193930_87.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_194409_24.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_194750_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_195806_12.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_201042_34.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210137_21.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210151_77.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210304_12.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210438_41.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_203021_17.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_203434_90.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_205854_74.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_204308_24.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_204542_97.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_231906_11.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_232746_36.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_233535_59.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_233824_39.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_234954_20.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_235651_83.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_000557_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_002916_31.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003316_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003429_93.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003746_97.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_004325_17.png">
<meta property="og:updated_time" content="2020-04-07T10:22:47.884Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="acm">
<meta name="twitter:description" content="此文只是笔记的随笔，时间有限，没有系统补充知识以总结，谨看">
<meta name="twitter:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200303_231616_81.png">
  <link rel="canonical" href="Belong34.github.io/2020/03/02/acm/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>acm | Renegades</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Renegades</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
        
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      
    
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="Belong34.github.io/2020/03/02/acm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="狗仔源">
      <meta itemprop="description" content="VCC & ME">
      <meta itemprop="image" content="/images/22.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Renegades">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            acm
            

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2020-03-02 13:13:34" itemprop="dateCreated datePublished" datetime="2020-03-02T13:13:34+08:00">2020-03-02</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-04-07 18:22:47" itemprop="dateModified" datetime="2020-04-07T18:22:47+08:00">2020-04-07</time>
              </span>
            
          

          
          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
              
                <span class="post-meta-item-text">本文字数：</span>
              
              <span>5.7k</span>
            </span>
          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
              
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              
              <span>5 分钟</span>
            </span>
          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>此文只是笔记的随笔，时间有限，没有系统补充知识以总结，谨看</p>
<a id="more"></a>
<h1 id="人工智能"><a href="#人工智能" class="headerlink" title="人工智能"></a>人工智能</h1><p>搜索 推理 学习</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200303_231616_81.png" alt="20200303_231616_81"></p>
<h1 id="数据科学"><a href="#数据科学" class="headerlink" title="数据科学"></a>数据科学</h1><p>目标：发现数据的基本原理，从观测的结果中构建数据模型，由于其数据比较大，所以会使用很多的算法来实现数据的分析。本质上讲与传统的物理学,化学等做的内容一样,但更加广泛</p>
<p>用户行为建模的例子：通过利用一些比较容易得到的数据去得到比较获取并且很有价值的数据<br>由联合数据分布P(x)得到条件数据分布P(x2|x1)<br>Raw Data -&gt; Data Service -&gt; Application</p>
<p>数据处理技术：数据本身是没有价值的，有价值的是数据服务</p>
<h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><h2 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h2><p>50年代（创建ML术语）-&gt;60年代（神经网络+感知机，因为感知机被证明了局限性所以被冷冻）-&gt;70年代（做符号归纳，专家系统。决策树模型）-&gt;80年代（起飞一波，反向传播，高级决策树）-&gt;90年代（自适应，文本学习，RL提出，SVM+核方法，贝叶斯）-&gt;00年代（概率图，变分推理，迁移学习，跨模态学习）-&gt;10年代（深度学习，强大算力，GPU，多任务+终身学习，深度强化学习）</p>
<h2 id="机器学习的两种类型"><a href="#机器学习的两种类型" class="headerlink" title="机器学习的两种类型"></a>机器学习的两种类型</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_133332_75.png" alt="20200302_133332_75"><br>监督侧重的是：通过某一维预测某一维。基于给定的数据预测目标概率分布</p>
<p>无监督：侧重在全部维，联合分布下求条件分布</p>
<p>而决策是多步的，主语是机器。</p>
<p>预测型用于辅助人决策，决策型是自己替代人自己决策。</p>
<h2 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_133026_33.png" alt="20200302_133026_33"></p>
<h1 id="机器学习应用"><a href="#机器学习应用" class="headerlink" title="机器学习应用"></a>机器学习应用</h1><h2 id="面向预测的应用"><a href="#面向预测的应用" class="headerlink" title="面向预测的应用"></a>面向预测的应用</h2><p>网页搜索：基本的Learning to rank；新一代搜索：QA系统，反馈<br>人脸识别<br>推荐系统：更重要的时手机终端<br>在线广告：用户是否喜欢广告，广告客户如何出价<br>信息提取：结构化信息提取，医疗文本信息提取<br>医疗图像分析<br>金融数据预测</p>
<h2 id="面向决策的应用"><a href="#面向决策的应用" class="headerlink" title="面向决策的应用"></a>面向决策的应用</h2><p>交互式内容推荐：抖音、影响用户的兴趣，GNN<br>机器人控制<br>自动驾驶<br>游戏智能<br>多智能体协作（Multi-agent RL），合作或竞争</p>
<p>关于文本的标注：半监督的一种：远程监督</p>
<h1 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_144342_82.png" alt="20200302_144342_82"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_144526_10.png" alt="20200302_144526_10"></p>
<h2 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h2><h3 id="学习目标是什么？"><a href="#学习目标是什么？" class="headerlink" title="学习目标是什么？"></a>学习目标是什么？</h3><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_150052_85.png" alt="20200302_150052_85"></p>
<p>平方误差：距离越远，损失越多，但容忍小距离 (误差)</p>
<p>怎么更新假设空间：梯度下降</p>
<h1 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h1><h2 id="过拟合，欠拟合"><a href="#过拟合，欠拟合" class="headerlink" title="过拟合，欠拟合"></a>过拟合，欠拟合</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_151345_26.png" alt="20200302_151345_26"></p>
<p>一开始建立复杂的模型防止欠拟合，然后正则化去惩罚</p>
<h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>本质：    本质上都是对向量求一个范式。损失函数 + 基于假设的罚值（范数距离）  </p>
<p>为了防止他只去到最中间那个点(每个等高线是θ)，也就是过拟合，过每个点的那种，我们加上惩罚项，使他往外面走一点。<br><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_152125_65.png" alt="20200302_152125_65"></p>
<ul>
<li>L1：稀疏特征</li>
<li>L1+L2：工业界一般</li>
<li>q太大了也不行，值可能也会变大，一般来说不会每个特征都大。BTW，一般残差(n次方)的权重都不会太大，太大了一般代表有一些东西干扰了。<br><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_152224_44.png" alt="20200302_152224_44"><h3 id="Q：超参入可学习吗？"><a href="#Q：超参入可学习吗？" class="headerlink" title="Q：超参入可学习吗？"></a>Q：超参入可学习吗？</h3>不可，不可导，也学习是使loss越小越好，这里明显是惩罚用的。</li>
</ul>
<h2 id="奥卡姆剃刀"><a href="#奥卡姆剃刀" class="headerlink" title="奥卡姆剃刀"></a>奥卡姆剃刀</h2><p>有多个假设模型，我们应该选择假设条件最少的建模方法，so正则化。比如少用些特征，或者特征间的交互模式比较简单</p>
<h2 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_153019_27.png" alt="20200302_153019_27"></p>
<h1 id="泛化能力-GA"><a href="#泛化能力-GA" class="headerlink" title="泛化能力(GA)"></a>泛化能力(GA)</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_153625_30.png" alt="20200302_153625_30"></p>
<h1 id="判别模型与生成模型"><a href="#判别模型与生成模型" class="headerlink" title="判别模型与生成模型"></a>判别模型与生成模型</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_130851_77.png" alt="20200309_130851_77"></p>
<h2 id="生成模型"><a href="#生成模型" class="headerlink" title="生成模型"></a>生成模型</h2><p>生成模型就是建模一个联合概率分布，然后进行条件推断(先建立好多维度的，然后根据需要选择特定维度，进行边缘化)。探寻数据分布(数据科学的本质)，受益于隐变量建模</p>
<p>应用:朴素贝叶斯,隐马尔科夫模型,混合高斯模型,马尔科夫随机场, 隐狄利克雷分布(LDA)等</p>
<p>关于生成模型，贝叶斯派，更能很好反映数据的分布，频率派：好算，投入生产中</p>
<h2 id="判别模型"><a href="#判别模型" class="headerlink" title="判别模型"></a>判别模型</h2><p>判别模型，确定性模型本质相当于拟合一个函数，而随机判别就是建立条件概率。</p>
<ul>
<li>直接建模预测标签与已知特征的关联</li>
<li>易于定义特定依赖的特征和模型</li>
<li>实际上产生更高的预测性能</li>
</ul>
<p>应用：线性回归,逻辑回归,k近邻, 支持向量机, (多层)感知机,决策树,随机森林等</p>
<h2 id="两者的差别"><a href="#两者的差别" class="headerlink" title="两者的差别"></a>两者的差别</h2><p>误差的侧重点，判别模型是集中精力去寻找这两维的差别，，而生成模型相当于学习到联合联合概率分布，和边缘分布。侧重于所有维，那么误差也是存在于所有维度上的，</p>
<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><p>确定性判别模型，一个截距，加上每一维度与标量的乘积</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_131806_93.png" alt="20200309_131806_93">   </p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_132108_75.png" alt="20200309_132108_75"></p>
<p>二维回归也是线性模型，相当于增加了一个映射，增多了一个维度(出现θ方就不是线性)。只不过可以把fai理解为特征工程</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200314_215650_84.png" alt="20200314_215650_84"></p>
<p>转换成三维图看，每一组特征所对应的y值不一样，但是会通过f(x)映射到一个面上，这个面叫做流形。那个y的取值不一样可以从两个角度理解，一个是x和y概率分布的问题。一个是还有一些特征没有被挖掘。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200314_220406_13.png" alt="20200314_220406_13"></p>
<p>在最小化目标函数的时候，我们可以看到，从某个θ处不同的取值看都是U(不同θU都是不一样的)。所以才使用梯度下降。 如果是θ多维的，就寻找梯度绝对值最大且沿着斜率往上走的那个，再减去这个梯度。</p>
<h1 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_134548_69.png" alt="20200309_134548_69"></p>
<p>目标是使得这个优化函数的值最小，然后梯度更新的目标是使得θ朝着梯度绝对值最大的地方，所以对fθ求导的xi</p>
<p>批量梯度在那个等高线图上的表示就是前面几段线更新的幅度都很大。而随机梯度在后半端会疯狂震荡，因为每一个取值都有偏差对他造成影响。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_135004_76.png" alt="20200309_135004_76"></p>
<p>小批量梯度将训练集分成k个batch，来优化，梯度下降</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_140809_41.png" alt="20200309_140809_41"></p>
<p>当然批量梯度下降也可以b并行化，具体还得看具体项目或者数据的规格，如果数据量很大的话，机器性能很有限的话，还是不适宜切割这么大块的数据。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_141040_87.png" alt="20200309_141040_87"></p>
<p>初始值不同有可能得到不同的局部最优解，初始化位置，可以当作为一个超参数，但如对于一个凸优化函数，局部最小值就是全局最小值，凸函数不一定可导，Relu</p>
<p>学习率的设置往往会对应一个函数动态发生改变1/根号t，其次，我们检查梯度下降是否有效，往往可以打印几个迭代得到的损失值，取判断误差是否有正常的下降</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_142550_96.png" alt="20200309_142550_96"></p>
<p>Q：梯度大，变化率大，也就是梯度下降会很敏感，如果还取很大的值的话，会不会很容易越界，跑过头了？<br>如图，存在这种情况，这个沟很窄，很容易就越出去，但通常来说，构建好的模型，往往在实际应用中会出现偏移，如果取值范围这么窄的话，很有可能实际中就不对应了，所以为了鲁棒性，一般来说会选择比较大的沟。其次为了防止落入窄山谷中，还有一些其他的梯度下降(动量等)</p>
<h1 id="线性回归矩阵形式"><a href="#线性回归矩阵形式" class="headerlink" title="线性回归矩阵形式"></a>线性回归矩阵形式</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_143216_11.png" alt="20200309_143216_11"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_143922_14.png" alt="20200309_143922_14"></p>
<p>计算量太大了 求逆的复杂度是n^3，所以这个只是理论上的，实际上还是使用梯度下降。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_144710_10.png" alt="20200309_144710_10"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_150049_88.png" alt="20200309_150049_88"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_150720_55.png" alt="20200309_150720_55"></p>
<p>当矩阵不是满秩的时候，得到的解不是唯一解，如图所示，很有可能谷底不是一个点，而是一条线，这时候我们需要引入正则化，取与这条线相切的那一点。</p>
<h1 id="泛线性模型"><a href="#泛线性模型" class="headerlink" title="泛线性模型"></a>泛线性模型</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154953_47.png" alt="20200309_154953_47"></p>
<p>泛线性模型其实就是将x变成了针对每个特征的一个映射矩阵。θ之间没有乘除运算即属于线性模型</p>
<p>核矩阵的作用：计算低维空间中的数据映射到高维空间后的内积，使得不再在乎x特征以及映射，而在乎相似度</p>
<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>分类问题线性可分，不可分的情况会映射到高维下可分</p>
<h2 id="二分类"><a href="#二分类" class="headerlink" title="二分类"></a>二分类</h2><p>逻辑回归处理分类问题，属于判别模型中的一种，通常来说使用概率判别模型(分类是离散数据，确定性判别模型对于分类任务不可以微分(函数表示都是导数为0，判别模型概率将离散数据转变成概率分布的连续分布,存在有意义的导数可以学习)。)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200315_000807_92.png" alt="20200315_000807_92"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_145911_01.png" alt="20200321_145911_01"></p>
<p>需要用sigmoid把概率的预测值转化为0-1之间的连续可导的表示，求出概率之后通过设置域(也就是h，看你的需要，更care哪个指标)来确定最终标签(大于为正例，否则为负例)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_150314_31.png" alt="20200321_150314_31"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_150732_61.png" alt="20200321_150732_61"></p>
<p>多分类是可以变成二分类的，例如五分类，可以变成5个二分类(是否第一类，是否第二类….)，不过相应参数会表达许多，在分类较多的情况下不太好</p>
<p>多分类将最小化交叉熵变成最大对数化似然求解，最后加上softmax函数，可以看作是sigmoid函数在多分类情况下的延伸，最后将得到类别数减去一组参数(把一组normalize为1,相当于二分类那个1)。通过e指数形式将模型输出的分数转换为一个概率分布。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_151639_36.png" alt="20200321_151639_36"></p>
<p>关于onehot的表示,通常会转成稀疏表示。因为这样，能确保每个特征之间独立。如果用1-7表示星期1到星期日，其实在先验上赋予了这些类别一些东西。七倍啥的，因此，还有一种设法是onehot 全0也代表一种类别。这种也是不太推荐的。在求取w和b的时候由于太接近了，使得他们的区分线很接近，导致准确率降低。全零的也是一个道理，相当于拿b和别人做区分。也是不太好的。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_152129_25.png" alt="20200321_152129_25"></p>
<h2 id="与非线性模型对比"><a href="#与非线性模型对比" class="headerlink" title="与非线性模型对比"></a>与非线性模型对比</h2><ul>
<li>优点：标准化，易于理解和实施，高效和可拓展性</li>
<li>缺点：建模局限（特征独立假设）,无法探索特征及交互</li>
</ul>
<h1 id="最大似然估计"><a href="#最大似然估计" class="headerlink" title="最大似然估计"></a>最大似然估计</h1><p>随机判别</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154359_81.png" alt="20200309_154359_81"></p>
<p>假设白噪声σ固定，然后可以把条件概率分布等价为了一个高斯分布(联合概率分布)，横坐标上的是θ，其对应的y就是这个条件概率分布。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154633_36.png" alt="20200309_154633_36"></p>
<p>然后我们是这个概率最大，这里使用到了对数计算，一个是因为可以避免算到无穷大或无穷小。把乘法变成了加法，二是最后的化简结果恰好等价于均方误差，就可以不用求梯度了。</p>
<p>PS：判别模型其实根据不同的数据取不同的σ，例如这个噪声的分布十分的不均匀，均方一下很大一下很小，我们就得使用大一点的sigma了</p>
<h1 id="分类指标"><a href="#分类指标" class="headerlink" title="分类指标"></a>分类指标</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153012_30.png" alt="20200309_153012_30"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153113_84.png" alt="20200309_153113_84"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153336_19.png" alt="20200309_153336_19"></p>
<p>如何决定h？使得f1score得到最大值，这样pr会比较均衡</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_135936_56.png" alt="20200321_135936_56"><br>前面的f1score等指标会受到正负样本比等 的影响，但auc基本上都在[0.5,1]，不受样本的太大影响，因此可以用它来横向对比不同任务数据上。如何计算，通过不断降低h的真正假正的变化计算。</p>
<h1 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_153844_57.png" alt="20200321_153844_57"></p>
<p>在现实中，数据存在噪声，往往会在数据周围有个分布，所以支持向量机的划线就是出于这种距离的原则，离数据点间隔越大越好，建立一个最鲁棒的决策边界. 离线的距离是打分，法向量是θ。如果函数</p>
<h2 id="逻辑回归的可视化"><a href="#逻辑回归的可视化" class="headerlink" title="逻辑回归的可视化"></a>逻辑回归的可视化</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_154330_97.png" alt="20200321_154330_97"></p>
<h2 id="支持向量机-1"><a href="#支持向量机-1" class="headerlink" title="支持向量机"></a>支持向量机</h2><p>类别标签的不同：{-1，1}</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155147_29.png" alt="20200321_155147_29"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155422_99.png" alt="20200321_155422_99"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155854_47.png" alt="20200321_155854_47"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_160044_95.png" alt="20200321_160044_95"></p>
<h2 id="向量机优化"><a href="#向量机优化" class="headerlink" title="向量机优化"></a>向量机优化</h2><p>这里使用到了一个凸优化的求解(拉格朗日对偶问题KKT条件)。推导看不太懂。主要的作用就是将一个有限制条件的函数变成了一个没有限制条件(少限制条件)的函数，从而使得可以求导。<br><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161323_39.png" alt="20200321_161323_39"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161508_35.png" alt="20200321_161508_35"></p>
<p>需要满足ag=0，当a等于0的时候是外面的那些点其实是没什么意义的。当g等于0的时候代表的就是最近的那几个点。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161540_22.png" alt="20200321_161540_22"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161925_76.png" alt="20200321_161925_76"></p>
<p>这里minmax和maxmin的选择，因为满足了KKT条件，所以两者是一样的。但是max在里面其实是没有什么意义的。因为有意义的点是求导等于0的。所以使用min在里面。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_175803_53.png" alt="20200329_175803_53"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_175940_11.png" alt="20200329_175940_11"><br>a&gt;0的情况仅仅存在于最近的几个支持向量上，通过这几个向量求解W，b则通过最近的两个正例和负例取平均值求得。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_180234_99.png" alt="20200329_180234_99"></p>
<p>只需要计算支持向量与样例的内积，计算效率很高，然后比较截距就得到正例和负例的判断了。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_180913_65.png" alt="20200329_180913_65"></p>
<p>如果存在一些偏了一点点的点(噪声)，可能会使得函数为了区分他造成很大的影响。我们可以加入个松弛变量(惩罚项)取限制住他，就是使得目标函数不要被太大的影响</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_181219_96.png" alt="20200329_181219_96"></p>
<p>相比较，hinge因为只受到那几个支持向量的影响，得到的函数都是很直的，即正负例分的很清晰。逻辑回归，因为考虑到较多点，虽然平滑，但是往往会使得一些已经判断是正确的了还会去影响到函数</p>
<p>流程如下：</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174024_10.png" alt="20200329_174024_10"></p>
<p>目标函数：</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174135_90.png" alt="20200329_174135_90"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174708_13.png" alt="20200329_174708_13"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174826_53.png" alt="20200329_174826_53"></p>
<h1 id="序列最小优化-SMO"><a href="#序列最小优化-SMO" class="headerlink" title="序列最小优化(SMO)"></a>序列最小优化(SMO)</h1><h2 id="坐标上升法"><a href="#坐标上升法" class="headerlink" title="坐标上升法"></a>坐标上升法</h2><p>每一次优化的时候，只取一个α。不断优化，直至收敛，</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_181853_99.png" alt="20200329_181853_99"></p>
<h2 id="SMO"><a href="#SMO" class="headerlink" title="SMO"></a>SMO</h2><p>但是不能使用，因为有一个限制条件，Σαiyi=0，只要有一点改变α就不等于0了(也就是αi变了αj也得变)，因此引入smo</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_182227_25.png" alt="20200329_182227_25"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_182556_35.png" alt="20200329_182556_35"></p>
<p>效率很高，复杂度仅仅为O(1)</p>
<h1 id="支持向量机核方法"><a href="#支持向量机核方法" class="headerlink" title="支持向量机核方法"></a>支持向量机核方法</h1><p>上文提到的松弛变量只能解决存在一点噪声的不可分情况，而实际上遇到高维的线性不可分，还是得从核出发</p>
<p>解决方法：将特征向量映射到高维空间中</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193048_57.png" alt="20200329_193048_57"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193311_58.png" alt="20200329_193311_58"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193930_87.png" alt="20200329_193930_87"></p>
<p>相对不关注映射是怎么样的，更多是衡量两者之间的相似性，包括到b的求解也是可以直接带入到K中，从而避开了映射。复杂度为O(n)(小于直接计算的O(n方))</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_194409_24.png" alt="20200329_194409_24"></p>
<p>此映射函数是一个无穷维的函数，但是我们不care。K是对称矩阵，半正定矩阵(ZTKZ&gt;=0)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_194750_84.png" alt="20200329_194750_84"></p>
<p>还有sigmoid核子(tanh(ax^Tz+C))，相当于一个二层的感知机</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>其实svm只是一个优化的目标函数而已，和最小化均方差啥的都一个道理，但是他有很好的结构性质与技巧。α。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_195806_12.png" alt="20200329_195806_12"></p>
<p>统计机器学习的本质归根到底就是两个数据的相似性：相似的数据拥有相同的label</p>
<h1 id="人工神经网络发展"><a href="#人工神经网络发展" class="headerlink" title="人工神经网络发展"></a>人工神经网络发展</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_201042_34.png" alt="20200329_201042_34"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210137_21.png" alt="20200329_210137_21"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210151_77.png" alt="20200329_210151_77"></p>
<p>停滞了20年，1986多感知机的方法得到了实现，但是解决方案不唯一</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210304_12.png" alt="20200329_210304_12"></p>
<p>直到前馈的出世统一了这个解决方案</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210438_41.png" alt="20200329_210438_41"></p>
<h1 id="普适逼近定理"><a href="#普适逼近定理" class="headerlink" title="普适逼近定理"></a>普适逼近定理</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_203021_17.png" alt="20200329_203021_17"></p>
<p>可以理解维有限神经元是很多隐藏层，每个点都是个感知机，可以通过一个精度控制每个感知机负责一小块的线段。达到逼近任意线的目标。</p>
<p>其中激活函数的目标就是添加非线性的因素，因为线性怎么叠加仍然还是线性，</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_203434_90.png" alt="20200329_203434_90"></p>
<p>Q:神经网络相比于一般的逼近方法(分段插值)，有什么好的地方呢？</p>
<p>A：可学习，到了深层次的东西，不可解释的东西，往往出现一些难以解释的效果</p>
<h1 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_205854_74.png" alt="20200329_205854_74"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_204308_24.png" alt="20200329_204308_24"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_204542_97.png" alt="20200329_204542_97"></p>
<h1 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_231906_11.png" alt="20200405_231906_11"></p>
<p>tanh将sigmoid的(0,1)和(2，2)变成了(-1,1)和(-1，1)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_232746_36.png" alt="20200405_232746_36"></p>
<p>Relu的问题是在0附近，过一点点就不动了，softplus(平滑)和noiseRelu(增加白噪声)就是针对0做一些处理，使其平滑。相比而言，Relu的计算最简单(快)，其次，由于在负值上的取值为0，所以起到了一种稀疏表示的作用(dropout)</p>
<p>损失函数：回归：均方误差 分类：交叉熵</p>
<h1 id="深度学习思想简介"><a href="#深度学习思想简介" class="headerlink" title="深度学习思想简介"></a>深度学习思想简介</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_233535_59.png" alt="20200405_233535_59"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_233824_39.png" alt="20200405_233824_39"></p>
<p>通常不会使用l1l2，如图，l2相当与在0点有一个量去拉着你，很容易导致掉下山峰</p>
<p>众包平台</p>
<p>cpu优化延迟，gpu优化带宽</p>
<h1 id="梯度消失问题的解决方法"><a href="#梯度消失问题的解决方法" class="headerlink" title="梯度消失问题的解决方法"></a>梯度消失问题的解决方法</h1><h2 id="Relu"><a href="#Relu" class="headerlink" title="Relu"></a>Relu</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_234954_20.png" alt="20200405_234954_20"></p>
<p>正值是1，所以相乘怎么样都是有梯度的   </p>
<h2 id="深度残差Resnet"><a href="#深度残差Resnet" class="headerlink" title="深度残差Resnet"></a>深度残差Resnet</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_235651_83.png" alt="20200405_235651_83"></p>
<p>训练数据有时在更深的神经网络性能反倒更差，有一种理解是：更深层次的表达后往往会出现更多不确定的优化曲面，很容易陷在一些沟壑内</p>
<p>Resnet的意义：</p>
<h2 id="批标准化"><a href="#批标准化" class="headerlink" title="批标准化"></a>批标准化</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_000557_13.png" alt="20200406_000557_13"></p>
<p>存在一些问题，就是每次经过激活函数的时候，往往利用的都是没什么意义的区域，就是经过一个激活函数之后，他的输出分布在很后面或者很前面，没有到曲折的部分，这是我们不想看到的。 这时候我们通过一个batch的数据构建分布，当然，这个分布可以自己设置位置(几个可以学习的参数)</p>
<h1 id="陷入局部最小的解决方法"><a href="#陷入局部最小的解决方法" class="headerlink" title="陷入局部最小的解决方法"></a>陷入局部最小的解决方法</h1><p>两个方向：爬山起点怎么设计，怎么更好的爬山</p>
<h2 id="深度信念网络"><a href="#深度信念网络" class="headerlink" title="深度信念网络"></a>深度信念网络</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_002916_31.png" alt="20200406_002916_31"></p>
<p>就是可见单元到隐藏单元，然后隐藏单元能回来，与原本的可见单元比较</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003316_13.png" alt="20200406_003316_13"></p>
<p>encoder和decoder，将特征压缩(学习到最有效的表征信息)再扩展回来和原图差不多，相当于有监督+无监督，损失函数是两张图片的差距，通过这种手段生成一组不错的初始值，然后就是微调模型了。例子：你去爬山，相当于你起点就是青藏高原了。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003429_93.png" alt="20200406_003429_93"></p>
<h2 id="adam"><a href="#adam" class="headerlink" title="adam"></a>adam</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003746_97.png" alt="20200406_003746_97"></p>
<p>可以基于之前的梯度冲出局部最小值。</p>
<h1 id="正则化-1"><a href="#正则化-1" class="headerlink" title="正则化"></a>正则化</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_004325_17.png" alt="20200406_004325_17"></p>
<p>通常不会使用l1l2，如图，l2相当与在0点有一个量去拉着你，很容易导致掉下山峰。</p>
<p>一个有意思的理解：相当于集成学习，每一次dropout的形式都代表一种模型，然后最后测试的时候使用的是全部模型集成在一起。</p>

    </div>

    
    
    
        
      

      <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2020/02/11/深度学习14天笔记/" rel="next" title="深度学习14天笔记">
                  <i class="fa fa-chevron-left"></i> 深度学习14天笔记
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2020/03/07/目标检测总结/" rel="prev" title="目标追踪总结">
                  目标追踪总结 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    
    <div class="comments" id="gitalk-container"></div>
  

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#人工智能"><span class="nav-number">1.</span> <span class="nav-text">人工智能</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#数据科学"><span class="nav-number">2.</span> <span class="nav-text">数据科学</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#机器学习"><span class="nav-number">3.</span> <span class="nav-text">机器学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#历史"><span class="nav-number">3.1.</span> <span class="nav-text">历史</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#机器学习的两种类型"><span class="nav-number">3.2.</span> <span class="nav-text">机器学习的两种类型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#优势"><span class="nav-number">3.3.</span> <span class="nav-text">优势</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#机器学习应用"><span class="nav-number">4.</span> <span class="nav-text">机器学习应用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#面向预测的应用"><span class="nav-number">4.1.</span> <span class="nav-text">面向预测的应用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面向决策的应用"><span class="nav-number">4.2.</span> <span class="nav-text">面向决策的应用</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#基本思想"><span class="nav-number">5.</span> <span class="nav-text">基本思想</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#监督学习"><span class="nav-number">5.1.</span> <span class="nav-text">监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#学习目标是什么？"><span class="nav-number">5.1.1.</span> <span class="nav-text">学习目标是什么？</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#模型选择"><span class="nav-number">6.</span> <span class="nav-text">模型选择</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#过拟合，欠拟合"><span class="nav-number">6.1.</span> <span class="nav-text">过拟合，欠拟合</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#正则化"><span class="nav-number">6.2.</span> <span class="nav-text">正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Q：超参入可学习吗？"><span class="nav-number">6.2.1.</span> <span class="nav-text">Q：超参入可学习吗？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#奥卡姆剃刀"><span class="nav-number">6.3.</span> <span class="nav-text">奥卡姆剃刀</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#交叉验证"><span class="nav-number">6.4.</span> <span class="nav-text">交叉验证</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#泛化能力-GA"><span class="nav-number">7.</span> <span class="nav-text">泛化能力(GA)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#判别模型与生成模型"><span class="nav-number">8.</span> <span class="nav-text">判别模型与生成模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#生成模型"><span class="nav-number">8.1.</span> <span class="nav-text">生成模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#判别模型"><span class="nav-number">8.2.</span> <span class="nav-text">判别模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#两者的差别"><span class="nav-number">8.3.</span> <span class="nav-text">两者的差别</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#线性回归"><span class="nav-number">9.</span> <span class="nav-text">线性回归</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#梯度"><span class="nav-number">10.</span> <span class="nav-text">梯度</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#线性回归矩阵形式"><span class="nav-number">11.</span> <span class="nav-text">线性回归矩阵形式</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#泛线性模型"><span class="nav-number">12.</span> <span class="nav-text">泛线性模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#逻辑回归"><span class="nav-number">13.</span> <span class="nav-text">逻辑回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#二分类"><span class="nav-number">13.1.</span> <span class="nav-text">二分类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#与非线性模型对比"><span class="nav-number">13.2.</span> <span class="nav-text">与非线性模型对比</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#最大似然估计"><span class="nav-number">14.</span> <span class="nav-text">最大似然估计</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分类指标"><span class="nav-number">15.</span> <span class="nav-text">分类指标</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#支持向量机"><span class="nav-number">16.</span> <span class="nav-text">支持向量机</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#逻辑回归的可视化"><span class="nav-number">16.1.</span> <span class="nav-text">逻辑回归的可视化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#支持向量机-1"><span class="nav-number">16.2.</span> <span class="nav-text">支持向量机</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#向量机优化"><span class="nav-number">16.3.</span> <span class="nav-text">向量机优化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#序列最小优化-SMO"><span class="nav-number">17.</span> <span class="nav-text">序列最小优化(SMO)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#坐标上升法"><span class="nav-number">17.1.</span> <span class="nav-text">坐标上升法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SMO"><span class="nav-number">17.2.</span> <span class="nav-text">SMO</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#支持向量机核方法"><span class="nav-number">18.</span> <span class="nav-text">支持向量机核方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">18.1.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#人工神经网络发展"><span class="nav-number">19.</span> <span class="nav-text">人工神经网络发展</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#普适逼近定理"><span class="nav-number">20.</span> <span class="nav-text">普适逼近定理</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#反向传播"><span class="nav-number">21.</span> <span class="nav-text">反向传播</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#激活函数"><span class="nav-number">22.</span> <span class="nav-text">激活函数</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#深度学习思想简介"><span class="nav-number">23.</span> <span class="nav-text">深度学习思想简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#梯度消失问题的解决方法"><span class="nav-number">24.</span> <span class="nav-text">梯度消失问题的解决方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Relu"><span class="nav-number">24.1.</span> <span class="nav-text">Relu</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#深度残差Resnet"><span class="nav-number">24.2.</span> <span class="nav-text">深度残差Resnet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#批标准化"><span class="nav-number">24.3.</span> <span class="nav-text">批标准化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#陷入局部最小的解决方法"><span class="nav-number">25.</span> <span class="nav-text">陷入局部最小的解决方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#深度信念网络"><span class="nav-number">25.1.</span> <span class="nav-text">深度信念网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#adam"><span class="nav-number">25.2.</span> <span class="nav-text">adam</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#正则化-1"><span class="nav-number">26.</span> <span class="nav-text">正则化</span></a></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/22.png"
      alt="狗仔源">
  <p class="site-author-name" itemprop="name">狗仔源</p>
  <div class="site-description" itemprop="description">VCC & ME</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">19</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">标签</span>
        
      </div>
    
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:530738743@qq.com" title="E-Mail &rarr; mailto:530738743@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">狗仔源</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">54k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">49 分钟</span>
</div>

        












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.1"></script><script src="/js/motion.js?v=7.4.1"></script>
<script src="/js/schemes/pisces.js?v=7.4.1"></script>

<script src="/js/next-boot.js?v=7.4.1"></script>



  





















  

  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: '3fd967d31c63d255d193',
      clientSecret: 'b8ead67458a8526ad97a04eb9a872c28c8ec09ff',
      repo: 'BelongComments',
      owner: 'Belong34',
      admin: ['Belong34'],
      id: '08270b795209ad409061a5d261b859de',
        language: window.navigator.language || window.navigator.userLanguage,
      
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
</script>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":0,"vOffset":20},"mobile":{"show":true},"log":false,"tagMode":false});</script></body>
</html>
