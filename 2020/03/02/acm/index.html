<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.1">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.1" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.1">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.4.1',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="此文只是笔记+课件记录，时间有限，没有系统补充知识以总结，没有什么参考意义">
<meta property="og:type" content="article">
<meta property="og:title" content="acm">
<meta property="og:url" content="Belong34.github.io/2020/03/02/acm/index.html">
<meta property="og:site_name" content="Renegades">
<meta property="og:description" content="此文只是笔记+课件记录，时间有限，没有系统补充知识以总结，没有什么参考意义">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200303_231616_81.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_133332_75.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_133026_33.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_144342_82.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_144526_10.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_150052_85.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_151345_26.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_152125_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_152224_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_153019_27.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_153625_30.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_130851_77.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_131806_93.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_132108_75.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200314_215650_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200314_220406_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_134548_69.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_135004_76.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_140809_41.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_141040_87.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_142550_96.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_143216_11.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_143922_14.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_144710_10.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_150049_88.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_150720_55.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154953_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200315_000807_92.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_145911_01.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_150314_31.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_150732_61.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_151639_36.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_152129_25.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154359_81.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154633_36.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153012_30.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153113_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153336_19.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_135936_56.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_153844_57.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_154330_97.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155147_29.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155422_99.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155854_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_160044_95.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161323_39.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161508_35.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161540_22.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161925_76.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_175803_53.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_175940_11.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_180234_99.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_180913_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_181219_96.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174024_10.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174135_90.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174708_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174826_53.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_181853_99.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_182227_25.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_182556_35.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193048_57.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193311_58.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193930_87.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_194409_24.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_194750_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_195806_12.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_201042_34.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210137_21.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210151_77.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210304_12.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210438_41.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_203021_17.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_203434_90.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_205854_74.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_204308_24.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_204542_97.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_231906_11.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_232746_36.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_233535_59.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_233824_39.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_234954_20.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_235651_83.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_000557_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_002916_31.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003316_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003429_93.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003746_97.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_004325_17.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_195527_32.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_201959_54.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_210348_68.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_210937_80.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_211302_29.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_211518_91.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_211656_49.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_225404_18.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_225750_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_230152_21.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_230601_45.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_230749_26.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_231054_95.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_231203_71.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_231417_38.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_231928_54.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_232319_78.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233201_92.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233420_91.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200419_002407_43.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233631_22.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233746_36.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233851_94.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_234405_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_234651_85.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_235042_97.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_235657_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_190417_91.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200419_000006_24.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200419_000410_59.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200419_000253_16.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_160003_22.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_160329_83.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_161533_69.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_161543_16.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_161824_41.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_162015_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_162239_60.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_163845_58.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164150_49.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164202_25.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164510_19.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164630_98.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164756_71.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_165239_23.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_165658_60.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_165709_70.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_180100_69.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_180649_99.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_181115_59.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_181455_86.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_182353_46.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_182858_70.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_183027_83.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_183231_85.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_183341_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_183918_73.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_213730_96.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_214320_93.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_214520_35.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_214629_11.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_215324_64.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_215329_88.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_215535_74.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_215932_28.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_220216_21.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_220241_86.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_220354_41.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_220429_49.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_225340_74.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_221212_92.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_221405_42.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_221641_22.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_221933_99.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_222207_83.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_222522_86.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_222636_59.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_223007_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_223100_85.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_224932_24.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_101221_77.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_103543_22.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104010_82.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104335_94.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_224603_55.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_224811_98.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104543_39.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104719_31.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104833_21.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_105048_88.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_105353_67.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_105533_36.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_105441_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_110311_74.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_110716_95.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_110911_30.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_111824_15.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_112543_66.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113043_42.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113121_83.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113243_90.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113633_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113826_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113935_91.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_114236_19.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_114426_77.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_195206_49.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_195749_94.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_200011_64.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_200115_54.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_200824_31.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_200923_31.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201036_71.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201443_51.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201510_56.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201624_78.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201711_98.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201847_17.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_224916_36.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_202845_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_203112_35.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_203612_98.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_203935_35.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_204143_50.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_204426_57.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_204533_11.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_204725_32.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_205032_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_205052_50.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_205148_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_205356_61.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_211617_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_220605_39.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095146_17.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095225_16.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095353_26.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095533_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095812_47.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_100248_59.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_100402_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_100458_74.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_100905_53.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101347_86.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101611_24.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101618_35.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101625_17.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101637_44.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101645_12.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101653_49.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_112840_26.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113144_82.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113308_52.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113408_11.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113554_81.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113837_65.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_114138_32.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_114240_28.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_114416_51.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_114823_52.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115020_23.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115316_93.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115327_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115337_20.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115727_97.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115833_14.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_120120_91.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_120726_84.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_121105_60.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_121208_57.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_121353_19.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_121646_89.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122110_13.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122310_72.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122506_59.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122645_83.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122719_66.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122941_57.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_123147_89.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124001_76.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124224_87.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124355_52.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124458_91.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124637_53.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124909_74.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_125019_20.png">
<meta property="og:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_125206_27.png">
<meta property="og:updated_time" content="2020-05-07T05:02:58.436Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="acm">
<meta name="twitter:description" content="此文只是笔记+课件记录，时间有限，没有系统补充知识以总结，没有什么参考意义">
<meta name="twitter:image" content="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200303_231616_81.png">
  <link rel="canonical" href="Belong34.github.io/2020/03/02/acm/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>acm | Renegades</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Renegades</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
        
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      
    
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="Belong34.github.io/2020/03/02/acm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="狗仔源">
      <meta itemprop="description" content="VCC & ME">
      <meta itemprop="image" content="/images/22.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Renegades">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            acm
            

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2020-03-02 13:13:34" itemprop="dateCreated datePublished" datetime="2020-03-02T13:13:34+08:00">2020-03-02</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-05-07 13:02:58" itemprop="dateModified" datetime="2020-05-07T13:02:58+08:00">2020-05-07</time>
              </span>
            
          

          
          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
              
                <span class="post-meta-item-text">本文字数：</span>
              
              <span>11k</span>
            </span>
          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
              
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              
              <span>10 分钟</span>
            </span>
          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>此文只是笔记+课件记录，时间有限，没有系统补充知识以总结，没有什么参考意义</p>
<a id="more"></a>
<h1 id="人工智能"><a href="#人工智能" class="headerlink" title="人工智能"></a>人工智能</h1><p>搜索 推理 学习</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200303_231616_81.png" alt="20200303_231616_81"></p>
<h1 id="数据科学"><a href="#数据科学" class="headerlink" title="数据科学"></a>数据科学</h1><p>目标：发现数据的基本原理，从观测的结果中构建数据模型，由于其数据比较大，所以会使用很多的算法来实现数据的分析。本质上讲与传统的物理学,化学等做的内容一样,但更加广泛</p>
<p>用户行为建模的例子：通过利用一些比较容易得到的数据去得到比较获取并且很有价值的数据<br>由联合数据分布P(x)得到条件数据分布P(x2|x1)<br>Raw Data -&gt; Data Service -&gt; Application</p>
<p>数据处理技术：数据本身是没有价值的，有价值的是数据服务</p>
<h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><h2 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h2><p>50年代（创建ML术语）-&gt;60年代（神经网络+感知机，因为感知机被证明了局限性所以被冷冻）-&gt;70年代（做符号归纳，专家系统。决策树模型）-&gt;80年代（起飞一波，反向传播，高级决策树）-&gt;90年代（自适应，文本学习，RL提出，SVM+核方法，贝叶斯）-&gt;00年代（概率图，变分推理，迁移学习，跨模态学习）-&gt;10年代（深度学习，强大算力，GPU，多任务+终身学习，深度强化学习）</p>
<h2 id="机器学习的两种类型"><a href="#机器学习的两种类型" class="headerlink" title="机器学习的两种类型"></a>机器学习的两种类型</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_133332_75.png" alt="20200302_133332_75"><br>监督侧重的是：通过某一维预测某一维。基于给定的数据预测目标概率分布</p>
<p>无监督：侧重在全部维，联合分布下求条件分布</p>
<p>而决策是多步的，主语是机器。</p>
<p>预测型用于辅助人决策，决策型是自己替代人自己决策。</p>
<h2 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_133026_33.png" alt="20200302_133026_33"></p>
<h1 id="机器学习应用"><a href="#机器学习应用" class="headerlink" title="机器学习应用"></a>机器学习应用</h1><h2 id="面向预测的应用"><a href="#面向预测的应用" class="headerlink" title="面向预测的应用"></a>面向预测的应用</h2><p>网页搜索：基本的Learning to rank；新一代搜索：QA系统，反馈<br>人脸识别<br>推荐系统：更重要的时手机终端<br>在线广告：用户是否喜欢广告，广告客户如何出价<br>信息提取：结构化信息提取，医疗文本信息提取<br>医疗图像分析<br>金融数据预测</p>
<h2 id="面向决策的应用"><a href="#面向决策的应用" class="headerlink" title="面向决策的应用"></a>面向决策的应用</h2><p>交互式内容推荐：抖音、影响用户的兴趣，GNN<br>机器人控制<br>自动驾驶<br>游戏智能<br>多智能体协作（Multi-agent RL），合作或竞争</p>
<p>关于文本的标注：半监督的一种：远程监督</p>
<h1 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_144342_82.png" alt="20200302_144342_82"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_144526_10.png" alt="20200302_144526_10"></p>
<h2 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h2><h3 id="学习目标是什么？"><a href="#学习目标是什么？" class="headerlink" title="学习目标是什么？"></a>学习目标是什么？</h3><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_150052_85.png" alt="20200302_150052_85"></p>
<p>平方误差：距离越远，损失越多，但容忍小距离 (误差)</p>
<p>怎么更新假设空间：梯度下降</p>
<h1 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h1><h2 id="过拟合，欠拟合"><a href="#过拟合，欠拟合" class="headerlink" title="过拟合，欠拟合"></a>过拟合，欠拟合</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_151345_26.png" alt="20200302_151345_26"></p>
<p>一开始建立复杂的模型防止欠拟合，然后正则化去惩罚</p>
<h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>本质：    本质上都是对向量求一个范式。损失函数 + 基于假设的罚值（范数距离）  </p>
<p>为了防止他只去到最中间那个点(每个等高线是θ)，也就是过拟合，过每个点的那种，我们加上惩罚项，使他往外面走一点。<br><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_152125_65.png" alt="20200302_152125_65"></p>
<ul>
<li>L1：稀疏特征</li>
<li>L1+L2：工业界一般</li>
<li>q太大了也不行，值可能也会变大，一般来说不会每个特征都大。BTW，一般残差(n次方)的权重都不会太大，太大了一般代表有一些东西干扰了。<br><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_152224_44.png" alt="20200302_152224_44"><h3 id="Q：超参入可学习吗？"><a href="#Q：超参入可学习吗？" class="headerlink" title="Q：超参入可学习吗？"></a>Q：超参入可学习吗？</h3>不可，不可导，也学习是使loss越小越好，这里明显是惩罚用的。</li>
</ul>
<h2 id="奥卡姆剃刀"><a href="#奥卡姆剃刀" class="headerlink" title="奥卡姆剃刀"></a>奥卡姆剃刀</h2><p>有多个假设模型，我们应该选择假设条件最少的建模方法，so正则化。比如少用些特征，或者特征间的交互模式比较简单</p>
<h2 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_153019_27.png" alt="20200302_153019_27"></p>
<h1 id="泛化能力-GA"><a href="#泛化能力-GA" class="headerlink" title="泛化能力(GA)"></a>泛化能力(GA)</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200302_153625_30.png" alt="20200302_153625_30"></p>
<h1 id="判别模型与生成模型"><a href="#判别模型与生成模型" class="headerlink" title="判别模型与生成模型"></a>判别模型与生成模型</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_130851_77.png" alt="20200309_130851_77"></p>
<h2 id="生成模型"><a href="#生成模型" class="headerlink" title="生成模型"></a>生成模型</h2><p>生成模型就是建模一个联合概率分布，然后进行条件推断(先建立好多维度的，然后根据需要选择特定维度，进行边缘化)。探寻数据分布(数据科学的本质)，受益于隐变量建模</p>
<p>应用:朴素贝叶斯,隐马尔科夫模型,混合高斯模型,马尔科夫随机场, 隐狄利克雷分布(LDA)等</p>
<p>关于生成模型，贝叶斯派，更能很好反映数据的分布，频率派：好算，投入生产中</p>
<h2 id="判别模型"><a href="#判别模型" class="headerlink" title="判别模型"></a>判别模型</h2><p>判别模型，确定性模型本质相当于拟合一个函数，而随机判别就是建立条件概率。</p>
<ul>
<li>直接建模预测标签与已知特征的关联</li>
<li>易于定义特定依赖的特征和模型</li>
<li>实际上产生更高的预测性能</li>
</ul>
<p>应用：线性回归,逻辑回归,k近邻, 支持向量机, (多层)感知机,决策树,随机森林等</p>
<h2 id="两者的差别"><a href="#两者的差别" class="headerlink" title="两者的差别"></a>两者的差别</h2><p>误差的侧重点，判别模型是集中精力去寻找这两维的差别，，而生成模型相当于学习到联合联合概率分布，和边缘分布。侧重于所有维，那么误差也是存在于所有维度上的，</p>
<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><p>确定性判别模型，一个截距，加上每一维度与标量的乘积</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_131806_93.png" alt="20200309_131806_93">   </p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_132108_75.png" alt="20200309_132108_75"></p>
<p>二维回归也是线性模型，相当于增加了一个映射，增多了一个维度(出现θ方就不是线性)。只不过可以把fai理解为特征工程</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200314_215650_84.png" alt="20200314_215650_84"></p>
<p>转换成三维图看，每一组特征所对应的y值不一样，但是会通过f(x)映射到一个面上，这个面叫做流形。那个y的取值不一样可以从两个角度理解，一个是x和y概率分布的问题。一个是还有一些特征没有被挖掘。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200314_220406_13.png" alt="20200314_220406_13"></p>
<p>在最小化目标函数的时候，我们可以看到，从某个θ处不同的取值看都是U(不同θU都是不一样的)。所以才使用梯度下降。 如果是θ多维的，就寻找梯度绝对值最大且沿着斜率往上走的那个，再减去这个梯度。</p>
<h1 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_134548_69.png" alt="20200309_134548_69"></p>
<p>目标是使得这个优化函数的值最小，然后梯度更新的目标是使得θ朝着梯度绝对值最大的地方，所以对fθ求导的xi</p>
<p>批量梯度在那个等高线图上的表示就是前面几段线更新的幅度都很大。而随机梯度在后半端会疯狂震荡，因为每一个取值都有偏差对他造成影响。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_135004_76.png" alt="20200309_135004_76"></p>
<p>小批量梯度将训练集分成k个batch，来优化，梯度下降</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_140809_41.png" alt="20200309_140809_41"></p>
<p>当然批量梯度下降也可以b并行化，具体还得看具体项目或者数据的规格，如果数据量很大的话，机器性能很有限的话，还是不适宜切割这么大块的数据。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_141040_87.png" alt="20200309_141040_87"></p>
<p>初始值不同有可能得到不同的局部最优解，初始化位置，可以当作为一个超参数，但如对于一个凸优化函数，局部最小值就是全局最小值，凸函数不一定可导，Relu</p>
<p>学习率的设置往往会对应一个函数动态发生改变1/根号t，其次，我们检查梯度下降是否有效，往往可以打印几个迭代得到的损失值，取判断误差是否有正常的下降</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_142550_96.png" alt="20200309_142550_96"></p>
<p>Q：梯度大，变化率大，也就是梯度下降会很敏感，如果还取很大的值的话，会不会很容易越界，跑过头了？<br>如图，存在这种情况，这个沟很窄，很容易就越出去，但通常来说，构建好的模型，往往在实际应用中会出现偏移，如果取值范围这么窄的话，很有可能实际中就不对应了，所以为了鲁棒性，一般来说会选择比较大的沟。其次为了防止落入窄山谷中，还有一些其他的梯度下降(动量等)</p>
<h1 id="线性回归矩阵形式"><a href="#线性回归矩阵形式" class="headerlink" title="线性回归矩阵形式"></a>线性回归矩阵形式</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_143216_11.png" alt="20200309_143216_11"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_143922_14.png" alt="20200309_143922_14"></p>
<p>计算量太大了 求逆的复杂度是n^3，所以这个只是理论上的，实际上还是使用梯度下降。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_144710_10.png" alt="20200309_144710_10"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_150049_88.png" alt="20200309_150049_88"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_150720_55.png" alt="20200309_150720_55"></p>
<p>当矩阵不是满秩的时候，得到的解不是唯一解，如图所示，很有可能谷底不是一个点，而是一条线，这时候我们需要引入正则化，取与这条线相切的那一点。</p>
<h1 id="泛线性模型"><a href="#泛线性模型" class="headerlink" title="泛线性模型"></a>泛线性模型</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154953_47.png" alt="20200309_154953_47"></p>
<p>泛线性模型其实就是将x变成了针对每个特征的一个映射矩阵。θ之间没有乘除运算即属于线性模型</p>
<p>核矩阵的作用：计算低维空间中的数据映射到高维空间后的内积，使得不再在乎x特征以及映射，而在乎相似度</p>
<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>分类问题线性可分，不可分的情况会映射到高维下可分</p>
<h2 id="二分类"><a href="#二分类" class="headerlink" title="二分类"></a>二分类</h2><p>逻辑回归处理分类问题，属于判别模型中的一种，通常来说使用概率判别模型(分类是离散数据，确定性判别模型对于分类任务不可以微分(函数表示都是导数为0，判别模型概率将离散数据转变成概率分布的连续分布,存在有意义的导数可以学习)。)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200315_000807_92.png" alt="20200315_000807_92"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_145911_01.png" alt="20200321_145911_01"></p>
<p>需要用sigmoid把概率的预测值转化为0-1之间的连续可导的表示，求出概率之后通过设置域(也就是h，看你的需要，更care哪个指标)来确定最终标签(大于为正例，否则为负例)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_150314_31.png" alt="20200321_150314_31"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_150732_61.png" alt="20200321_150732_61"></p>
<p>多分类是可以变成二分类的，例如五分类，可以变成5个二分类(是否第一类，是否第二类….)，不过相应参数会表达许多，在分类较多的情况下不太好</p>
<p>多分类将最小化交叉熵变成最大对数化似然求解，最后加上softmax函数，可以看作是sigmoid函数在多分类情况下的延伸，最后将得到类别数减去一组参数(把一组normalize为1,相当于二分类那个1)。通过e指数形式将模型输出的分数转换为一个概率分布。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_151639_36.png" alt="20200321_151639_36"></p>
<p>关于onehot的表示,通常会转成稀疏表示。因为这样，能确保每个特征之间独立。如果用1-7表示星期1到星期日，其实在先验上赋予了这些类别一些东西。七倍啥的，因此，还有一种设法是onehot 全0也代表一种类别。这种也是不太推荐的。在求取w和b的时候由于太接近了，使得他们的区分线很接近，导致准确率降低。全零的也是一个道理，相当于拿b和别人做区分。也是不太好的。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_152129_25.png" alt="20200321_152129_25"></p>
<h2 id="与非线性模型对比"><a href="#与非线性模型对比" class="headerlink" title="与非线性模型对比"></a>与非线性模型对比</h2><ul>
<li>优点：标准化，易于理解和实施，高效和可拓展性</li>
<li>缺点：建模局限（特征独立假设）,无法探索特征及交互</li>
</ul>
<h1 id="最大似然估计"><a href="#最大似然估计" class="headerlink" title="最大似然估计"></a>最大似然估计</h1><p>随机判别</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154359_81.png" alt="20200309_154359_81"></p>
<p>假设白噪声σ固定，然后可以把条件概率分布等价为了一个高斯分布(联合概率分布)，横坐标上的是θ，其对应的y就是这个条件概率分布。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_154633_36.png" alt="20200309_154633_36"></p>
<p>然后我们是这个概率最大，这里使用到了对数计算，一个是因为可以避免算到无穷大或无穷小。把乘法变成了加法，二是最后的化简结果恰好等价于均方误差，就可以不用求梯度了。</p>
<p>PS：判别模型其实根据不同的数据取不同的σ，例如这个噪声的分布十分的不均匀，均方一下很大一下很小，我们就得使用大一点的sigma了</p>
<h1 id="分类指标"><a href="#分类指标" class="headerlink" title="分类指标"></a>分类指标</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153012_30.png" alt="20200309_153012_30"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153113_84.png" alt="20200309_153113_84"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200309_153336_19.png" alt="20200309_153336_19"></p>
<p>如何决定h？使得f1score得到最大值，这样pr会比较均衡</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_135936_56.png" alt="20200321_135936_56"><br>前面的f1score等指标会受到正负样本比等 的影响，但auc基本上都在[0.5,1]，不受样本的太大影响，因此可以用它来横向对比不同任务数据上。如何计算，通过不断降低h的真正假正的变化计算。</p>
<h1 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_153844_57.png" alt="20200321_153844_57"></p>
<p>在现实中，数据存在噪声，往往会在数据周围有个分布，所以支持向量机的划线就是出于这种距离的原则，离数据点间隔越大越好，建立一个最鲁棒的决策边界. 离线的距离是打分，法向量是θ。如果函数</p>
<h2 id="逻辑回归的可视化"><a href="#逻辑回归的可视化" class="headerlink" title="逻辑回归的可视化"></a>逻辑回归的可视化</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_154330_97.png" alt="20200321_154330_97"></p>
<h2 id="支持向量机-1"><a href="#支持向量机-1" class="headerlink" title="支持向量机"></a>支持向量机</h2><p>类别标签的不同：{-1，1}</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155147_29.png" alt="20200321_155147_29"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155422_99.png" alt="20200321_155422_99"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_155854_47.png" alt="20200321_155854_47"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_160044_95.png" alt="20200321_160044_95"></p>
<h2 id="向量机优化"><a href="#向量机优化" class="headerlink" title="向量机优化"></a>向量机优化</h2><p>这里使用到了一个凸优化的求解(拉格朗日对偶问题KKT条件)。推导看不太懂。主要的作用就是将一个有限制条件的函数变成了一个没有限制条件(少限制条件)的函数，从而使得可以求导。<br><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161323_39.png" alt="20200321_161323_39"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161508_35.png" alt="20200321_161508_35"></p>
<p>需要满足ag=0，当a等于0的时候是外面的那些点其实是没什么意义的。当g等于0的时候代表的就是最近的那几个点。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161540_22.png" alt="20200321_161540_22"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200321_161925_76.png" alt="20200321_161925_76"></p>
<p>这里minmax和maxmin的选择，因为满足了KKT条件，所以两者是一样的。但是max在里面其实是没有什么意义的。因为有意义的点是求导等于0的。所以使用min在里面。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_175803_53.png" alt="20200329_175803_53"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_175940_11.png" alt="20200329_175940_11"><br>a&gt;0的情况仅仅存在于最近的几个支持向量上，通过这几个向量求解W，b则通过最近的两个正例和负例取平均值求得。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_180234_99.png" alt="20200329_180234_99"></p>
<p>只需要计算支持向量与样例的内积，计算效率很高，然后比较截距就得到正例和负例的判断了。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_180913_65.png" alt="20200329_180913_65"></p>
<p>如果存在一些偏了一点点的点(噪声)，可能会使得函数为了区分他造成很大的影响。我们可以加入个松弛变量(惩罚项)取限制住他，就是使得目标函数不要被太大的影响</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_181219_96.png" alt="20200329_181219_96"></p>
<p>相比较，hinge因为只受到那几个支持向量的影响，得到的函数都是很直的，即正负例分的很清晰。逻辑回归，因为考虑到较多点，虽然平滑，但是往往会使得一些已经判断是正确的了还会去影响到函数</p>
<p>流程如下：</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174024_10.png" alt="20200329_174024_10"></p>
<p>目标函数：</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174135_90.png" alt="20200329_174135_90"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174708_13.png" alt="20200329_174708_13"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_174826_53.png" alt="20200329_174826_53"></p>
<h1 id="序列最小优化-SMO"><a href="#序列最小优化-SMO" class="headerlink" title="序列最小优化(SMO)"></a>序列最小优化(SMO)</h1><h2 id="坐标上升法"><a href="#坐标上升法" class="headerlink" title="坐标上升法"></a>坐标上升法</h2><p>每一次优化的时候，只取一个α。不断优化，直至收敛，</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_181853_99.png" alt="20200329_181853_99"></p>
<h2 id="SMO"><a href="#SMO" class="headerlink" title="SMO"></a>SMO</h2><p>但是不能使用，因为有一个限制条件，Σαiyi=0，只要有一点改变α就不等于0了(也就是αi变了αj也得变)，因此引入smo</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_182227_25.png" alt="20200329_182227_25"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_182556_35.png" alt="20200329_182556_35"></p>
<p>效率很高，复杂度仅仅为O(1)</p>
<h1 id="支持向量机核方法"><a href="#支持向量机核方法" class="headerlink" title="支持向量机核方法"></a>支持向量机核方法</h1><p>上文提到的松弛变量只能解决存在一点噪声的不可分情况，而实际上遇到高维的线性不可分，还是得从核出发</p>
<p>解决方法：将特征向量映射到高维空间中</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193048_57.png" alt="20200329_193048_57"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193311_58.png" alt="20200329_193311_58"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_193930_87.png" alt="20200329_193930_87"></p>
<p>相对不关注映射是怎么样的，更多是衡量两者之间的相似性，包括到b的求解也是可以直接带入到K中，从而避开了映射。复杂度为O(n)(小于直接计算的O(n方))</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_194409_24.png" alt="20200329_194409_24"></p>
<p>此映射函数是一个无穷维的函数，但是我们不care。K是对称矩阵，半正定矩阵(ZTKZ&gt;=0)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_194750_84.png" alt="20200329_194750_84"></p>
<p>还有sigmoid核子(tanh(ax^Tz+C))，相当于一个二层的感知机</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>其实svm只是一个优化的目标函数而已，和最小化均方差啥的都一个道理，但是他有很好的结构性质与技巧。α。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_195806_12.png" alt="20200329_195806_12"></p>
<p>统计机器学习的本质归根到底就是两个数据的相似性：相似的数据拥有相同的label</p>
<h1 id="人工神经网络发展"><a href="#人工神经网络发展" class="headerlink" title="人工神经网络发展"></a>人工神经网络发展</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_201042_34.png" alt="20200329_201042_34"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210137_21.png" alt="20200329_210137_21"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210151_77.png" alt="20200329_210151_77"></p>
<p>停滞了20年，1986多感知机的方法得到了实现，但是解决方案不唯一</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210304_12.png" alt="20200329_210304_12"></p>
<p>直到前馈的出世统一了这个解决方案</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_210438_41.png" alt="20200329_210438_41"></p>
<h1 id="普适逼近定理"><a href="#普适逼近定理" class="headerlink" title="普适逼近定理"></a>普适逼近定理</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_203021_17.png" alt="20200329_203021_17"></p>
<p>可以理解维有限神经元是很多隐藏层，每个点都是个感知机，可以通过一个精度控制每个感知机负责一小块的线段。达到逼近任意线的目标。</p>
<p>其中激活函数的目标就是添加非线性的因素，因为线性怎么叠加仍然还是线性，</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_203434_90.png" alt="20200329_203434_90"></p>
<p>Q:神经网络相比于一般的逼近方法(分段插值)，有什么好的地方呢？</p>
<p>A：可学习，到了深层次的东西，不可解释的东西，往往出现一些难以解释的效果</p>
<h1 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_205854_74.png" alt="20200329_205854_74"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_204308_24.png" alt="20200329_204308_24"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200329_204542_97.png" alt="20200329_204542_97"></p>
<h1 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_231906_11.png" alt="20200405_231906_11"></p>
<p>tanh将sigmoid的(0,1)和(2，2)变成了(-1,1)和(-1，1)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_232746_36.png" alt="20200405_232746_36"></p>
<p>Relu的问题是在0附近，过一点点就不动了，softplus(平滑)和noiseRelu(增加白噪声)就是针对0做一些处理，使其平滑。相比而言，Relu的计算最简单(快)，其次，由于在负值上的取值为0，所以起到了一种稀疏表示的作用(dropout)</p>
<p>损失函数：回归：均方误差 分类：交叉熵</p>
<h1 id="深度学习思想简介"><a href="#深度学习思想简介" class="headerlink" title="深度学习思想简介"></a>深度学习思想简介</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_233535_59.png" alt="20200405_233535_59"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_233824_39.png" alt="20200405_233824_39"></p>
<p>通常不会使用l1l2，如图，l2相当与在0点有一个量去拉着你，很容易导致掉下山峰</p>
<p>众包平台</p>
<p>cpu优化延迟，gpu优化带宽</p>
<h1 id="梯度消失问题的解决方法"><a href="#梯度消失问题的解决方法" class="headerlink" title="梯度消失问题的解决方法"></a>梯度消失问题的解决方法</h1><h2 id="Relu"><a href="#Relu" class="headerlink" title="Relu"></a>Relu</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_234954_20.png" alt="20200405_234954_20"></p>
<p>正值是1，所以相乘怎么样都是有梯度的   </p>
<h2 id="深度残差Resnet"><a href="#深度残差Resnet" class="headerlink" title="深度残差Resnet"></a>深度残差Resnet</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200405_235651_83.png" alt="20200405_235651_83"></p>
<p>训练数据有时在更深的神经网络性能反倒更差，有一种理解是：更深层次的表达后往往会出现更多不确定的优化曲面，很容易陷在一些沟壑内</p>
<p>Resnet的意义：</p>
<h2 id="批标准化"><a href="#批标准化" class="headerlink" title="批标准化"></a>批标准化</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_000557_13.png" alt="20200406_000557_13"></p>
<p>存在一些问题，就是每次经过激活函数的时候，往往利用的都是没什么意义的区域，就是经过一个激活函数之后，他的输出分布在很后面或者很前面，没有到曲折的部分，这是我们不想看到的。 这时候我们通过一个batch的数据构建分布，当然，这个分布可以自己设置位置(几个可以学习的参数)</p>
<h1 id="陷入局部最小的解决方法"><a href="#陷入局部最小的解决方法" class="headerlink" title="陷入局部最小的解决方法"></a>陷入局部最小的解决方法</h1><p>两个方向：爬山起点怎么设计，怎么更好的爬山</p>
<h2 id="深度信念网络"><a href="#深度信念网络" class="headerlink" title="深度信念网络"></a>深度信念网络</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_002916_31.png" alt="20200406_002916_31"></p>
<p>就是可见单元到隐藏单元，然后隐藏单元能回来，与原本的可见单元比较</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003316_13.png" alt="20200406_003316_13"></p>
<p>encoder和decoder，将特征压缩(学习到最有效的表征信息)再扩展回来和原图差不多，相当于有监督+无监督，损失函数是两张图片的差距，通过这种手段生成一组不错的初始值，然后就是微调模型了。例子：你去爬山，相当于你起点就是青藏高原了。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003429_93.png" alt="20200406_003429_93"></p>
<h2 id="adam"><a href="#adam" class="headerlink" title="adam"></a>adam</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_003746_97.png" alt="20200406_003746_97"></p>
<p>可以基于之前的梯度冲出局部最小值。</p>
<h1 id="正则化-1"><a href="#正则化-1" class="headerlink" title="正则化"></a>正则化</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200406_004325_17.png" alt="20200406_004325_17"></p>
<p>通常不会使用l1l2，如图，l2相当与在0点有一个量去拉着你，很容易导致掉下山峰。</p>
<p>一个有意思的理解：相当于集成学习，每一次dropout的形式都代表一种模型，然后最后测试的时候使用的是全部模型集成在一起。</p>
<h1 id="CNN-空间上的特征"><a href="#CNN-空间上的特征" class="headerlink" title="CNN(空间上的特征)"></a>CNN(空间上的特征)</h1><p>其实kernel可以看作各种各样的模式，取获取这个感受野的内积也就是模式是否相似，然后pooling就是在反传的时候去掉一些意义不大的gradient。所以一般用maxpooling (match最大的)。前面n-1层就是抽取不同感受野下的特征(像素，线条，角，局部，全局)，但是最后一层往往都是线性分类。表征学习</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_195527_32.png" alt="20200418_195527_32"></p>
<p>真相挖掘</p>
<h2 id="用于文本分类"><a href="#用于文本分类" class="headerlink" title="用于文本分类"></a>用于文本分类</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_201959_54.png" alt="20200418_201959_54"></p>
<p>使用的kernel红色：1x3(embedding的5列实际只是编码的表而已，所以不用管)，使用了4个kernel变成第二个红色，也就是将连续的词语获得特征，变成一个，然后max over time pooling，则是将连续的一列词句抽取特征最显著的变成了一个，然后4个kernel连接起来，形成表征。所有kernel结合起来。好处就是抽取了和分类任务相关的词语合起来，得到最有效的表征。相当于我抽了 listen word。省了时间，而不是说每三个就组成一个，这样一个个训练效率不高。</p>
<h1 id="RNN-时间上的特征"><a href="#RNN-时间上的特征" class="headerlink" title="RNN(时间上的特征)"></a>RNN(时间上的特征)</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_210348_68.png" alt="20200418_210348_68"></p>
<p>可以理解为两个w相乘再相加，也可以理解为两个wconcat再乘。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_210937_80.png" alt="20200418_210937_80"></p>
<p>可以看到bp的时候涉及w的运算很多，也很容易把我们带到很远的地方去，所以要小心学习率</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_211302_29.png" alt="20200418_211302_29"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_211518_91.png" alt="20200418_211518_91"></p>
<h1 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h1><p>RNN问题：</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_211656_49.png" alt="20200418_211656_49"></p>
<p>sigmoid都是拿来当一个过滤的门，而relu或tanh都是做特征来用的</p>
<p>遗忘门基于当前的记忆要把长期记忆哪部分遗忘掉，而输入门则是注入哪些当前信号。</p>
<p>有long term 和short term，long term 通过两个sigmoid遗忘和注入新的记忆，再把得到的新long term 和一个sigmoid 过滤当作当前的short term 放到下一个short term上</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_225404_18.png" alt="20200418_225404_18"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_225750_44.png" alt="20200418_225750_44"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_230152_21.png" alt="20200418_230152_21"></p>
<h2 id="Q-amp-A-课程上的提问"><a href="#Q-amp-A-课程上的提问" class="headerlink" title="Q &amp; A(课程上的提问)"></a>Q &amp; A(课程上的提问)</h2><ul>
<li>1.为什么要用tanh来压缩信息？还是说是只是为了丰富网络？如果只是为了丰富网络用relu可以吗？压缩了信息处理会变快吗？</li>
</ul>
<p>你这个问题其实问到我了，我之前没仔细思考为啥lstm里面默认是tanh而不是relu。我临时思考了一下，感觉是这样的：c里面是长期记忆，如果你用relu这样的activation，很可能某一个step就会往c里面注入很大的信息量，把之前的记忆都dominate了。相反tanh因为是bound住的，所以不会造成某一step注入过量信息。</p>
<ul>
<li><p>2.为什么说c这部分没有经过压缩就能很好的解决长期依赖？压缩了就不能很好地传递长期信息了吗？</p>
<p>每次压缩是把之前的记忆向量乘以一个矩阵然后加上当前step进来的信息向量。如果压缩一直做，当然就不能很好的保持较长的dependency了。</p>
<h2 id="词嵌入"><a href="#词嵌入" class="headerlink" title="词嵌入"></a>词嵌入</h2></li>
</ul>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_230601_45.png" alt="20200418_230601_45"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_230749_26.png" alt="20200418_230749_26"></p>
<p>词嵌入是一种对文本算法学习后的表示形式，可以理解为一个单词在算法中的储存形式。大家知道存入计算机的都是0101的数值化序列，这里也是同理，词嵌入就是将文本数值化以方便拟合算法。这种将单词或者文档数字化表示的方式被认为是深度学习在自然语言处理任务中最具有挑战性的问题之一。<br>词嵌入实际上是一种将各个单词在预定的向量空间中表示为实值向量的一类技术。每个单词被映射成一个向量（初始随机化），并且这个向量可以通过神经网络的方式来学习更新。因此这项技术基本集中应用与深度学习领域。</p>
<p>这项技术的关键点在于如何用密集的分布式向量来表示每个单词。这样做的好处在于与one-hot这样的编码对比，使用词嵌入表示的单词向量往往只有几十或者几百个维度。极大的减少了计算和储存量</p>
<h2 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_231054_95.png" alt="20200418_231054_95"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_231203_71.png" alt="20200418_231203_71">  </p>
<h2 id="视觉语言对齐"><a href="#视觉语言对齐" class="headerlink" title="视觉语言对齐"></a>视觉语言对齐</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_231417_38.png" alt="20200418_231417_38"></p>
<p>对齐：描述经过双向rnn，得到每一个位置的vector表示，图片划分区域，用vector和图片位置做一些操作，得到分数用于监督</p>
<h2 id="生成图像描述"><a href="#生成图像描述" class="headerlink" title="生成图像描述"></a>生成图像描述</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_231928_54.png" alt="20200418_231928_54"><br>通过展平的cnn向量和decode的rnn生成单词，做loss的计算，返回给rnn和cnn。 cnn也学习如何生成更符合表征的vector</p>
<p>长短期记忆网络学习视觉语言对齐时，通过计算区域CNN的图片输出表示与双向RNN的中间输出向量之间的内积，来评判语句与图像之间的匹配程度</p>
<h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_232319_78.png" alt="20200418_232319_78"></p>
<p>Q:sigmoid relu tanh<br>sigmoid一般不放在神经网络中间，因为梯度消失，但类似lstm这种需要0-1区间的地方用得到。</p>
<h1 id="函数逼近"><a href="#函数逼近" class="headerlink" title="函数逼近"></a>函数逼近</h1><p>前几周的学习都是参数化的模型，然后梯度求解。(参数的规模不会随数据发生改变)。树的思维方式不一样</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233201_92.png" alt="20200418_233201_92"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233420_91.png" alt="20200418_233420_91"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200419_002407_43.png" alt="20200419_002407_43"></p>
<p>直接再假设空间找到函数，而不是通过参数学习出来</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233631_22.png" alt="20200418_233631_22"></p>
<p>非常容易学习高阶特征(非线性可分)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233746_36.png" alt="20200418_233746_36"></p>
<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_233851_94.png" alt="20200418_233851_94"></p>
<p>如何选择分裂节点？-&gt;具有更高的信息增益的特征(更强分类能力)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_234405_65.png" alt="20200418_234405_65"></p>
<p>越中间越不确定</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_234651_85.png" alt="20200418_234651_85"></p>
<p>度量的是两个分布的距离</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_235042_97.png" alt="20200418_235042_97"></p>
<p>相当于有没有看到y对于我不确定的降低有多少</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200418_235657_47.png" alt="20200418_235657_47"></p>
<p>前者的弊端就是有可能人们把树分的很细，每个节点可能就一两个，(升高分成厘米)。所以引入后者避免这个问题</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_190417_91.png" alt="20200426_190417_91"></p>
<h1 id="ID3"><a href="#ID3" class="headerlink" title="ID3"></a>ID3</h1><p>一个特征在同一条路径最多出现一次。因为第二次使用特征的时候并不会分出子空间来。如果不限制树的深度和宽度，树是可以无限拟合数据的。定义损失函数为叶子节点的经验熵<em>数据量的总和，再次基础上加上叶子节点的数目</em>lamda。这个项用来防止过拟合。ID3是针对离散数据的。C4.5改进了它用信息增益率来分节点。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200419_000006_24.png" alt="20200419_000006_24"></p>
<ul>
<li>Q：有可能划分到最后每一个样例一个节点？</li>
</ul>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200419_000410_59.png" alt="20200419_000410_59"></p>
<p>改进损失函数，加入关于叶子节点数量的惩罚项</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200419_000253_16.png" alt="20200419_000253_16"></p>
<p>Q：决策树和神经网络？<br>决策树更适用一些比较混乱的数据或者missing，而神经网络一般是比较连续的数据</p>
<h1 id="CART决策树"><a href="#CART决策树" class="headerlink" title="CART决策树"></a>CART决策树</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_160003_22.png" alt="20200426_160003_22"></p>
<h2 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_160329_83.png" alt="20200426_160329_83"></p>
<h2 id="分类树"><a href="#分类树" class="headerlink" title="分类树"></a>分类树</h2><p>贝塔分布</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_161533_69.png" alt="20200426_161533_69"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_161543_16.png" alt="20200426_161543_16"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_161824_41.png" alt="20200426_161824_41"></p>
<p>基尼不纯度与熵的分类错误率十分相似，选择能最小化基尼不纯度的特征作为分割点</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_162015_44.png" alt="20200426_162015_44"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_162239_60.png" alt="20200426_162239_60"></p>
<p>往往决策树的模型都可以可视化变成if else便于可视化，原理解释以及debug</p>
<h2 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h2><p>树模型往往更适合处理mix type，missing的数据，outliers，单调的输入，不相关输入，介于参数化和无参数化模型(多一个样本不会多一个参数，或者样本变多了参数也不一定会固定不变)，可解释性。<br>缺点：对于斜着的线性分割不在行，单颗树不太适于预测</p>
<h1 id="集成树"><a href="#集成树" class="headerlink" title="集成树"></a>集成树</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_163845_58.png" alt="20200426_163845_58"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164150_49.png" alt="20200426_164150_49"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164202_25.png" alt="20200426_164202_25"></p>
<p>不同模型在不同场景的权重可以不一样。某方面的专家可以提高他的权重，也可也学习权重</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164510_19.png" alt="20200426_164510_19"></p>
<p>softmax作为gating fn</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164630_98.png" alt="20200426_164630_98"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_164756_71.png" alt="20200426_164756_71"></p>
<p>术业有专攻，针对改变每个专家的权重</p>
<h1 id="bagging"><a href="#bagging" class="headerlink" title="bagging"></a>bagging</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_165239_23.png" alt="20200426_165239_23"></p>
<p>使得小数据样本的下的训练更加客观，鲁棒，不会受一些特别数据的影响。</p>
<h2 id="bootstrap"><a href="#bootstrap" class="headerlink" title="bootstrap"></a>bootstrap</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_165658_60.png" alt="20200426_165658_60"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_165709_70.png" alt="20200426_165709_70"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_180100_69.png" alt="20200426_180100_69"></p>
<p>除了训练集上的采样，也可以对特征sampling。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_180649_99.png" alt="20200426_180649_99"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_181115_59.png" alt="20200426_181115_59"></p>
<p>最后的三个项分别噪声(没法降低)，偏差，方差。</p>
<h1 id="树模型总结"><a href="#树模型总结" class="headerlink" title="树模型总结"></a>树模型总结</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_181455_86.png" alt="20200426_181455_86"></p>
<p>树模型不是在参数空间进行的模型，而是泛函空间，通过改变树的结构来训练模型，本质上loss也不是一个东西，一个是通过梯度求解的，树则是通过不断分割节点计算loss。</p>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_182353_46.png" alt="20200426_182353_46"></p>
<p>协方差矩阵的求解，得到b要大，ρ要小的指导思想，可知bagging tree往往不能使得ρ降低。</p>
<p>虽然通过bootstrap可以使得训练集的分布不太一样，但是树本身还是比较鲁棒的，没有很好的降低相关度</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_182858_70.png" alt="20200426_182858_70"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_183027_83.png" alt="20200426_183027_83"></p>
<h1 id="bagging-VS-随机森林-VS-Bootsing"><a href="#bagging-VS-随机森林-VS-Bootsing" class="headerlink" title="bagging VS 随机森林 VS Bootsing"></a>bagging VS 随机森林 VS Bootsing</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_183231_85.png" alt="20200426_183231_85"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_183341_47.png" alt="20200426_183341_47"></p>
<h1 id="广义加性模型"><a href="#广义加性模型" class="headerlink" title="广义加性模型"></a>广义加性模型</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_183918_73.png" alt="20200426_183918_73"></p>
<p>以上一次的m个模型集合一起的输出与上个模型的结果做差作为这个模型的label</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_213730_96.png" alt="20200426_213730_96"></p>
<h1 id="Adaboost"><a href="#Adaboost" class="headerlink" title="Adaboost"></a>Adaboost</h1><h2 id="学习准则"><a href="#学习准则" class="headerlink" title="学习准则"></a>学习准则</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_214320_93.png" alt="20200426_214320_93"></p>
<p>区别是多了1和log  ，指数准则和对数似然(交叉熵)在二阶泰勒级数上是等价的</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_214520_35.png" alt="20200426_214520_35"></p>
<p>区别是多了一个1/2</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_214629_11.png" alt="20200426_214629_11"></p>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_215324_64.png" alt="20200426_215324_64"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_215329_88.png" alt="20200426_215329_88"></p>
<p>相当于max精准度，因为y和fx同号</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_215535_74.png" alt="20200426_215535_74"></p>
<p>目标同上</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_215932_28.png" alt="20200426_215932_28"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_220216_21.png" alt="20200426_220216_21"></p>
<p>根据c和err关系公式你可以看到，如果一个模型的c显著高于其他模型，那这个模型的err就很接近于0了，那这个时候确实应该让这个模型“一家独大”，dominate其他模型。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_220241_86.png" alt="20200426_220241_86"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_220354_41.png" alt="20200426_220354_41"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_220429_49.png" alt="20200426_220429_49"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_225340_74.png" alt="20200426_225340_74"></p>
<h1 id="提升算法简史"><a href="#提升算法简史" class="headerlink" title="提升算法简史"></a>提升算法简史</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_221212_92.png" alt="20200426_221212_92"></p>
<p>其实和svm一样，统计学习中都是说如何使得边界间隔最大</p>
<h1 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_221405_42.png" alt="20200426_221405_42"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_221641_22.png" alt="20200426_221641_22"></p>
<p>多一棵树模型变得复杂当然要加一个惩罚项</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_221933_99.png" alt="20200426_221933_99"></p>
<p>就是对两个梯度进行优化，可以理解为在梯度方向上长一棵树，最小化j</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_222207_83.png" alt="20200426_222207_83"></p>
<p>叶子数要少，且w不能太大(要不与深度加深同步的是假设性太强)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_222522_86.png" alt="20200426_222522_86"></p>
<p>二次优化问题，没有c是因为树沿着梯度方向走已经学出来了最优值</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_222636_59.png" alt="20200426_222636_59"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_223007_44.png" alt="20200426_223007_44"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_223100_85.png" alt="20200426_223100_85"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200426_224932_24.png" alt="20200426_224932_24"></p>
<h1 id="深度森林"><a href="#深度森林" class="headerlink" title="深度森林"></a>深度森林</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_101221_77.png" alt="20200503_101221_77"></p>
<p>DNNs成功的关键：庞大的训练数据(减小过拟合),高效的算力机器，训练技巧(一般的多层网络反串的时候多层会发散)</p>
<p>dnn的关键：逐层处理，特征变换，足够的模型复杂度</p>
<p>dnn就是在中间学习多层的Representation(逐层学习)，而一般的机器学习是就数据那层</p>
<p>dnn&amp;&amp;kernel matrix：统计学习的本质就是学习相似度，kernel matrix在svm中是直接给出了定义的函数映射，而dnn中是通过学习到效果较好的kernel matrix</p>
<p>与树模型的对比：树模型连简单的线性旋转也没做到</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_103543_22.png" alt="20200503_103543_22"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104010_82.png" alt="20200503_104010_82"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104335_94.png" alt="20200503_104335_94"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_224603_55.png" alt="20200505_224603_55"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_224811_98.png" alt="20200505_224811_98"></p>
<h2 id="多粒度级联森林-gcforest"><a href="#多粒度级联森林-gcforest" class="headerlink" title="多粒度级联森林(gcforest)"></a>多粒度级联森林(gcforest)</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104543_39.png" alt="20200503_104543_39"></p>
<p>集成学习：个体存在差异，个体不能太差</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104719_31.png" alt="20200503_104719_31"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_104833_21.png" alt="20200503_104833_21"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_105048_88.png" alt="20200503_105048_88"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_105353_67.png" alt="20200503_105353_67"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_105533_36.png" alt="20200503_105533_36"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_105441_65.png" alt="20200503_105441_65"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_110311_74.png" alt="20200503_110311_74"></p>
<p>gcforest所有数据都用相同的超参数，但是在图像上可能还是不太行，因为树模型本身的曲线就是不光滑的(阶梯)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_110716_95.png" alt="20200503_110716_95"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_110911_30.png" alt="20200503_110911_30"></p>
<h1 id="排序与过滤"><a href="#排序与过滤" class="headerlink" title="排序与过滤"></a>排序与过滤</h1><h1 id="学习排序"><a href="#学习排序" class="headerlink" title="学习排序"></a>学习排序</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_111824_15.png" alt="20200503_111824_15"></p>
<p>可导是必要条件</p>
<p>信息检索(IR)是从信息集合中获取用户所需要的有关信息的过程。两个关键：检索候选文档，对检索文档排序</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_112543_66.png" alt="20200503_112543_66"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113043_42.png" alt="20200503_113043_42"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113121_83.png" alt="20200503_113121_83"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113243_90.png" alt="20200503_113243_90"></p>
<h1 id="排序方法"><a href="#排序方法" class="headerlink" title="排序方法"></a>排序方法</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113633_44.png" alt="20200503_113633_44"></p>
<h2 id="pointwise"><a href="#pointwise" class="headerlink" title="pointwise"></a>pointwise</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113826_44.png" alt="20200503_113826_44"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_113935_91.png" alt="20200503_113935_91"></p>
<h2 id="pairwise"><a href="#pairwise" class="headerlink" title="pairwise"></a>pairwise</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_114236_19.png" alt="20200503_114236_19"></p>
<p>不在讨论q&amp;d的labels了，而是直接讨论谁应该在前面</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200503_114426_77.png" alt="20200503_114426_77"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_195206_49.png" alt="20200505_195206_49"></p>
<p>缺点：每个文档都被认为具有相同的重要性，但是实际情况上前面的重要性和后面的重要性是不同的。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_195749_94.png" alt="20200505_195749_94"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_200011_64.png" alt="20200505_200011_64"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_200115_54.png" alt="20200505_200115_54"></p>
<h2 id="Listwise"><a href="#Listwise" class="headerlink" title="Listwise"></a>Listwise</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_200824_31.png" alt="20200505_200824_31"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_200923_31.png" alt="20200505_200923_31"></p>
<h2 id="LambdaRank"><a href="#LambdaRank" class="headerlink" title="LambdaRank"></a>LambdaRank</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201036_71.png" alt="20200505_201036_71"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201443_51.png" alt="20200505_201443_51"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201510_56.png" alt="20200505_201510_56"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201624_78.png" alt="20200505_201624_78"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201711_98.png" alt="20200505_201711_98"></p>
<h2 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_201847_17.png" alt="20200505_201847_17"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_224916_36.png" alt="20200505_224916_36"></p>
<p>与传统的二分类有什么区别呢？二分类label与label之间没关系，排序label之间有相关性。如ABC(ground truth)和ACB的分数会比较高。</p>
<h1 id="个性化推荐"><a href="#个性化推荐" class="headerlink" title="个性化推荐"></a>个性化推荐</h1><p>与信息检索的区别是没有用户的查询，操作基于用户画像。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_202845_47.png" alt="20200505_202845_47"></p>
<p>协同过滤是跨维度的。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_203112_35.png" alt="20200505_203112_35"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_203612_98.png" alt="20200505_203612_98"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_203935_35.png" alt="20200505_203935_35"></p>
<p>皮尔森那里，减去平均值可以区分一些喜欢打高分和低分的用户</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_204143_50.png" alt="20200505_204143_50"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_204426_57.png" alt="20200505_204426_57"></p>
<p>xa指的是先验的用户，xu指的是目标用户</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_204533_11.png" alt="20200505_204533_11"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_204725_32.png" alt="20200505_204725_32"></p>
<p>大训练集比较好，K取30的时候效果最好</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_205032_65.png" alt="20200505_205032_65"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_205052_50.png" alt="20200505_205052_50"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_205148_44.png" alt="20200505_205148_44"></p>
<h1 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_205356_61.png" alt="20200505_205356_61"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_211617_84.png" alt="20200505_211617_84"></p>
<p>KNN，高斯过程</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200505_220605_39.png" alt="20200505_220605_39"></p>
<h1 id="概率图模型"><a href="#概率图模型" class="headerlink" title="概率图模型"></a>概率图模型</h1><p>数据科学的目的就是构建数据的联合分布，然后根据联合分布求求出想要知道的条件分布，但是问题就是我们如果直接根据数据本身求联合概率分布，复杂度很高，所以这里引入了概率图模型，也就是通过一些先验知识对features之间的关系做一些限制。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095146_17.png" alt="20200507_095146_17"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095225_16.png" alt="20200507_095225_16"></p>
<h1 id="贝叶斯网络-有向图"><a href="#贝叶斯网络-有向图" class="headerlink" title="贝叶斯网络(有向图)"></a>贝叶斯网络(有向图)</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095353_26.png" alt="20200507_095353_26"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095533_44.png" alt="20200507_095533_44"></p>
<p>如果是一般的联合概率分布求法是全连接图，计算复杂度也大大增加。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_095812_47.png" alt="20200507_095812_47"></p>
<p>首先假设xi是符合某种先验的分布的，然后根据先验分布下的x去求取label，最后把所有的xi连乘起来(独立)</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_100248_59.png" alt="20200507_100248_59"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_100402_65.png" alt="20200507_100402_65"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_100458_74.png" alt="20200507_100458_74"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_100905_53.png" alt="20200507_100905_53"></p>
<p>前半段训练(推断所有random variable的后验分布)，后面是预测。边缘化即积掉隐变量</p>
<h1 id="概率图模型的条件独立"><a href="#概率图模型的条件独立" class="headerlink" title="概率图模型的条件独立"></a>概率图模型的条件独立</h1><p>上图式子的连乘的前提条件是独立</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101347_86.png" alt="20200507_101347_86">   </p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101611_24.png" alt="20200507_101611_24"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101618_35.png" alt="20200507_101618_35"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101625_17.png" alt="20200507_101625_17"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101637_44.png" alt="20200507_101637_44"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101645_12.png" alt="20200507_101645_12"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_101653_49.png" alt="20200507_101653_49"></p>
<p>head to head 知道的node发生变化，则概率也在发生变化：：explaining away</p>
<h2 id="有向分离"><a href="#有向分离" class="headerlink" title="有向分离"></a>有向分离</h2><p>只通过图模型，就判断谁和谁是独立的。A和B的所有路径都被阻断了</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_112840_26.png" alt="20200507_112840_26"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113144_82.png" alt="20200507_113144_82"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113308_52.png" alt="20200507_113308_52"></p>
<h2 id="独立同分布"><a href="#独立同分布" class="headerlink" title="独立同分布"></a>独立同分布</h2><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113408_11.png" alt="20200507_113408_11"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113554_81.png" alt="20200507_113554_81"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_113837_65.png" alt="20200507_113837_65"></p>
<p>α是拉普拉斯平滑因子，防止为0</p>
<h1 id="马尔可夫网络-无向图"><a href="#马尔可夫网络-无向图" class="headerlink" title="马尔可夫网络(无向图)"></a>马尔可夫网络(无向图)</h1><p>某个random variable的周围邻居全部被阻塞了，则这个也确定下来了</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_114138_32.png" alt="20200507_114138_32"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_114240_28.png" alt="20200507_114240_28"></p>
<p>团内两两连接</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_114416_51.png" alt="20200507_114416_51"></p>
<ul>
<li>势函数需要&gt;=0，确保概率为非负数</li>
<li>势函数可以用领域知识定义，相当于贝叶斯的，conditional distribution</li>
</ul>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_114823_52.png" alt="20200507_114823_52"></p>
<p>能量高的时候，势比较低。也就是能量高就越不稳定，就越难保持在原地。概率也就越低</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115020_23.png" alt="20200507_115020_23"></p>
<p>温度很高，处于混沌状态那么ps也就等于1/|s|(所有的state取平均)</p>
<h1 id="马尔可夫网络实例"><a href="#马尔可夫网络实例" class="headerlink" title="马尔可夫网络实例"></a>马尔可夫网络实例</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115316_93.png" alt="20200507_115316_93"></p>
<p>这里取负数，联想玻尔兹曼分布</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115327_13.png" alt="20200507_115327_13"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115337_20.png" alt="20200507_115337_20"></p>
<h1 id="马尔可夫-Vs-贝叶斯"><a href="#马尔可夫-Vs-贝叶斯" class="headerlink" title="马尔可夫 Vs 贝叶斯"></a>马尔可夫 Vs 贝叶斯</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115727_97.png" alt="20200507_115727_97"></p>
<p>1234成为了一个团</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_115833_14.png" alt="20200507_115833_14"></p>
<p>两者的conditional independence绝大多是可以共同表示出来，但是还是存在一些不能同时表示出来的。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_120120_91.png" alt="20200507_120120_91"></p>
<p>图1 如果变成了无向图之后，分布变得更加广阔了。</p>
<h1 id="链式模型推断"><a href="#链式模型推断" class="headerlink" title="链式模型推断"></a>链式模型推断</h1><p>就是给了任意图结构之后，去推断出边缘分布</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_120726_84.png" alt="20200507_120726_84"></p>
<p>频率派是参数估计(parameter estimation)，也就是通过最小或最大loss方程来更新参数。而贝叶斯派则是推断新的分布(variable inference)，也就是通过更新更优的分布，对认知的升级。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_121105_60.png" alt="20200507_121105_60"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_121208_57.png" alt="20200507_121208_57"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_121353_19.png" alt="20200507_121353_19"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_121646_89.png" alt="20200507_121646_89"></p>
<p>横向动态规划</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122110_13.png" alt="20200507_122110_13"></p>
<p>z不用求了。计算条件分布的时候会除掉</p>
<h1 id="树图模型推断"><a href="#树图模型推断" class="headerlink" title="树图模型推断"></a>树图模型推断</h1><p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122310_72.png" alt="20200507_122310_72"></p>
<p>13根节点的确定是随意的。提起来就是一棵树</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122506_59.png" alt="20200507_122506_59"></p>
<p>因为树有交叉，所以不能用消息传递，一个factor指向同一个x相当于计算一种x的势函数。</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122645_83.png" alt="20200507_122645_83"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122719_66.png" alt="20200507_122719_66"></p>
<p>factor和random variable只于彼此相连</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_122941_57.png" alt="20200507_122941_57"></p>
<p>和消息传递类似，就是根据要的random variable，与他相连的所有factor开始加和他们的子节点(子节点可能会遇到factor的话就连乘)，最后连乘所有与他相连的factor(message 就是加和关系，function就是连乘)，message就是被隐藏掉的所有random variable的加和</p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_123147_89.png" alt="20200507_123147_89"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124001_76.png" alt="20200507_124001_76"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124224_87.png" alt="20200507_124224_87"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124355_52.png" alt="20200507_124355_52"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124458_91.png" alt="20200507_124458_91"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124637_53.png" alt="20200507_124637_53"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_124909_74.png" alt="20200507_124909_74"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_125019_20.png" alt="20200507_125019_20"></p>
<p><img src="https://gitee.com/Belong34/MyBolgImage/raw/master/Image/20200507_125206_27.png" alt="20200507_125206_27"></p>
<p>sum product算法</p>
<h1 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h1><p>贝叶斯派比较于频率派，是白盒模型，而且往往需要较少的样本就可以得到不错效果，但是确定在于他求条件概率的时候的对于w一些积分是没有显式解的，通常就是使用一些sample w的方法或者定义他符合某个分布(高斯)去拟合他。结果就是思维elegant，解法比较随意。 也就是问题所在，思想很高，但是落地很难</p>

    </div>

    
    
    
        
      

      <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2020/02/11/深度学习14天笔记/" rel="next" title="深度学习14天笔记">
                  <i class="fa fa-chevron-left"></i> 深度学习14天笔记
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2020/03/07/目标检测总结/" rel="prev" title="目标追踪总结">
                  目标追踪总结 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    
    <div class="comments" id="gitalk-container"></div>
  

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#人工智能"><span class="nav-number">1.</span> <span class="nav-text">人工智能</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#数据科学"><span class="nav-number">2.</span> <span class="nav-text">数据科学</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#机器学习"><span class="nav-number">3.</span> <span class="nav-text">机器学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#历史"><span class="nav-number">3.1.</span> <span class="nav-text">历史</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#机器学习的两种类型"><span class="nav-number">3.2.</span> <span class="nav-text">机器学习的两种类型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#优势"><span class="nav-number">3.3.</span> <span class="nav-text">优势</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#机器学习应用"><span class="nav-number">4.</span> <span class="nav-text">机器学习应用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#面向预测的应用"><span class="nav-number">4.1.</span> <span class="nav-text">面向预测的应用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面向决策的应用"><span class="nav-number">4.2.</span> <span class="nav-text">面向决策的应用</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#基本思想"><span class="nav-number">5.</span> <span class="nav-text">基本思想</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#监督学习"><span class="nav-number">5.1.</span> <span class="nav-text">监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#学习目标是什么？"><span class="nav-number">5.1.1.</span> <span class="nav-text">学习目标是什么？</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#模型选择"><span class="nav-number">6.</span> <span class="nav-text">模型选择</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#过拟合，欠拟合"><span class="nav-number">6.1.</span> <span class="nav-text">过拟合，欠拟合</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#正则化"><span class="nav-number">6.2.</span> <span class="nav-text">正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Q：超参入可学习吗？"><span class="nav-number">6.2.1.</span> <span class="nav-text">Q：超参入可学习吗？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#奥卡姆剃刀"><span class="nav-number">6.3.</span> <span class="nav-text">奥卡姆剃刀</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#交叉验证"><span class="nav-number">6.4.</span> <span class="nav-text">交叉验证</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#泛化能力-GA"><span class="nav-number">7.</span> <span class="nav-text">泛化能力(GA)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#判别模型与生成模型"><span class="nav-number">8.</span> <span class="nav-text">判别模型与生成模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#生成模型"><span class="nav-number">8.1.</span> <span class="nav-text">生成模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#判别模型"><span class="nav-number">8.2.</span> <span class="nav-text">判别模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#两者的差别"><span class="nav-number">8.3.</span> <span class="nav-text">两者的差别</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#线性回归"><span class="nav-number">9.</span> <span class="nav-text">线性回归</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#梯度"><span class="nav-number">10.</span> <span class="nav-text">梯度</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#线性回归矩阵形式"><span class="nav-number">11.</span> <span class="nav-text">线性回归矩阵形式</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#泛线性模型"><span class="nav-number">12.</span> <span class="nav-text">泛线性模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#逻辑回归"><span class="nav-number">13.</span> <span class="nav-text">逻辑回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#二分类"><span class="nav-number">13.1.</span> <span class="nav-text">二分类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#与非线性模型对比"><span class="nav-number">13.2.</span> <span class="nav-text">与非线性模型对比</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#最大似然估计"><span class="nav-number">14.</span> <span class="nav-text">最大似然估计</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分类指标"><span class="nav-number">15.</span> <span class="nav-text">分类指标</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#支持向量机"><span class="nav-number">16.</span> <span class="nav-text">支持向量机</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#逻辑回归的可视化"><span class="nav-number">16.1.</span> <span class="nav-text">逻辑回归的可视化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#支持向量机-1"><span class="nav-number">16.2.</span> <span class="nav-text">支持向量机</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#向量机优化"><span class="nav-number">16.3.</span> <span class="nav-text">向量机优化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#序列最小优化-SMO"><span class="nav-number">17.</span> <span class="nav-text">序列最小优化(SMO)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#坐标上升法"><span class="nav-number">17.1.</span> <span class="nav-text">坐标上升法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SMO"><span class="nav-number">17.2.</span> <span class="nav-text">SMO</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#支持向量机核方法"><span class="nav-number">18.</span> <span class="nav-text">支持向量机核方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">18.1.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#人工神经网络发展"><span class="nav-number">19.</span> <span class="nav-text">人工神经网络发展</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#普适逼近定理"><span class="nav-number">20.</span> <span class="nav-text">普适逼近定理</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#反向传播"><span class="nav-number">21.</span> <span class="nav-text">反向传播</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#激活函数"><span class="nav-number">22.</span> <span class="nav-text">激活函数</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#深度学习思想简介"><span class="nav-number">23.</span> <span class="nav-text">深度学习思想简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#梯度消失问题的解决方法"><span class="nav-number">24.</span> <span class="nav-text">梯度消失问题的解决方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Relu"><span class="nav-number">24.1.</span> <span class="nav-text">Relu</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#深度残差Resnet"><span class="nav-number">24.2.</span> <span class="nav-text">深度残差Resnet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#批标准化"><span class="nav-number">24.3.</span> <span class="nav-text">批标准化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#陷入局部最小的解决方法"><span class="nav-number">25.</span> <span class="nav-text">陷入局部最小的解决方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#深度信念网络"><span class="nav-number">25.1.</span> <span class="nav-text">深度信念网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#adam"><span class="nav-number">25.2.</span> <span class="nav-text">adam</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#正则化-1"><span class="nav-number">26.</span> <span class="nav-text">正则化</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CNN-空间上的特征"><span class="nav-number">27.</span> <span class="nav-text">CNN(空间上的特征)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#用于文本分类"><span class="nav-number">27.1.</span> <span class="nav-text">用于文本分类</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#RNN-时间上的特征"><span class="nav-number">28.</span> <span class="nav-text">RNN(时间上的特征)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#LSTM"><span class="nav-number">29.</span> <span class="nav-text">LSTM</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Q-amp-A-课程上的提问"><span class="nav-number">29.1.</span> <span class="nav-text">Q &amp; A(课程上的提问)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#词嵌入"><span class="nav-number">29.2.</span> <span class="nav-text">词嵌入</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#语言模型"><span class="nav-number">29.3.</span> <span class="nav-text">语言模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#视觉语言对齐"><span class="nav-number">29.4.</span> <span class="nav-text">视觉语言对齐</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#生成图像描述"><span class="nav-number">29.5.</span> <span class="nav-text">生成图像描述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结-1"><span class="nav-number">29.6.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#函数逼近"><span class="nav-number">30.</span> <span class="nav-text">函数逼近</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#决策树"><span class="nav-number">31.</span> <span class="nav-text">决策树</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ID3"><span class="nav-number">32.</span> <span class="nav-text">ID3</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CART决策树"><span class="nav-number">33.</span> <span class="nav-text">CART决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#回归树"><span class="nav-number">33.1.</span> <span class="nav-text">回归树</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分类树"><span class="nav-number">33.2.</span> <span class="nav-text">分类树</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结-2"><span class="nav-number">33.3.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#集成树"><span class="nav-number">34.</span> <span class="nav-text">集成树</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#bagging"><span class="nav-number">35.</span> <span class="nav-text">bagging</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#bootstrap"><span class="nav-number">35.1.</span> <span class="nav-text">bootstrap</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#树模型总结"><span class="nav-number">36.</span> <span class="nav-text">树模型总结</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#随机森林"><span class="nav-number">37.</span> <span class="nav-text">随机森林</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#bagging-VS-随机森林-VS-Bootsing"><span class="nav-number">38.</span> <span class="nav-text">bagging VS 随机森林 VS Bootsing</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#广义加性模型"><span class="nav-number">39.</span> <span class="nav-text">广义加性模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Adaboost"><span class="nav-number">40.</span> <span class="nav-text">Adaboost</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#学习准则"><span class="nav-number">40.1.</span> <span class="nav-text">学习准则</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#算法"><span class="nav-number">40.2.</span> <span class="nav-text">算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#提升算法简史"><span class="nav-number">41.</span> <span class="nav-text">提升算法简史</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#GBDT"><span class="nav-number">42.</span> <span class="nav-text">GBDT</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#深度森林"><span class="nav-number">43.</span> <span class="nav-text">深度森林</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#多粒度级联森林-gcforest"><span class="nav-number">43.1.</span> <span class="nav-text">多粒度级联森林(gcforest)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#排序与过滤"><span class="nav-number">44.</span> <span class="nav-text">排序与过滤</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#学习排序"><span class="nav-number">45.</span> <span class="nav-text">学习排序</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#排序方法"><span class="nav-number">46.</span> <span class="nav-text">排序方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#pointwise"><span class="nav-number">46.1.</span> <span class="nav-text">pointwise</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pairwise"><span class="nav-number">46.2.</span> <span class="nav-text">pairwise</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Listwise"><span class="nav-number">46.3.</span> <span class="nav-text">Listwise</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LambdaRank"><span class="nav-number">46.4.</span> <span class="nav-text">LambdaRank</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结-3"><span class="nav-number">46.5.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#个性化推荐"><span class="nav-number">47.</span> <span class="nav-text">个性化推荐</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#KNN"><span class="nav-number">48.</span> <span class="nav-text">KNN</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#概率图模型"><span class="nav-number">49.</span> <span class="nav-text">概率图模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#贝叶斯网络-有向图"><span class="nav-number">50.</span> <span class="nav-text">贝叶斯网络(有向图)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#概率图模型的条件独立"><span class="nav-number">51.</span> <span class="nav-text">概率图模型的条件独立</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#有向分离"><span class="nav-number">51.1.</span> <span class="nav-text">有向分离</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#独立同分布"><span class="nav-number">51.2.</span> <span class="nav-text">独立同分布</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#马尔可夫网络-无向图"><span class="nav-number">52.</span> <span class="nav-text">马尔可夫网络(无向图)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#马尔可夫网络实例"><span class="nav-number">53.</span> <span class="nav-text">马尔可夫网络实例</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#马尔可夫-Vs-贝叶斯"><span class="nav-number">54.</span> <span class="nav-text">马尔可夫 Vs 贝叶斯</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#链式模型推断"><span class="nav-number">55.</span> <span class="nav-text">链式模型推断</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#树图模型推断"><span class="nav-number">56.</span> <span class="nav-text">树图模型推断</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#summary"><span class="nav-number">57.</span> <span class="nav-text">summary</span></a></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/22.png"
      alt="狗仔源">
  <p class="site-author-name" itemprop="name">狗仔源</p>
  <div class="site-description" itemprop="description">VCC & ME</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">19</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">标签</span>
        
      </div>
    
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:530738743@qq.com" title="E-Mail &rarr; mailto:530738743@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">狗仔源</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">59k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">54 分钟</span>
</div>

        












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.1"></script><script src="/js/motion.js?v=7.4.1"></script>
<script src="/js/schemes/pisces.js?v=7.4.1"></script>

<script src="/js/next-boot.js?v=7.4.1"></script>



  





















  

  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: '3fd967d31c63d255d193',
      clientSecret: 'b8ead67458a8526ad97a04eb9a872c28c8ec09ff',
      repo: 'BelongComments',
      owner: 'Belong34',
      admin: ['Belong34'],
      id: '08270b795209ad409061a5d261b859de',
        language: window.navigator.language || window.navigator.userLanguage,
      
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
</script>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":0,"vOffset":20},"mobile":{"show":true},"log":false,"tagMode":false});</script></body>
</html>
